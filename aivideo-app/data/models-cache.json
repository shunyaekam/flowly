{
  "lastSync": "2025-07-25T21:48:10.922Z",
  "totalModels": 265,
  "syncResults": [
    {
      "provider": "replicate",
      "modelsFetched": 1000,
      "modelsFiltered": 265,
      "timeSeconds": 29.849
    }
  ],
  "providers": {
    "replicate": {
      "modelsFetched": 1000,
      "modelsFiltered": 265,
      "timeSeconds": 29.849
    }
  },
  "models": [
    {
      "id": "bytedance/sdxl-lightning-4step",
      "name": "sdxl-lightning-4step",
      "displayName": "sdxl-lightning-4step",
      "provider": "replicate",
      "category": "image",
      "endpoint": "bytedance/sdxl-lightning-4step",
      "version": "6f7a773af6fc3e8de9d5a3c00be77c17308914bf67772726aff83496ba1e3bbe",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "SDXL-Lightning by ByteDance: a fast text-to-image model that makes high-quality images in 4 steps",
        "runCount": 1022182577,
        "confidence": 0.6,
        "qualityScore": 125.09528474601078,
        "createdAt": "2025-03-17T18:05:29.527465Z",
        "owner": "bytedance",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/779f3f58-c3db-4403-a01b-3ffed97a1449/out-0-1.jpg",
        "githubUrl": "https://github.com/lucataco/cog-sdxl-lightning-4step",
        "paperUrl": "https://huggingface.co/ByteDance/SDXL-Lightning/resolve/main/sdxl_lightning_report.pdf",
        "licenseUrl": "https://huggingface.co/ByteDance/SDXL-Lightning/blob/main/LICENSE.md",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "width": 1024,
              "height": 1024,
              "prompt": "self-portrait of a woman, lightning in the background",
              "scheduler": "K_EULER",
              "num_outputs": 1,
              "guidance_scale": 0,
              "negative_prompt": "worst quality, low quality",
              "num_inference_steps": 4
            },
            "output": [
              "https://replicate.delivery/yhqm/VyD24fDyzM2nQSg0nQc58W2EIj16hGcWKrXJozjAMR1BeidTA/out-0.png"
            ],
            "prompt": "self-portrait of a woman, lightning in the background"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Leave blank to randomize the seed",
          "width": "Width of output image. Recommended 1024 or 1280",
          "height": "Height of output image. Recommended 1024 or 1280",
          "prompt": "Input prompt",
          "scheduler": "scheduler",
          "num_outputs": "Number of images to output.",
          "guidance_scale": "Scale for classifier-free guidance",
          "negative_prompt": "Negative Input prompt",
          "num_inference_steps": "Number of denoising steps. 4 for best results",
          "disable_safety_checker": "Disable safety checker for generated images"
        }
      }
    },
    {
      "id": "black-forest-labs/flux-schnell",
      "name": "flux-schnell",
      "displayName": "flux-schnell",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-schnell",
      "version": "c846a69991daf4c0e5d016514849d14ee5b2e6846ce6b9d6f21369e564cfe51e",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "The fastest image generation model tailored for local development and personal use",
        "runCount": 418463099,
        "confidence": 0.6,
        "qualityScore": 106.21657168009271,
        "createdAt": "2025-06-25T20:02:06.203810Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/67c990ba-bb67-4355-822f-2bd8c42b2f0d/flux-schnell.webp",
        "githubUrl": "https://github.com/replicate/cog-flux",
        "paperUrl": null,
        "licenseUrl": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-schnell",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "black forest gateau cake spelling out the words \"FLUX SCHNELL\", tasty, food photography, dynamic shot",
              "go_fast": true,
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "output_quality": 80
            },
            "output": [
              "https://replicate.delivery/yhqm/hcDDSNf633zeDUz9sWkKfaftcfJLWIvuhn9vfCFWmufxelmemA/out-0.webp"
            ],
            "prompt": "black forest gateau cake spelling out the words \"FLUX SCHNELL\", tasty, food photography, dynamic shot"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Prompt for generated image",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16. Note that outputs will not be deterministic when this is enabled, even if you set a seed.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image",
          "output_format": "Format of the output images",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "num_inference_steps": "Number of denoising steps. 4 is recommended, and lower number of steps produce lower quality outputs, faster.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "openai/gpt-4o-mini",
      "name": "gpt-4o-mini",
      "displayName": "gpt-4o-mini",
      "provider": "replicate",
      "category": "image",
      "endpoint": "openai/gpt-4o-mini",
      "version": "dbc3c0dae7691f6f7fe979f5b17c93e5fc61d86e0631f4237ff284f79373fcf8",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Low latency, low cost version of OpenAI's GPT-4o model",
        "runCount": 1797845,
        "confidence": 0.6,
        "qualityScore": 97.54752488167736,
        "createdAt": "2025-06-23T20:48:54.058227Z",
        "owner": "openai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/274e635d-c3e7-4d26-919a-43d5f1431b00/Screenshot_2025-05-14_at_8.21.53P.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://openai.com/policies/",
        "pricing": {
          "tier": "premium"
        },
        "examples": [
          {
            "input": {
              "top_p": 1,
              "prompt": "My situationship is starting to cross over into more than \"friends with benefits\" territory. I'm catching feelings, but this is not in my five year plan. What should I do?",
              "messages": [],
              "image_input": [],
              "temperature": 1,
              "system_prompt": "You are a helpful assistant.",
              "presence_penalty": 0,
              "frequency_penalty": 0,
              "max_completion_tokens": 4096
            },
            "output": "Navigating a situationship can be challenging, especially when feelings begin to develop. Here are some steps you can take to handle the situation:\n\n1. **Reflect on Your Feelings**: Take some time to understand your emotions. Why are you catching feelings? Is it because of the connection you have, or is it more about wanting something deeper? Understanding your feelings can help you make a clearer decision.\n\n2. **Consider Your Goals**: Since you mentioned this isn’t part of your five-year plan, think about what that means for you. What are your priorities right now? Are you willing to reconsider your goals, or do you want to stick to them?\n\n3. **Communicate Openly**: If you feel comfortable, consider having an honest conversation with the other person. Share your feelings and your perspective on the situation. Communication is key in any relationship, especially when emotions are involved.\n\n4. **Set Boundaries**: If you prefer to maintain the \"friends with benefits\" aspect, it might be helpful to set some boundaries to avoid getting too emotionally invested. Clearly defining the relationship can help both of you understand what's expected.\n\n5. **Evaluate the Other Person's Feelings**: Try to gauge how the other person feels about the situation. Are they also developing feelings, or are they content with keeping things casual? Their feelings will heavily influence how you should proceed.\n\n6. **Plan for Different Outcomes**: If you talk and find that both of you are on the same page, you might decide to explore a deeper relationship. If not, you need to consider if you're comfortable continuing as is or if it’s better to distance yourself.\n\n7. **Prioritize Self-Care**: Regardless of how you decide to move forward, make sure to take care of yourself emotionally. It's okay to feel conflicted, and processing those feelings is essential.\n\nRemember, it’s perfectly okay to prioritize your goals and values. If you find that your feelings could lead to complications you’re not prepared for, it might be best to reassess the connection.",
            "prompt": "My situationship is starting to cross over into more than \"friends with benefits\" territory. I'm catching feelings, but this is not in my five year plan. What should I do?"
          }
        ],
        "parameterDescriptions": {
          "top_p": "Nucleus sampling parameter - the model considers the results of the tokens with top_p probability mass. (0.1 means only the tokens comprising the top 10% probability mass are considered.)",
          "prompt": "The prompt to send to the model. Do not use if using messages.",
          "image_input": "List of images to send to the model",
          "temperature": "Sampling temperature between 0 and 2",
          "system_prompt": "System prompt to set the assistant's behavior",
          "presence_penalty": "Presence penalty parameter - positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.",
          "frequency_penalty": "Frequency penalty parameter - positive values penalize the repetition of tokens.",
          "max_completion_tokens": "Maximum number of completion tokens to generate"
        }
      }
    },
    {
      "id": "black-forest-labs/flux-1.1-pro",
      "name": "flux-1.1-pro",
      "displayName": "flux-1.1-pro",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-1.1-pro",
      "version": "80a09d66baa990429c2f5ae8a4306bf778a1b3775afd01cc2cc8bdbe9033769c",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Faster, better FLUX Pro. Text-to-image model with excellent image quality, prompt adherence, and output diversity.",
        "runCount": 45336970,
        "confidence": 0.9,
        "qualityScore": 96.56452501191275,
        "createdAt": "2025-03-31T12:45:41.061611Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/bd872eff-363a-4e10-8cc1-84057afa9f57/flux-1.1-cover.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://replicate.com/black-forest-labs/flux-pro#license",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "black forest gateau cake spelling out the words \"FLUX 1 . 1 Pro\", tasty, food photography",
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "output_quality": 80,
              "safety_tolerance": 2,
              "prompt_upsampling": true
            },
            "output": "https://replicate.delivery/czjl/XetPfMnnBtnyLUNiNcnl2Hneyeo8AsfsOl2AG5Znql5f3VK9E/tmpuv7lgrx7.jpg",
            "prompt": "black forest gateau cake spelling out the words \"FLUX 1 . 1 Pro\", tasty, food photography"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "width": "Width of the generated image in text-to-image mode. Only used when aspect_ratio=custom. Must be a multiple of 32 (if it's not, it will be rounded to nearest multiple of 32). Note: Ignored in img2img and inpainting modes.",
          "height": "Height of the generated image in text-to-image mode. Only used when aspect_ratio=custom. Must be a multiple of 32 (if it's not, it will be rounded to nearest multiple of 32). Note: Ignored in img2img and inpainting modes.",
          "prompt": "Text prompt for image generation",
          "aspect_ratio": "Aspect ratio for the generated image",
          "image_prompt": "Image to use with Flux Redux. This is used together with the text prompt to guide the generation towards the composition of the image_prompt. Must be jpeg, png, gif, or webp.",
          "output_format": "Format of the output images.",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "safety_tolerance": "Safety tolerance, 1 is most strict and 6 is most permissive",
          "prompt_upsampling": "Automatically modify the prompt for more creative generation"
        }
      }
    },
    {
      "id": "black-forest-labs/flux-dev",
      "name": "flux-dev",
      "displayName": "flux-dev",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-dev",
      "version": "6e4a938f85952bdabcc15aa329178c4d681c52bf25a0342403287dc26944661d",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A 12 billion parameter rectified flow transformer capable of generating images from text descriptions",
        "runCount": 22794589,
        "confidence": 0.6,
        "qualityScore": 93.57831785073233,
        "createdAt": "2025-06-25T20:04:14.718506Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/cb4203e5-9ece-42e7-b326-98ff3fa35c3a/Replicate_Prediction_15.webp",
        "githubUrl": "https://github.com/replicate/cog-flux",
        "paperUrl": null,
        "licenseUrl": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "black forest gateau cake spelling out the words \"FLUX DEV\", tasty, food photography, dynamic shot",
              "go_fast": true,
              "guidance": 3.5,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "output_quality": 80,
              "prompt_strength": 0.8,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/pvkq4S7Nx96bCdxUEK51fDCFx1Msf5UDJWItRW9VNeByPydpA/out-0.webp"
            ],
            "prompt": "black forest gateau cake spelling out the words \"FLUX DEV\", tasty, food photography, dynamic shot"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image mode. The aspect ratio of your output will match this image",
          "prompt": "Prompt for generated image",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16. Note that outputs will not be deterministic when this is enabled, even if you set a seed.",
          "guidance": "Guidance for generated image",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image",
          "output_format": "Format of the output images",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "num_inference_steps": "Number of denoising steps. Recommended range is 28-50, and lower number of steps produce lower quality outputs, faster.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "black-forest-labs/flux-1.1-pro-ultra",
      "name": "flux-1.1-pro-ultra",
      "displayName": "flux-1.1-pro-ultra",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-1.1-pro-ultra",
      "version": "c6e5086a542c99e7e523a83d3017654e8618fe64ef427c772a1def05bb599f0c",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "FLUX1.1 [pro] in ultra and raw modes. Images are up to 4 megapixels. Use raw mode for realism.",
        "runCount": 15153812,
        "confidence": 0.9,
        "qualityScore": 91.80521923696753,
        "createdAt": "2025-03-31T12:46:38.338040Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/8121c76b-fbff-41d9-834d-c70dea9d2191/flux-ultra-cover.jpg",
        "githubUrl": null,
        "paperUrl": "https://blackforestlabs.ai/flux-1-1-ultra/",
        "licenseUrl": "https://replicate.com/black-forest-labs/flux-pro#license",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "raw": false,
              "prompt": "a majestic snow-capped mountain peak bathed in a warm glow of the setting sun",
              "aspect_ratio": "3:2",
              "output_format": "jpg",
              "safety_tolerance": 2,
              "image_prompt_strength": 0.1
            },
            "output": "https://replicate.delivery/czjl/jqtNvxYHcnLELpszvkVf0APhMkBnwzrdo205RaVB7MttqU6JA/tmppokfymld.jpg",
            "prompt": "a majestic snow-capped mountain peak bathed in a warm glow of the setting sun"
          }
        ],
        "parameterDescriptions": {
          "raw": "Generate less processed, more natural-looking images",
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Text prompt for image generation",
          "aspect_ratio": "Aspect ratio for the generated image",
          "image_prompt": "Image to use with Flux Redux. This is used together with the text prompt to guide the generation towards the composition of the image_prompt. Must be jpeg, png, gif, or webp.",
          "output_format": "Format of the output images.",
          "safety_tolerance": "Safety tolerance, 1 is most strict and 6 is most permissive",
          "image_prompt_strength": "Blend between the prompt and the image prompt."
        }
      }
    },
    {
      "id": "black-forest-labs/flux-pro",
      "name": "flux-pro",
      "displayName": "flux-pro",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-pro",
      "version": "1e237aa703bf3a8ab480d5b595563128807af649c50afc0b4f22a9174e90d1d6",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "State-of-the-art image generation with top of the line prompt following, visual quality, image detail and output diversity.",
        "runCount": 12519865,
        "confidence": 0.9,
        "qualityScore": 90.9759968064981,
        "createdAt": "2025-03-31T12:44:55.496144Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/a36275e2-34d4-4b3d-83cd-f9aaf73c9386/https___replicate.delive_o40qpZl.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://replicate.com/black-forest-labs/flux-pro#license",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "steps": 25,
              "width": 1024,
              "height": 1024,
              "prompt": "The world's largest black forest cake, the size of a building, surrounded by trees of the black forest",
              "guidance": 3,
              "interval": 2,
              "safety_tolerance": 2
            },
            "output": "https://bflapistorage.blob.core.windows.net/public/c8145aa6e5894cbd815d6ce708fea9f2/sample.jpg",
            "prompt": "The world's largest black forest cake, the size of a building, surrounded by trees of the black forest"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "steps": "Number of diffusion steps",
          "width": "Width of the generated image in text-to-image mode. Only used when aspect_ratio=custom. Must be a multiple of 32 (if it's not, it will be rounded to nearest multiple of 32). Note: Ignored in img2img and inpainting modes.",
          "height": "Height of the generated image in text-to-image mode. Only used when aspect_ratio=custom. Must be a multiple of 32 (if it's not, it will be rounded to nearest multiple of 32). Note: Ignored in img2img and inpainting modes.",
          "prompt": "Text prompt for image generation",
          "guidance": "Controls the balance between adherence to the text prompt and image quality/diversity. Higher values make the output more closely match the prompt but may reduce overall image quality. Lower values allow for more creative freedom but might produce results less relevant to the prompt.",
          "interval": "Interval is a setting that increases the variance in possible outputs letting the model be a tad more dynamic in what outputs it may produce in terms of composition, color, detail, and prompt interpretation. Setting this value low will ensure strong prompt following with more consistent outputs, setting it higher will produce more dynamic or varied outputs.",
          "aspect_ratio": "Aspect ratio for the generated image",
          "image_prompt": "Image to use with Flux Redux. This is used together with the text prompt to guide the generation towards the composition of the image_prompt. Must be jpeg, png, gif, or webp.",
          "output_format": "Format of the output images.",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "safety_tolerance": "Safety tolerance, 1 is most strict and 6 is most permissive",
          "prompt_upsampling": "Automatically modify the prompt for more creative generation"
        }
      }
    },
    {
      "id": "black-forest-labs/flux-kontext-pro",
      "name": "flux-kontext-pro",
      "displayName": "flux-kontext-pro",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-kontext-pro",
      "version": "aa776ca45ce7f7d185418f700df8ec6ca6cb367bfd88e9cd225666c4c179d1d7",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A state-of-the-art text-based image editing model that delivers high-quality outputs with excellent prompt following and consistent results for transforming images through natural language",
        "runCount": 11117616,
        "confidence": 0.9,
        "qualityScore": 90.46011708589783,
        "createdAt": "2025-07-24T19:38:52.052171Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/e74eecd6-daf1-4050-9f04-36313bd6f007/two-people-cropped.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "Make this a 90s cartoon",
              "input_image": "https://replicate.delivery/pbxt/N55l5TWGh8mSlNzW8usReoaNhGbFwvLeZR3TX1NL4pd2Wtfv/replicate-prediction-f2d25rg6gnrma0cq257vdw2n4c.png",
              "aspect_ratio": "match_input_image",
              "output_format": "jpg",
              "safety_tolerance": 2
            },
            "output": "https://replicate.delivery/xezq/83OKs6yfdoT5YCpfREnrFFbqLbfWbus8Q0e06fQ0BAMDRKamC/tmpu3nqollf.jpg",
            "prompt": "Make this a 90s cartoon"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Text description of what you want to generate, or the instruction on how to edit the given image.",
          "input_image": "Image to use as reference. Must be jpeg, png, gif, or webp.",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "output_format": "Output format for the generated image",
          "safety_tolerance": "Safety tolerance, 0 is most strict and 6 is most permissive. 2 is currently the maximum allowed when input images are used.",
          "prompt_upsampling": "Automatic prompt improvement"
        }
      }
    },
    {
      "id": "prunaai/flux.1-dev",
      "name": "flux.1-dev",
      "displayName": "flux.1-dev",
      "provider": "replicate",
      "category": "image",
      "endpoint": "prunaai/flux.1-dev",
      "version": "b0306d92aa025bb747dc74162f3c27d6ed83798e08e5f8977adf3d859d0536a3",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This is the fastest Flux Dev endpoint in the world, contact us for more at pruna.ai",
        "runCount": 9549733,
        "confidence": 0.6,
        "qualityScore": 89.79991274835992,
        "createdAt": "2025-07-25T12:11:26.215907Z",
        "owner": "prunaai",
        "coverImage": "https://replicate.delivery/xezq/SUtU1LMXRjLQP1MxG9Jz22zmK520sAlcpIuKWJZ9xMRMnAQF/output_-1_0.jpeg",
        "githubUrl": "https://github.com/black-forest-labs/flux",
        "paperUrl": "https://bfl.ai/announcements/24-08-01-bfl",
        "licenseUrl": "https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "prompt": "black forest gateau cake spelling out the words \"FLUX DEV\", tasty, food photography, dynamic shot",
              "guidance": 3.5,
              "image_size": 1024,
              "speed_mode": "Extra Juiced 🔥 (more speed)",
              "aspect_ratio": "1:1",
              "output_format": "jpg",
              "output_quality": 80,
              "num_inference_steps": 28
            },
            "output": "https://replicate.delivery/xezq/SUtU1LMXRjLQP1MxG9Jz22zmK520sAlcpIuKWJZ9xMRMnAQF/output_-1_0.jpeg",
            "prompt": "black forest gateau cake spelling out the words \"FLUX DEV\", tasty, food photography, dynamic shot"
          }
        ],
        "parameterDescriptions": {
          "seed": "Seed",
          "prompt": "Prompt",
          "guidance": "Guidance scale",
          "image_size": "Base image size (longest side)",
          "speed_mode": "Speed optimization level",
          "aspect_ratio": "Aspect ratio of the output image",
          "output_format": "Output format",
          "output_quality": "Output quality (for jpg and webp)",
          "num_inference_steps": "Number of inference steps"
        }
      }
    },
    {
      "id": "openai/gpt-4.1-nano",
      "name": "gpt-4.1-nano",
      "displayName": "gpt-4.1-nano",
      "provider": "replicate",
      "category": "image",
      "endpoint": "openai/gpt-4.1-nano",
      "version": "e92a2f45589db9836c6351c17c4d94ef912b8e846d352a180ba7f1b6123b37f0",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Fastest, most cost-effective GPT-4.1 model from OpenAI",
        "runCount": 256813,
        "confidence": 0.6,
        "qualityScore": 89.09618695241899,
        "createdAt": "2025-06-23T21:24:50.399875Z",
        "owner": "openai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/f2c12cca-5859-407a-9189-0509526e4757/Screenshot_2025-05-01_at_12.29.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://openai.com/policies/",
        "pricing": {
          "tier": "premium"
        },
        "examples": [
          {
            "input": {
              "prompt": "What is San Junipero?",
              "temperature": 1,
              "system_prompt": "You are a helpful assistant."
            },
            "output": "San Junipero is a fictional town featured in the anthology series *Black Mirror*, specifically in the episode titled \"San Junipero.\" The episode originally aired in 2016 and is one of the most acclaimed installments of the series.\n\nIn the story, San Junipero is depicted as a picturesque, nostalgic beach town set in California, primarily during the 1980s. It is revealed to be a virtual reality simulation where people can visit temporarily or permanently after death or while still alive. The town serves as a digital paradise, allowing residents to relive past memories, connect with loved ones, and choose to extend their consciousness beyond physical mortality.\n\nThe episode explores themes of love, memory, mortality, and the ethical dilemmas associated with virtual immortality, making San Junipero a significant and thought-provoking setting within the narrative.",
            "prompt": "What is San Junipero?"
          }
        ],
        "parameterDescriptions": {
          "top_p": "Nucleus sampling parameter - the model considers the results of the tokens with top_p probability mass. (0.1 means only the tokens comprising the top 10% probability mass are considered.)",
          "prompt": "The prompt to send to the model. Do not use if using messages.",
          "image_input": "List of images to send to the model",
          "temperature": "Sampling temperature between 0 and 2",
          "system_prompt": "System prompt to set the assistant's behavior",
          "presence_penalty": "Presence penalty parameter - positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.",
          "frequency_penalty": "Frequency penalty parameter - positive values penalize the repetition of tokens.",
          "max_completion_tokens": "Maximum number of completion tokens to generate"
        }
      }
    },
    {
      "id": "openai/gpt-image-1",
      "name": "gpt-image-1",
      "displayName": "gpt-image-1",
      "provider": "replicate",
      "category": "image",
      "endpoint": "openai/gpt-image-1",
      "version": "a6198aeaea27df5f3a9f11335cd61b2031729f9527cd34e6cdb4bb3ee9355b87",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A multimodal image generation model that creates high-quality images. You need to bring your own verified OpenAI key to use this model. Your OpenAI account will be charged for usage.",
        "runCount": 225533,
        "confidence": 0.6,
        "qualityScore": 88.53212022485891,
        "createdAt": "2025-07-18T11:00:53.415896Z",
        "owner": "openai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/105c8d2f-df56-499f-8121-3a1f6232cf0b/Screenshot_2025-04-23_at_4.08..png",
        "githubUrl": null,
        "paperUrl": "https://openai.com/index/image-generation-api/",
        "licenseUrl": "https://openai.com/policies/",
        "pricing": {
          "tier": "premium"
        },
        "examples": [
          {
            "input": {
              "prompt": "Add the floral pattern to the vase",
              "quality": "auto",
              "background": "auto",
              "moderation": "auto",
              "aspect_ratio": "1:1",
              "input_images": [
                "https://replicate.delivery/pbxt/MusWuQJm1RJPu1Cj0ajRmoMnHyYNPk6ljT1QCU4DbHMsqDTF/53541851-62f3-44a7-b075-ef053ae2f324.jpg",
                "https://replicate.delivery/pbxt/MusWuPkfcvyZQuuXeMIbQXEMe9K2G8rDCNraQffAt0OzMRaT/colored-flower-pattern-free-vector.jpg"
              ],
              "output_format": "webp",
              "openai_api_key": "[REDACTED]",
              "number_of_images": 1,
              "output_compression": 90
            },
            "output": [
              "https://replicate.delivery/xezq/hEcJpm50O9ouFVu506qf6wAjLKc4MH1oFeRZ4PORmTqVqVnUA/tmpfkxavg8q.png"
            ],
            "prompt": "Add the floral pattern to the vase"
          }
        ],
        "parameterDescriptions": {
          "prompt": "A text description of the desired image",
          "quality": "The quality of the generated image",
          "user_id": "An optional unique identifier representing your end-user. This helps OpenAI monitor and detect abuse.",
          "background": "Set whether the background is transparent or opaque or choose automatically",
          "moderation": "Content moderation level",
          "aspect_ratio": "The aspect ratio of the generated image",
          "input_images": "A list of images to use as input for the generation",
          "output_format": "Output format",
          "input_fidelity": "Control how much effort the model will exert to match the style and features, especially facial features, of input images",
          "openai_api_key": "Your OpenAI API key",
          "number_of_images": "Number of images to generate (1-10)",
          "output_compression": "Compression level (0-100%)"
        }
      }
    },
    {
      "id": "bytedance/seedream-3",
      "name": "seedream-3",
      "displayName": "seedream-3",
      "provider": "replicate",
      "category": "image",
      "endpoint": "bytedance/seedream-3",
      "version": "e97385a576173b08a6a87546457582b01f65bf29a4dc00f1191e884894e0bc73",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A text-to-image model with support for native high-resolution (2K) image generation",
        "runCount": 190194,
        "confidence": 0.9,
        "qualityScore": 87.79199095666841,
        "createdAt": "2025-06-25T22:31:30.688912Z",
        "owner": "bytedance",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/de2ae1dd-f7b8-4b9e-901e-86125ac2b4a8/tmpcoezojc2.jpg",
        "githubUrl": null,
        "paperUrl": "https://arxiv.org/pdf/2504.11346",
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "size": "regular",
              "width": 2048,
              "height": 2048,
              "prompt": "A cinematic, photorealistic medium shot capturing the nostalgic warmth of a mid-2000s indie film. The focus is a young woman with a sleek, straight bob haircut in cool platinum white with freckled skin, looking directly and intently into the camera lens with a knowing smirk, her head is looking up slightly. She wears an oversized band t-shirt that says \"Seedream 3.0 on Replicate\" in huge stylized text over a long-sleeved striped top and simple silver stud earrings. The lighting is soft, golden hour sunlight creating lens flare and illuminating dust motes in the air. The background shows a blurred outdoor urban setting with graffiti-covered walls (the graffiti says \"seedream\" in stylized graffiti lettering), rendered with a shallow depth of field. Natural film grain, a warm, slightly muted color palette, and sharp focus on her expressive eyes enhance the intimate, authentic feel",
              "aspect_ratio": "16:9",
              "guidance_scale": 2.5
            },
            "output": "https://replicate.delivery/xezq/3o7diQSJVj78DlUsUlqk75pJOvR6ApeCdTmXQED4xJ0WeX6UA/tmpcoezojc2.jpg",
            "prompt": "A cinematic, photorealistic medium shot capturing the nostalgic warmth of a mid-2000s indie film. The focus is a young woman with a sleek, straight bob haircut in cool platinum white with freckled skin, looking directly and intently into the camera lens with a knowing smirk, her head is looking up slightly. She wears an oversized band t-shirt that says \"Seedream 3.0 on Replicate\" in huge stylized text over a long-sleeved striped top and simple silver stud earrings. The lighting is soft, golden hour sunlight creating lens flare and illuminating dust motes in the air. The background shows a blurred outdoor urban setting with graffiti-covered walls (the graffiti says \"seedream\" in stylized graffiti lettering), rendered with a shallow depth of field. Natural film grain, a warm, slightly muted color palette, and sharp focus on her expressive eyes enhance the intimate, authentic feel"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "size": "Big images will have their longest dimension be 2048px. Small images will have their shortest dimension be 512px. Regular images will always be 1 megapixel. Ignored if aspect ratio is custom.",
          "width": "Image width",
          "height": "Image height",
          "prompt": "Text prompt for image generation",
          "aspect_ratio": "Image aspect ratio. Set to 'custom' to specify width and height.",
          "guidance_scale": "Prompt adherence. Higher = more literal."
        }
      }
    },
    {
      "id": "bytedance/seedance-1-lite",
      "name": "seedance-1-lite",
      "displayName": "seedance-1-lite",
      "provider": "replicate",
      "category": "video",
      "endpoint": "bytedance/seedance-1-lite",
      "version": "5097a2c4414863ed7dc948d482b72e9b07dbb4f0ad24a6027452697ff1c3693b",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A video generation model that offers text-to-video and image-to-video support for 5s or 10s videos, at 480p and 720p resolution",
        "runCount": 163977,
        "confidence": 0.9,
        "qualityScore": 87.14785585123866,
        "createdAt": "2025-07-16T17:11:36.416995Z",
        "owner": "bytedance",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/961a33d5-e27a-4b15-8cdd-3e37d5375297/replicate-seedance-1-lite.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "fps": 24,
              "prompt": "a woman walks in the park",
              "duration": 5,
              "resolution": "720p",
              "aspect_ratio": "16:9",
              "camera_fixed": false
            },
            "output": "https://replicate.delivery/xezq/L4f180LhnhSCHihiHQ1vX7ZfEG7XOK2WCKNlGGd81xGr7v4UA/tmpeywvj5rm.mp4",
            "prompt": "a woman walks in the park"
          }
        ],
        "parameterDescriptions": {
          "fps": "Frame rate (frames per second)",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image-to-video generation",
          "prompt": "Text prompt for video generation",
          "duration": "Video duration in seconds",
          "resolution": "Video resolution",
          "aspect_ratio": "Video aspect ratio. Ignored if an image is used.",
          "camera_fixed": "Whether to fix camera position",
          "last_frame_image": "Input image for last frame generation. This only works if an image start frame is given too."
        }
      }
    },
    {
      "id": "bytedance/hyper-flux-8step",
      "name": "hyper-flux-8step",
      "displayName": "hyper-flux-8step",
      "provider": "replicate",
      "category": "image",
      "endpoint": "bytedance/hyper-flux-8step",
      "version": "16084e9731223a4367228928a6cb393b21736da2a0ca6a5a492ce311f0a97143",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Hyper FLUX 8-step by ByteDance",
        "runCount": 15196210,
        "confidence": 0.6,
        "qualityScore": 86.81735315120869,
        "createdAt": "2025-03-18T17:28:17.120989Z",
        "owner": "bytedance",
        "coverImage": "https://replicate.delivery/yhqm/bKCAFhWFtbafL6Q31fEkfzVUKDUxY3GcdU1KGtR1AfRhcHOOB/out-0.webp",
        "githubUrl": "https://github.com/lucataco/cog-hyper-flux-8step",
        "paperUrl": "https://arxiv.org/abs/2404.13686",
        "licenseUrl": "https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "a dog smiling and looking directly at the camera, wearing a white t-shirt with the word \"HYPER\" printed on it.",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3.5,
              "output_quality": 80,
              "num_inference_steps": 8
            },
            "output": [
              "https://replicate.delivery/yhqm/bKCAFhWFtbafL6Q31fEkfzVUKDUxY3GcdU1KGtR1AfRhcHOOB/out-0.webp"
            ],
            "prompt": "a dog smiling and looking directly at the camera, wearing a white t-shirt with the word \"HYPER\" printed on it."
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "width": "Width of the generated image. Optional, only used when aspect_ratio=custom. Must be a multiple of 16 (if it's not, it will be rounded to nearest multiple of 16)",
          "height": "Height of the generated image. Optional, only used when aspect_ratio=custom. Must be a multiple of 16 (if it's not, it will be rounded to nearest multiple of 16)",
          "prompt": "Prompt for generated image",
          "num_outputs": "Number of images to output.",
          "aspect_ratio": "Aspect ratio for the generated image. The size will always be 1 megapixel, i.e. 1024x1024 if aspect ratio is 1:1. To use arbitrary width and height, set aspect ratio to 'custom'.",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "num_inference_steps": "Number of inference steps",
          "disable_safety_checker": "Disable safety checker for generated images. This feature is only available through the API. See [https://replicate.com/docs/how-does-replicate-work#safety](https://replicate.com/docs/how-does-replicate-work#safety)"
        }
      }
    },
    {
      "id": "recraft-ai/recraft-v3",
      "name": "recraft-v3",
      "displayName": "recraft-v3",
      "provider": "replicate",
      "category": "image",
      "endpoint": "recraft-ai/recraft-v3",
      "version": "0fea59248a8a1ddb8197792577f6627ec65482abc49f50c6e9da40ca8729d24d",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Recraft V3 (code-named red_panda) is a text-to-image model with the ability to generate long texts, and images in a wide list of styles. As of today, it is SOTA in image generation, proven by the Text-to-Image Benchmark by Artificial Analysis",
        "runCount": 4476365,
        "confidence": 0.9,
        "qualityScore": 86.50925588419769,
        "createdAt": "2025-03-24T10:34:19.501238Z",
        "owner": "recraft-ai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/a2b66c42-4633-443d-997f-cc987bca07c7/V3.webp",
        "githubUrl": null,
        "paperUrl": "https://recraft.ai",
        "licenseUrl": "https://www.recraft.ai/terms",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "size": "1365x1024",
              "style": "any",
              "prompt": "a wildlife photography photo of a red panda using a laptop in a snowy forest"
            },
            "output": "https://replicate.delivery/czjl/eTxDZunLeFulD0734CMCIuhP6llmZbgtbxfjzyfi4hxAAOwOB/output.webp",
            "prompt": "a wildlife photography photo of a red panda using a laptop in a snowy forest"
          }
        ],
        "parameterDescriptions": {
          "size": "Width and height of the generated image. Size is ignored if an aspect ratio is set.",
          "style": "Style of the generated image.",
          "prompt": "Text prompt for image generation",
          "aspect_ratio": "Aspect ratio of the generated image"
        }
      }
    },
    {
      "id": "bytedance/seedance-1-pro",
      "name": "seedance-1-pro",
      "displayName": "seedance-1-pro",
      "provider": "replicate",
      "category": "video",
      "endpoint": "bytedance/seedance-1-pro",
      "version": "567d056ac32cf4966a0a6ce60b043408e2a81493e7b0c6579af80aca19d1c070",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A pro version of Seedance that offers text-to-video and image-to-video support for 5s or 10s videos, at 480p and 1080p resolution",
        "runCount": 127020,
        "confidence": 0.9,
        "qualityScore": 86.03875527492745,
        "createdAt": "2025-07-16T17:15:35.061492Z",
        "owner": "bytedance",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/b11bb650-a993-485b-b433-f1ba1c4cb90b/replicate-seedance-1-pro.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "fps": 24,
              "prompt": "The sun rises slowly between tall buildings. [Ground-level follow shot] Bicycle tires roll over a dew-covered street at dawn. The cyclist passes through dappled light under a bridge as the entire city gradually wakes up.",
              "duration": 5,
              "resolution": "1080p",
              "aspect_ratio": "16:9",
              "camera_fixed": false
            },
            "output": "https://replicate.delivery/xezq/ClgDLn4vlLosCtQeNCBMfAFxFefS9CwjWr6XkppFrQ2saYoTB/tmp4csnp1gw.mp4",
            "prompt": "The sun rises slowly between tall buildings. [Ground-level follow shot] Bicycle tires roll over a dew-covered street at dawn. The cyclist passes through dappled light under a bridge as the entire city gradually wakes up."
          }
        ],
        "parameterDescriptions": {
          "fps": "Frame rate (frames per second)",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image-to-video generation",
          "prompt": "Text prompt for video generation",
          "duration": "Video duration in seconds",
          "resolution": "Video resolution",
          "aspect_ratio": "Video aspect ratio. Ignored if an image is used.",
          "camera_fixed": "Whether to fix camera position"
        }
      }
    },
    {
      "id": "luma/photon-flash",
      "name": "photon-flash",
      "displayName": "photon-flash",
      "provider": "replicate",
      "category": "image",
      "endpoint": "luma/photon-flash",
      "version": "4235af608e50dac14e9244198cef089049efbd83ba05f2aa4e271076a6f613ee",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Accelerated variant of Photon prioritizing speed while maintaining quality",
        "runCount": 118646,
        "confidence": 0.9,
        "qualityScore": 85.74256761517393,
        "createdAt": "2025-07-25T13:22:19.539108Z",
        "owner": "luma",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/8459f7e9-7445-4046-82aa-917a0f561b80/tmpyf9dx02r.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://lumalabs.ai/dream-machine/api/terms",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "A train car is engulfed in a massive explosion, with flames and smoke billowing into the sky as debris flies in all directions, cinematic photograph, explosive action, high contrast, dynamic lighting.",
              "aspect_ratio": "16:9",
              "image_reference_weight": 0.85,
              "style_reference_weight": 0.85
            },
            "output": "https://replicate.delivery/czjl/6iZ89qakg74mCVjFYeDk0GljoYQReoV0k7WwSjxXmCLcV53TA/tmpyf9dx02r.jpg",
            "prompt": "A train car is engulfed in a massive explosion, with flames and smoke billowing into the sky as debris flies in all directions, cinematic photograph, explosive action, high contrast, dynamic lighting."
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Text prompt for image generation",
          "aspect_ratio": "Aspect ratio of the generated image",
          "image_reference": "Reference image to guide generation",
          "style_reference": "Style reference image to guide generation",
          "character_reference": "Character reference image to guide generation",
          "image_reference_url": "Deprecated: Use image_reference instead",
          "style_reference_url": "Deprecated: Use style_reference instead",
          "image_reference_weight": "Weight of the reference image. Larger values will make the reference image have a stronger influence on the generated image.",
          "style_reference_weight": "Weight of the style reference image",
          "character_reference_url": "Deprecated: Use character_reference instead"
        }
      }
    },
    {
      "id": "black-forest-labs/flux-dev-lora",
      "name": "flux-dev-lora",
      "displayName": "flux-dev-lora",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-dev-lora",
      "version": "ae0d7d645446924cf1871e3ca8796e8318f72465d2b5af9323a835df93bf0917",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A version of flux-dev, a text to image model, that supports fast fine-tuned lora inference",
        "runCount": 3300830,
        "confidence": 0.6,
        "qualityScore": 85.18623289357178,
        "createdAt": "2025-06-25T20:05:15.087009Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/a79cc4a8-318c-4316-a800-097ef0bdce7a/https___replicate.del_25H5GQ7.webp",
        "githubUrl": "https://github.com/replicate/cog-flux",
        "paperUrl": null,
        "licenseUrl": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "style of 80s cyberpunk, a portrait photo",
              "go_fast": true,
              "guidance": 3,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "lora_weights": "fofr/flux-80s-cyberpunk",
              "output_format": "webp",
              "output_quality": 80,
              "prompt_strength": 0.8,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/a43wloJrIDpoJpCH81EfhI00PbQrmhpfpUWqCvZPtWEsOvwTA/out-0.webp"
            ],
            "prompt": "style of 80s cyberpunk, a portrait photo"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image mode. The aspect ratio of your output will match this image",
          "prompt": "Prompt for generated image",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16. Note that outputs will not be deterministic when this is enabled, even if you set a seed.",
          "guidance": "Guidance for generated image",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image",
          "hf_api_token": "HuggingFace API token. If you're using a hf lora that needs authentication, you'll need to provide an API token.",
          "lora_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>[/<lora-weights-file.safetensors>], CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet, including signed URLs. For example, 'fofr/flux-pixar-cars'. Civit AI and HuggingFace LoRAs may require an API token to access, which you can provide in the `civitai_api_token` and `hf_api_token` inputs respectively.",
          "output_format": "Format of the output images",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "civitai_api_token": "Civitai API token. If you're using a civitai lora that needs authentication, you'll need to provide an API token.",
          "num_inference_steps": "Number of denoising steps. Recommended range is 28-50, and lower number of steps produce lower quality outputs, faster.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "black-forest-labs/flux-kontext-max",
      "name": "flux-kontext-max",
      "displayName": "flux-kontext-max",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-kontext-max",
      "version": "f72e27297d9c05a36b7fd8faff393d31e3b368543e0bc44bde521886700e166c",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A premium text-based image editing model that delivers maximum performance and improved typography generation for transforming images through natural language prompts",
        "runCount": 3036589,
        "confidence": 0.9,
        "qualityScore": 84.82386157490241,
        "createdAt": "2025-07-24T19:41:26.678917Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/debc1069-7e6b-48a7-a71b-489cc7cf1323/replicate-prediction-np382f6t.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "Make the letters 3D, floating in space on a city street",
              "input_image": "https://replicate.delivery/xezq/XfwWjHJ7HfrmXE6ukuLVEpXWfeQ3PQeRI5mApuLXRxST7XMmC/tmpc91tlq20.png",
              "aspect_ratio": "match_input_image",
              "output_format": "jpg",
              "safety_tolerance": 2
            },
            "output": "https://replicate.delivery/xezq/Mbbd8Tx2YfRYXSEmLgblTzGtj4ZurpgPjLui6jAqfXLasRzUA/tmpkav_ivyd.jpg",
            "prompt": "Make the letters 3D, floating in space on a city street"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Text description of what you want to generate, or the instruction on how to edit the given image.",
          "input_image": "Image to use as reference. Must be jpeg, png, gif, or webp.",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "output_format": "Output format for the generated image",
          "safety_tolerance": "Safety tolerance, 0 is most strict and 6 is most permissive. 2 is currently the maximum allowed when input images are used.",
          "prompt_upsampling": "Automatic prompt improvement"
        }
      }
    },
    {
      "id": "anthropic/claude-3.7-sonnet",
      "name": "claude-3.7-sonnet",
      "displayName": "claude-3.7-sonnet",
      "provider": "replicate",
      "category": "image",
      "endpoint": "anthropic/claude-3.7-sonnet",
      "version": "81a891bd00c339f3565bda15b255b372eb8bf6c669fe996b66eea5d677454a46",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "The most intelligent Claude model and the first hybrid reasoning model on the market (claude-3-7-sonnet-20250219)",
        "runCount": 2337752,
        "confidence": 0.6,
        "qualityScore": 83.68798622991868,
        "createdAt": "2025-02-25T17:00:21.887168Z",
        "owner": "anthropic",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/56aed331-fb30-4e82-9708-b63b2fa90699/claude-3.7-logo.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://www.anthropic.com/legal/consumer-terms",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "Give me a recipe for pancakes that could feed all of California.",
              "max_tokens": 8192,
              "system_prompt": "",
              "max_image_resolution": 0.5
            },
            "output": [
              "#",
              " Colossal California",
              " Pancake",
              " Recipe\n\n## Ingredients",
              "\n- 800",
              " million",
              " cups",
              " all",
              "-purpose flour (",
              "roughly",
              " 100",
              " million",
              " pounds",
              ")\n- 400",
              " million cups",
              " milk",
              " (about",
              " 3",
              ".",
              "2",
              " billion p",
              "ints)\n- ",
              "200 million eggs (",
              "approximately 16.",
              "7 million",
              " dozen",
              ")\n- 40",
              " million cups sugar",
              "\n- 20 million",
              " tabl",
              "espoons baking powder",
              "\n- 10 ",
              "million teaspoons salt",
              "\n- 10",
              " million cups butter,",
              " melted",
              "\n\n## Instructions\n1.",
              " Locate",
              " approximately",
              " 10,",
              "000 industrial",
              "-sized mixing facilities",
              " across",
              " the",
              " state.",
              "\n2. Coordinate",
              " ",
              "100,000 volunteer",
              " mixing",
              " teams.\n3.",
              " Combine",
              " dry",
              " ingredients in massive",
              " containers",
              " using",
              " cement",
              " mixer",
              "-",
              "style",
              " equipment.\n4.",
              " In",
              " separate containers, wh",
              "isk together the",
              " milk",
              " an",
              "d eggs (",
              "perhaps",
              " using fire",
              " hose",
              " systems",
              " for",
              " circulation",
              ").\n5.",
              " Gradually incorporate wet",
              " ingredients into dry ingredients.",
              "\n6. Cook",
              " on",
              " ",
              "500",
              ",000 simultaneously",
              " operating extra",
              "-large griddles.",
              "\n7. Serve",
              " with",
              " approximately",
              " 5",
              " million gallons of",
              " maple syrup.",
              "\n\n## Notes",
              "\n- Cooking",
              " time:",
              " Approximately 3 weeks",
              " with",
              " ",
              "24/7 operation",
              "\n- Woul",
              "d require",
              " borrow",
              "ing industrial",
              " equipment",
              " from multiple",
              " nations",
              "\n- May",
              " cause",
              " maple",
              " syrup shortages worldwide",
              "\n- Environmental",
              " impact statement",
              " pending\n\nWoul",
              "d you like me to calculate",
              " the exact nutrit",
              "ional information",
              " for ",
              "39",
              " million serv",
              "ings?",
              " ",
              "😊"
            ],
            "prompt": "Give me a recipe for pancakes that could feed all of California."
          }
        ],
        "parameterDescriptions": {
          "image": "Optional input image. Images are priced as (width px * height px)/750 input tokens",
          "prompt": "Input prompt",
          "max_tokens": "Maximum number of output tokens",
          "system_prompt": "System prompt",
          "max_image_resolution": "Maximum image resolution in megapixels. Scales down image before sending it to Claude, to save time and money."
        }
      }
    },
    {
      "id": "black-forest-labs/flux-schnell-lora",
      "name": "flux-schnell-lora",
      "displayName": "flux-schnell-lora",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-schnell-lora",
      "version": "83180e3ae073b7f87cd85b8bb649337412fd006d10db49e04ea5e821e87fbeb3",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "The fastest image generation model tailored for fine-tuned use",
        "runCount": 2321869,
        "confidence": 0.6,
        "qualityScore": 83.65837900216013,
        "createdAt": "2025-06-24T22:15:35.545471Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/98c9bf91-5bc0-4a2d-960f-8c3fcd69f1f3/https___replicate.deliver_a20JvIo.png",
        "githubUrl": "https://github.com/replicate/cog-flux",
        "paperUrl": null,
        "licenseUrl": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-schnell",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "a closeup BLKLGHT portrait photo of a cyberpunk",
              "go_fast": true,
              "lora_scale": 0.8,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "lora_weights": "fofr/flux-black-light",
              "output_format": "webp",
              "output_quality": 80,
              "num_inference_steps": 4
            },
            "output": [
              "https://replicate.delivery/xezq/T7gLEVc07aqvBdrWweJanOmMebAX97jUTfQrsLmXPQOvsahnA/out-0.webp"
            ],
            "prompt": "a closeup BLKLGHT portrait photo of a cyberpunk"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Prompt for generated image",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16. Note that outputs will not be deterministic when this is enabled, even if you set a seed.",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image",
          "lora_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "output_format": "Format of the output images",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "num_inference_steps": "Number of denoising steps. 4 is recommended, and lower number of steps produce lower quality outputs, faster.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "black-forest-labs/flux-fill-pro",
      "name": "flux-fill-pro",
      "displayName": "flux-fill-pro",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-fill-pro",
      "version": "10b45d01bb46cffc8d7893b36d720e369d732bb2e48ca3db469a18929eff359d",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Professional inpainting and outpainting model with state-of-the-art performance. Edit or extend images with natural, seamless results.",
        "runCount": 2244446,
        "confidence": 0.9,
        "qualityScore": 83.51109354500736,
        "createdAt": "2025-03-31T12:06:31.217065Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/13571f4b-d677-404f-bff0-ad44da9d5fa0/https___replicate.deli_llwvezd.jpg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://replicate.com/black-forest-labs/flux-fill-pro#license",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "mask": "https://replicate.delivery/pbxt/M0gpLCYdCLbnhcz95Poy66q30XW9VSCN65DoDQ8IzdzlQonw/kill-bill-mask.png",
              "image": "https://replicate.delivery/pbxt/M0gpKVE9wmEtOQFNDOpwz1uGs0u6nK2NcE85IihwlN0ZEnMF/kill-bill-poster.jpg",
              "steps": 50,
              "prompt": "movie poster says \"FLUX FILL\"",
              "guidance": 60,
              "outpaint": "None",
              "output_format": "jpg",
              "safety_tolerance": 2,
              "prompt_upsampling": false
            },
            "output": "https://replicate.delivery/xezq/Hc95qpsbiwK4ARfhuT6RHmEc4x89jS8dFMCdw8uW9iHogLGKA/tmp54g7ws1t.jpg",
            "prompt": "movie poster says \"FLUX FILL\""
          }
        ],
        "parameterDescriptions": {
          "mask": "A black-and-white image that describes the part of the image to inpaint. Black areas will be preserved while white areas will be inpainted. Must have the same size as image. Optional if you provide an alpha mask in the original image. Must be jpeg, png, gif, or webp.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "The image to inpaint. Can contain an alpha mask. Must be jpeg, png, gif, or webp.",
          "steps": "Number of diffusion steps. Higher values yield finer details but increase processing time.",
          "prompt": "Text prompt for image generation",
          "guidance": "Controls the balance between adherence to the text prompt and image quality/diversity. Higher values make the output more closely match the prompt but may reduce overall image quality. Lower values allow for more creative freedom but might produce results less relevant to the prompt.",
          "outpaint": "A quick option for outpainting an input image. Mask will be ignored.",
          "output_format": "Format of the output images.",
          "safety_tolerance": "Safety tolerance, 1 is most strict and 6 is most permissive",
          "prompt_upsampling": "Automatically modify the prompt for more creative generation"
        }
      }
    },
    {
      "id": "deepseek-ai/deepseek-v3",
      "name": "deepseek-v3",
      "displayName": "deepseek-v3",
      "provider": "replicate",
      "category": "image",
      "endpoint": "deepseek-ai/deepseek-v3",
      "version": "5500ea20e92e133d8981dc6f5b820d2eedd9b52f4ab8a856fccd4ddbb992396e",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "DeepSeek-V3-0324 is the leading non-reasoning model, a milestone for open source",
        "runCount": 2204763,
        "confidence": 0.6,
        "qualityScore": 83.43362109004295,
        "createdAt": "2025-03-25T22:55:21.829257Z",
        "owner": "deepseek-ai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/1fb6b760-d41b-4421-94f9-9539fc928fce/deepseek-v3-cover.jpg",
        "githubUrl": "https://github.com/deepseek-ai/DeepSeek-V3",
        "paperUrl": null,
        "licenseUrl": "https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-MODEL",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "top_p": 1,
              "prompt": "What is the speed of an unladen swallow?",
              "max_tokens": 1024,
              "temperature": 0.6,
              "presence_penalty": 0,
              "frequency_penalty": 0
            },
            "output": [
              "",
              "The question",
              " \"",
              "What",
              " is",
              " the",
              " speed",
              " of",
              " an",
              " unl",
              "aden",
              " swallow",
              "?\"",
              " is",
              " famously",
              " from",
              " *",
              "Mont",
              "y",
              " Python",
              " and",
              " the",
              " Holy",
              " Gra",
              "il",
              "*,",
              " where",
              " it",
              "'s",
              " posed",
              " as",
              " a",
              " bridge",
              "keeper",
              "'s",
              " r",
              "iddle",
              ".",
              " \n\n",
              "###",
              " Scientific",
              " Answer",
              ":\n",
              "If",
              " taken",
              " literally",
              ",",
              " the",
              " speed",
              " of",
              " a",
              " swallow",
              " (",
              "a",
              " small",
              " bird",
              ")",
              " depends",
              " on",
              " the",
              " species",
              " and",
              " flight",
              " conditions",
              ".",
              " The",
              " most",
              " commonly",
              " referenced",
              " swallow",
              " in",
              " this",
              " context",
              " is",
              " the",
              " **",
              "European",
              " barn",
              " swallow",
              " (*",
              "H",
              "ir",
              "undo",
              " rust",
              "ica",
              "*)",
              "**,",
              " which",
              " has",
              " an",
              " estimated",
              " cruising",
              " flight",
              " speed",
              " of",
              " around",
              " **",
              "11",
              "–",
              "16",
              " meters",
              " per",
              " second",
              " (",
              "25",
              "–",
              "35",
              " mph",
              " or",
              " ",
              "40",
              "–",
              "55",
              " km",
              "/h",
              ")**",
              " when",
              " un",
              "bur",
              "dened",
              " (",
              "un",
              "l",
              "aden",
              ").",
              " However",
              ",",
              " this",
              " can",
              " vary",
              " based",
              " on",
              " wind",
              " conditions",
              " and",
              " whether",
              " the",
              " bird",
              " is",
              " gl",
              "iding",
              " or",
              " fl",
              "apping",
              ".\n\n",
              "###",
              " Mont",
              "y",
              " Python",
              " Answer",
              ":\n",
              "In",
              " the",
              " film",
              ",",
              " King",
              " Arthur",
              " (",
              "t",
              "rying",
              " to",
              " cross",
              " the",
              " Bridge",
              " of",
              " Death",
              ")",
              " answers",
              ":",
              "  \n",
              "*",
              "\"",
              "What",
              " do",
              " you",
              " mean",
              "?",
              " An",
              " African",
              " or",
              " European",
              " swallow",
              "?\"",
              "*",
              "  \n",
              "The",
              " bridge",
              "keeper",
              " then",
              " conced",
              "es",
              " he",
              " doesn",
              "'t",
              " know",
              " and",
              " is",
              " flung",
              " into",
              " the",
              " ab",
              "yss",
              ".",
              "  \n\n",
              "This",
              " implies",
              " the",
              " joke",
              " is",
              " about",
              " the",
              " absurd",
              " specificity",
              " of",
              " the",
              " question",
              "—",
              "highlight",
              "ing",
              " that",
              " even",
              " a",
              " seemingly",
              " simple",
              " query",
              " can",
              " be",
              " un",
              "answer",
              "able",
              " without",
              " context",
              ".",
              "  \n\n",
              "So",
              ",",
              " for",
              " fun",
              ":",
              "  \n",
              "-",
              " **",
              "European",
              " swallow",
              "**:",
              " ~",
              "11",
              " m",
              "/s",
              " (",
              "as",
              " above",
              ").",
              "  \n",
              "-",
              " **",
              "African",
              " swallow",
              "**:",
              " Hypot",
              "hetically",
              ",",
              " maybe",
              " similar",
              " (",
              "but",
              " no",
              " species",
              " is",
              " explicitly",
              " called",
              " \"",
              "African",
              " swallow",
              "\").",
              "  \n\n",
              "Would",
              " you",
              " like",
              " to",
              " discuss",
              " aer",
              "odynamics",
              " or",
              " coconut",
              " migration",
              " next",
              "?",
              " 🐦",
              "🌴",
              ""
            ],
            "prompt": "What is the speed of an unladen swallow?"
          }
        ],
        "parameterDescriptions": {
          "top_p": "Top-p (nucleus) sampling",
          "prompt": "Prompt",
          "max_tokens": "The maximum number of tokens the model should generate as output.",
          "temperature": "The value used to modulate the next token probabilities.",
          "presence_penalty": "Presence penalty",
          "frequency_penalty": "Frequency penalty"
        }
      }
    },
    {
      "id": "prunaai/flux-schnell",
      "name": "flux-schnell",
      "displayName": "flux-schnell",
      "provider": "replicate",
      "category": "image",
      "endpoint": "prunaai/flux-schnell",
      "version": "8954d56c83d4db1abf8e701e86c5c9faf231e76a7469821428746972ed75fddb",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This is a 3x faster FLUX.1 [schnell] model from Black Forest Labs, optimised with pruna with minimal quality loss. Contact us for more at pruna.ai",
        "runCount": 2131575,
        "confidence": 0.6,
        "qualityScore": 83.28700821755474,
        "createdAt": "2025-07-25T13:21:57.526491Z",
        "owner": "prunaai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/82bdde20-b9e6-4a2a-98cc-bbba982e49d1/flux_schnell.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "prompt": "a cat jumping in the air to catch a bird",
              "speed_mode": "Juiced 🔥 (default)",
              "image_width": 1024,
              "image_height": 1024,
              "output_format": "jpg",
              "guidance_scale": 3.5,
              "output_quality": 80,
              "num_inference_steps": 4
            },
            "output": "https://replicate.delivery/xezq/Tf6XymwBAkzlJqC8fAJfbHx3OVWHajIu7GSuVf5BM4R9EmHTB/output_-1_0.jpeg",
            "prompt": "a cat jumping in the air to catch a bird"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Prompt for generated image",
          "megapixels": "Approximate number of megapixels for generated image",
          "speed_mode": "Run faster predictions with model optimized for speed",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio of the output image",
          "output_format": "Format of the output images",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "num_inference_steps": "Number of denoising steps. 4 is recommended, and lower number of steps produce lower quality outputs, faster."
        }
      }
    },
    {
      "id": "luma/ray-flash-2-540p",
      "name": "ray-flash-2-540p",
      "displayName": "ray-flash-2-540p",
      "provider": "replicate",
      "category": "video",
      "endpoint": "luma/ray-flash-2-540p",
      "version": "b33440c8b44b11f7c09382674db14007cd2488b808fc5472832791ed6947b3fa",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "start_image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate 5s and 9s 540p videos, faster and cheaper than Ray 2",
        "runCount": 47448,
        "confidence": 0.9,
        "qualityScore": 81.76227063990744,
        "createdAt": "2025-07-25T11:44:04.136024Z",
        "owner": "luma",
        "coverImage": "https://replicate.delivery/xezq/vfuqZQoMXX3MfkaUsfoqanFPHaB42R7Mbq7i0bc7H5zX52woA/tmpd2p3nej6.mp4",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://lumalabs.ai/dream-machine/api/terms",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "loop": false,
              "prompt": "A cinematic anime character intimate closeup, she is sitting at a cafe on a busy city street in the morning, drinking coffee, it is cold, a dynamic scene",
              "duration": 5,
              "aspect_ratio": "16:9"
            },
            "output": "https://replicate.delivery/xezq/vfuqZQoMXX3MfkaUsfoqanFPHaB42R7Mbq7i0bc7H5zX52woA/tmpd2p3nej6.mp4",
            "prompt": "A cinematic anime character intimate closeup, she is sitting at a cafe on a busy city street in the morning, drinking coffee, it is cold, a dynamic scene"
          }
        ],
        "parameterDescriptions": {
          "loop": "Whether the video should loop, with the last frame matching the first frame for smooth, continuous playback.",
          "prompt": "Text prompt for video generation",
          "concepts": "List of camera concepts to apply to the video generation. Concepts include: truck_left, pan_right, pedestal_down, low_angle, pedestal_up, selfie, pan_left, roll_right, zoom_in, over_the_shoulder, orbit_right, orbit_left, static, tiny_planet, high_angle, bolt_cam, dolly_zoom, overhead, zoom_out, handheld, roll_left, pov, aerial_drone, push_in, crane_down, truck_right, tilt_down, elevator_doors, tilt_up, ground_level, pull_out, aerial, crane_up, eye_level",
          "duration": "Duration of the video in seconds",
          "end_image": "An optional last frame of the video to use as the ending frame.",
          "start_image": "An optional first frame of the video to use as the starting frame.",
          "aspect_ratio": "Aspect ratio of the generated video",
          "end_image_url": "URL of an image to use as the ending frame",
          "start_image_url": "URL of an image to use as the starting frame"
        }
      }
    },
    {
      "id": "luma/ray",
      "name": "ray",
      "displayName": "ray",
      "provider": "replicate",
      "category": "video",
      "endpoint": "luma/ray",
      "version": "ec16dc44af18758ec1ff7998f5779896f84f5834ea53991d15f65711686a9a79",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "start_image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Fast, high quality text-to-video and image-to-video (Also known as Dream Machine)",
        "runCount": 47213,
        "confidence": 0.9,
        "qualityScore": 81.7407079569366,
        "createdAt": "2025-07-25T11:43:23.064363Z",
        "owner": "luma",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/496f8ab2-3a87-4fe7-9867-5572460c2b5e/ray-cover.webp",
        "githubUrl": null,
        "paperUrl": "https://lumalabs.ai/dream-machine",
        "licenseUrl": "https://lumalabs.ai/dream-machine/api/terms",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "loop": false,
              "prompt": "This video shows the majestic beauty of a waterfall cascading down a cliff into a serene lake. The waterfall, with its powerful flow, is the central focus of the video. The surrounding landscape is lush and green, with trees and foliage adding to the natural beauty of the scene",
              "aspect_ratio": "16:9"
            },
            "output": "https://replicate.delivery/czjl/j9Fz1tqiiK7QFZfQlPKjYxUYcTRx64QGnM4XhUUVdBtIIG9JA/tmpvq1ddzt7.mp4",
            "prompt": "This video shows the majestic beauty of a waterfall cascading down a cliff into a serene lake. The waterfall, with its powerful flow, is the central focus of the video. The surrounding landscape is lush and green, with trees and foliage adding to the natural beauty of the scene"
          }
        ],
        "parameterDescriptions": {
          "loop": "Whether the video should loop, with the last frame matching the first frame for smooth, continuous playback. This input is ignored if end_image_url or end_video_id are set.",
          "prompt": "Text prompt for video generation",
          "end_image": "An optional last frame of the video to use as the ending frame.",
          "start_image": "An optional first frame of the video to use as the starting frame.",
          "aspect_ratio": "Aspect ratio of the video. Ignored if a start frame, end frame or video ID is given.",
          "end_video_id": "Prepend a new video generation to the beginning of an existing one (Also called 'reverse extend'). You can combine this with start_image_url, or start_video_id.",
          "end_image_url": "URL of an image to use as the ending frame",
          "start_video_id": "Continue or extend a video generation with a new generation. You can combine this with end_image_url, or end_video_id.",
          "start_image_url": "URL of an image to use as the starting frame"
        }
      }
    },
    {
      "id": "prunaai/hidream-l1-fast",
      "name": "hidream-l1-fast",
      "displayName": "hidream-l1-fast",
      "provider": "replicate",
      "category": "image",
      "endpoint": "prunaai/hidream-l1-fast",
      "version": "91752cc0b07ccd5976f1db2b6b7f10296ac12d6cb2ba87056f79b17ffacca5f5",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This is an optimised version of the hidream-l1 model using the pruna ai optimisation toolkit!",
        "runCount": 1400732,
        "confidence": 0.6,
        "qualityScore": 81.46355360355386,
        "createdAt": "2025-07-12T10:33:50.929495Z",
        "owner": "prunaai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/3dec7e29-9ca4-4338-ace6-6472d7a06b19/replicate-prediction-ba4msq0t.webp",
        "githubUrl": "https://github.com/HiDream-ai/HiDream-I1",
        "paperUrl": null,
        "licenseUrl": "https://github.com/HiDream-ai/HiDream-I1/blob/main/LICENSE",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "seed": 10,
              "prompt": "a purple cheetah holding a sign that says \"pip install pruna\"",
              "model_type": "fast",
              "resolution": "1024 × 1024 (Square)",
              "speed_mode": "Extra Juiced 🚀 (even more speed)",
              "output_format": "jpg",
              "output_quality": 80
            },
            "output": "https://replicate.delivery/xezq/OALMfA3NE2XrR6CWzm349oQR2KcB1QVfidkzj4jiuLSh0efTB/output_10_0.jpeg",
            "prompt": "a purple cheetah holding a sign that says \"pip install pruna\""
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed (-1 for random)",
          "prompt": "Prompt",
          "model_type": "Model type",
          "resolution": "Output resolution",
          "speed_mode": "Speed optimization level",
          "output_format": "Output format",
          "output_quality": "Output quality (for jpg and webp)"
        }
      }
    },
    {
      "id": "google/imagen-3",
      "name": "imagen-3",
      "displayName": "imagen-3",
      "provider": "replicate",
      "category": "image",
      "endpoint": "google/imagen-3",
      "version": "3e0b477743ff405dc5b77dd73456d7ef96705a9aad479c668d57743ce1d4ca96",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Google's highest quality text-to-image model, capable of generating images with detail, rich lighting and beauty",
        "runCount": 1307002,
        "confidence": 0.9,
        "qualityScore": 81.1627658442978,
        "createdAt": "2025-07-18T15:58:17.023954Z",
        "owner": "google",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/6e164365-9cab-422b-bf05-76d127abe3a2/replicate-prediction-_OX51bG7.webp",
        "githubUrl": null,
        "paperUrl": "https://deepmind.google/technologies/imagen-3/",
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "A close-up, macro photography stock photo of a strawberry intricately sculpted into the shape of a hummingbird in mid-flight, its wings a blur as it sips nectar from a vibrant, tubular flower. The backdrop features a lush, colorful garden with a soft, bokeh effect, creating a dreamlike atmosphere. The image is exceptionally detailed and captured with a shallow depth of field, ensuring a razor-sharp focus on the strawberry-hummingbird and gentle fading of the background. The high resolution, professional photographers style, and soft lighting illuminate the scene in a very detailed manner, professional color grading amplifies the vibrant colors and creates an image with exceptional clarity. The depth of field makes the hummingbird and flower stand out starkly against the bokeh background.",
              "aspect_ratio": "1:1",
              "safety_filter_level": "block_medium_and_above"
            },
            "output": "https://replicate.delivery/xezq/fp7FAY10OsyMcqf80C9YfbnDT9ewjZ5ghuun2Q9CRdiskfihC/tmp6ty8ezoy.png",
            "prompt": "A close-up, macro photography stock photo of a strawberry intricately sculpted into the shape of a hummingbird in mid-flight, its wings a blur as it sips nectar from a vibrant, tubular flower. The backdrop features a lush, colorful garden with a soft, bokeh effect, creating a dreamlike atmosphere. The image is exceptionally detailed and captured with a shallow depth of field, ensuring a razor-sharp focus on the strawberry-hummingbird and gentle fading of the background. The high resolution, professional photographers style, and soft lighting illuminate the scene in a very detailed manner, professional color grading amplifies the vibrant colors and creates an image with exceptional clarity. The depth of field makes the hummingbird and flower stand out starkly against the bokeh background."
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for image generation",
          "aspect_ratio": "Aspect ratio of the generated image",
          "output_format": "Format of the output image",
          "safety_filter_level": "block_low_and_above is strictest, block_medium_and_above blocks some prompts, block_only_high is most permissive but some prompts will still be blocked"
        }
      }
    },
    {
      "id": "bytedance/seededit-3.0",
      "name": "seededit-3.0",
      "displayName": "seededit-3.0",
      "provider": "replicate",
      "category": "image",
      "endpoint": "bytedance/seededit-3.0",
      "version": "36b28026517bfbcfba8a36998498ca73e8d45c513734b83d71d45a9586729ae9",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Text-guided image editing model that preserves original details while making targeted modifications like lighting changes, object removal, and style conversion",
        "runCount": 37287,
        "confidence": 0.9,
        "qualityScore": 80.71569089924529,
        "createdAt": "2025-07-16T17:24:20.792370Z",
        "owner": "bytedance",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/7baed8f1-dce4-4f4a-8a42-83830112a621/replicate-prediction-vpcqhmcw.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/NMwv9XpdfihyolvoSzVf5zH1q7PwxG42KajxyHeHq0ZKJEki/4ccgkq0a6xrm80cpykfszajfaw.png",
              "prompt": "Change the text to \"SEEDEDIT 3 ON REPLICATE\", put her in a garden, she is making the \"ok\" sign with both hands",
              "guidance_scale": 5.5
            },
            "output": "https://replicate.delivery/xezq/ds6T2ezcIzSQRSzrODljh5ncAmuqg2xIsmwrhrpvsLZ86sgKA/tmp90dct5to.jpg",
            "prompt": "Change the text to \"SEEDEDIT 3 ON REPLICATE\", put her in a garden, she is making the \"ok\" sign with both hands"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image to edit",
          "prompt": "Text prompt for image generation",
          "guidance_scale": "Prompt adherence. Higher = more literal."
        }
      }
    },
    {
      "id": "kwaivgi/kling-v1.6-standard",
      "name": "kling-v1.6-standard",
      "displayName": "kling-v1.6-standard",
      "provider": "replicate",
      "category": "video",
      "endpoint": "kwaivgi/kling-v1.6-standard",
      "version": "ad7e130132a2ae0c815fb3a5d31d897530cda5860e5f464f5eef48efd9ee8b4b",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "start_image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate 5s and 10s videos in 720p resolution at 30fps",
        "runCount": 1010649,
        "confidence": 0.9,
        "qualityScore": 80.04600780332984,
        "createdAt": "2025-06-04T11:36:03.419565Z",
        "owner": "kwaivgi",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/5b9d5726-ee87-4881-94e8-71e118d2dd4e/replicate-prediction-_F2jima2.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "a portrait photo of a woman underwater with flowing hair",
              "duration": 5,
              "cfg_scale": 0.5,
              "start_image": "https://replicate.delivery/pbxt/MNRKHnYUu5HjNqEerj2kxWRmUD3xWGaZ0gJmhqVbkra2jCbD/underwater.jpeg",
              "aspect_ratio": "16:9",
              "negative_prompt": ""
            },
            "output": "https://replicate.delivery/czjl/xFIwsxPXTtpCHJw2WqLH3gqACg3csLVVdKtbLf1heBzXiUJUA/tmp35xuh600.mp4",
            "prompt": "a portrait photo of a woman underwater with flowing hair"
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for video generation",
          "duration": "Duration of the video in seconds",
          "cfg_scale": "Flexibility in video generation; The higher the value, the lower the model's degree of flexibility, and the stronger the relevance to the user's prompt.",
          "start_image": "First frame of the video",
          "aspect_ratio": "Aspect ratio of the video. Ignored if start_image is provided.",
          "negative_prompt": "Things you do not want to see in the video",
          "reference_images": "Reference images to use in video generation (up to 4 images). Also known as scene elements."
        }
      }
    },
    {
      "id": "minimax/image-01",
      "name": "image-01",
      "displayName": "image-01",
      "provider": "replicate",
      "category": "image",
      "endpoint": "minimax/image-01",
      "version": "abbfceebd9f32eba5a69624c59fe3d434ed8d8208aa858f9734040062c03d8c9",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Minimax's first image model, with character reference support",
        "runCount": 964518,
        "confidence": 0.6,
        "qualityScore": 79.8431078720425,
        "createdAt": "2025-04-25T09:52:19.696259Z",
        "owner": "minimax",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/926994db-2c8e-4b7d-934f-2f86b2480e55/43b05178-4b2a-42d9-9130-4fedae65.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "A close-up portrait of a leopard with distinctive spotted pattern and intense eyes",
              "aspect_ratio": "3:4",
              "number_of_images": 1,
              "prompt_optimizer": true
            },
            "output": [
              "https://replicate.delivery/xezq/DIW1tQHSNXY2Lhlk22V8fQsEqx5sDfqilWuNbciQTmf1mtpoA/tmpf6p003az.jpeg"
            ],
            "prompt": "A close-up portrait of a leopard with distinctive spotted pattern and intense eyes"
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for generation",
          "aspect_ratio": "Image aspect ratio",
          "number_of_images": "Number of images to generate",
          "prompt_optimizer": "Use prompt optimizer",
          "subject_reference": "An optional character reference image (human face) to use as the subject in the generated image(s)."
        }
      }
    },
    {
      "id": "meta/llama-4-scout-instruct",
      "name": "llama-4-scout-instruct",
      "displayName": "llama-4-scout-instruct",
      "provider": "replicate",
      "category": "image",
      "endpoint": "meta/llama-4-scout-instruct",
      "version": "8137b3975c483beadba5dbb424eb6824248cdc8a6746abbcfafb96886e82965f",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A 17 billion parameter model with 16 experts",
        "runCount": 3025618,
        "confidence": 0.6,
        "qualityScore": 79.80814238751509,
        "createdAt": "2025-04-05T22:51:30.279036Z",
        "owner": "meta",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/a8c11ea4-9b93-4946-b4d8-0f36d6df204c/meta-logo.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://www.llama.com/llama4/license/",
        "pricing": {
          "tier": "premium"
        },
        "examples": [
          {
            "input": {
              "top_p": 1,
              "prompt": "Hello, Llama!",
              "max_tokens": 1024,
              "temperature": 0.6,
              "presence_penalty": 0,
              "frequency_penalty": 0
            },
            "output": [
              "",
              "Hello!",
              " It's nice to meet you",
              ". I'm Llama,",
              " a large language model developed",
              " by Meta. How can",
              " I assist you today?",
              ""
            ],
            "prompt": "Hello, Llama!"
          }
        ],
        "parameterDescriptions": {
          "top_p": "Top-p (nucleus) sampling",
          "prompt": "Prompt",
          "max_tokens": "The maximum number of tokens the model should generate as output.",
          "temperature": "The value used to modulate the next token probabilities.",
          "presence_penalty": "Presence penalty",
          "frequency_penalty": "Frequency penalty"
        }
      }
    },
    {
      "id": "zsxkib/mmaudio",
      "name": "mmaudio",
      "displayName": "mmaudio",
      "provider": "replicate",
      "category": "video",
      "endpoint": "zsxkib/mmaudio",
      "version": "62871fb59889b2d7c13777f08deb3b36bdff88f7e1d53a50ad7694548a41b484",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image",
        "videoUrl": "video"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Add sound to video using the MMAudio V2 model. An advanced AI model that synthesizes high-quality audio from video content, enabling seamless video-to-audio transformation.",
        "runCount": 910153,
        "confidence": 0.9,
        "qualityScore": 79.59114882092149,
        "createdAt": "2025-04-02T11:46:11.438040Z",
        "owner": "zsxkib",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/34262841-19bf-443c-9892-72488fec1ef2/mmaudio-cover.webp",
        "githubUrl": "https://github.com/zsxkib/cog-mmaudio",
        "paperUrl": "https://hkchengrex.github.io/MMAudio",
        "licenseUrl": "https://github.com/hkchengrex/MMAudio#MIT-1-ov-file",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "video": "https://huggingface.co/hkchengrex/MMAudio/resolve/main/examples/sora_galloping.mp4",
              "prompt": "galloping",
              "duration": 8,
              "num_steps": 25,
              "cfg_strength": 4.5,
              "negative_prompt": "music"
            },
            "output": "https://replicate.delivery/xezq/Tckf6OZjDlQ2Q6Zq0RHSfu2S4CHbfSj2YoYtzjxsI3OlCb9oA/20250402_115808.mp4",
            "prompt": "galloping"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Use -1 or leave blank to randomize the seed",
          "image": "Optional image file for image-to-audio generation (experimental)",
          "video": "Optional video file for video-to-audio generation",
          "prompt": "Text prompt for generated audio",
          "duration": "Duration of output in seconds",
          "num_steps": "Number of inference steps",
          "cfg_strength": "Guidance strength (CFG)",
          "negative_prompt": "Negative prompt to avoid certain sounds"
        }
      }
    },
    {
      "id": "ibm-granite/granite-3.3-8b-instruct",
      "name": "granite-3.3-8b-instruct",
      "displayName": "granite-3.3-8b-instruct",
      "provider": "replicate",
      "category": "image",
      "endpoint": "ibm-granite/granite-3.3-8b-instruct",
      "version": "a325a0cacfb0aa9226e6bad1abe5385f1073f4c7f8c36e52ed040e5409e6c034",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Granite-3.3-8B-Instruct is a 8-billion parameter 128K context length language model fine-tuned for improved reasoning and instruction-following capabilities.",
        "runCount": 787641,
        "confidence": 0.6,
        "qualityScore": 78.96328866280084,
        "createdAt": "2025-04-15T16:28:21.615152Z",
        "owner": "ibm-granite",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/81dc0178-9ff8-4869-9c72-cd334450533e/Granite_2D_B_Low_no_Grain.png",
        "githubUrl": "https://github.com/bjhargrave/cog-models/tree/main/ibm-granite/granite-3.3-8b-instruct",
        "paperUrl": null,
        "licenseUrl": "https://www.apache.org/licenses/LICENSE-2.0",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "top_k": 50,
              "top_p": 0.9,
              "prompt": "How is perplexity measured for LLMs and why is it useful?",
              "max_tokens": 512,
              "min_tokens": 0,
              "temperature": 0.6,
              "presence_penalty": 0,
              "frequency_penalty": 0
            },
            "output": [
              "Per",
              "plex",
              "ity",
              " is",
              " a",
              " common",
              " metric",
              " used",
              " to",
              " evaluate",
              " the",
              " performance",
              " of",
              " language",
              " models",
              ",",
              " including",
              " large",
              " language",
              " models",
              " (",
              "LL",
              "Ms",
              ").",
              " It",
              " measures",
              " how",
              " well",
              " a",
              " language",
              " model",
              " predict",
              "s",
              " a",
              " sample",
              ".",
              " A",
              " lower",
              " per",
              "plex",
              "ity",
              " score",
              " indicates",
              " better",
              " performance",
              ",",
              " as",
              " it",
              " suggests",
              " the",
              " model",
              " is",
              " more",
              " conf",
              "ident",
              " in",
              " its",
              " predictions",
              ".",
              "\n",
              "\n",
              "Per",
              "plex",
              "ity",
              " is",
              " calculated",
              " by",
              " raising",
              " ",
              "2",
              " to",
              " the",
              " average",
              " negative",
              " log",
              "-",
              "likelihood",
              " of",
              " the",
              " test",
              " set",
              ".",
              " In",
              " simpler",
              " terms",
              ",",
              " it",
              " quant",
              "ifies",
              " the",
              " uncertainty",
              " of",
              " the",
              " model",
              " in",
              " predict",
              "ing",
              " the",
              " next",
              " word",
              " in",
              " a",
              " sequence",
              ".",
              " A",
              " per",
              "plex",
              "ity",
              " of",
              " ",
              "2",
              "^",
              "n",
              " means",
              " that",
              ",",
              " on",
              " average",
              ",",
              " the",
              " model",
              " is",
              " uncert",
              "ain",
              " about",
              " the",
              " next",
              " word",
              ",",
              " assigning",
              " a",
              " probability",
              " of",
              " ",
              "1",
              "/",
              "n",
              " to",
              " the",
              " correct",
              " word",
              ".",
              "\n",
              "\n",
              "Here",
              "'s",
              " a",
              " step",
              "-",
              "by",
              "-",
              "step",
              " break",
              "down",
              " of",
              " the",
              " calculation",
              ":",
              "\n",
              "\n",
              "1",
              ".",
              " For",
              " each",
              " word",
              " in",
              " the",
              " test",
              " set",
              ",",
              " the",
              " language",
              " model",
              " computes",
              " a",
              " probability",
              " distribution",
              " over",
              " the",
              " vocabulary",
              ",",
              " predict",
              "ing",
              " the",
              " likelihood",
              " of",
              " the",
              " next",
              " word",
              ".",
              "\n",
              "2",
              ".",
              " The",
              " negative",
              " log",
              "arith",
              "m",
              " (",
              "base",
              " ",
              "2",
              ")",
              " of",
              " these",
              " probabilities",
              " is",
              " calculated",
              " for",
              " each",
              " word",
              ".",
              "\n",
              "3",
              ".",
              " The",
              " negative",
              " log",
              "-",
              "likelihood",
              " is",
              " aver",
              "aged",
              " across",
              " all",
              " words",
              " in",
              " the",
              " test",
              " set",
              ".",
              "\n",
              "4",
              ".",
              " ",
              "2",
              " raised",
              " to",
              " the",
              " power",
              " of",
              " this",
              " average",
              " negative",
              " log",
              "-",
              "likelihood",
              " gives",
              " the",
              " per",
              "plex",
              "ity",
              " score",
              ".",
              "\n",
              "\n",
              "Per",
              "plex",
              "ity",
              " is",
              " useful",
              " for",
              " several",
              " reasons",
              ":",
              "\n",
              "\n",
              "1",
              ".",
              " **",
              "Model",
              " comparison",
              "**:",
              " It",
              " allows",
              " for",
              " comparing",
              " different",
              " language",
              " models",
              " or",
              " model",
              " configurations",
              ".",
              " A",
              " model",
              " with",
              " lower",
              " per",
              "plex",
              "ity",
              " on",
              " a",
              " given",
              " test",
              " set",
              " is",
              " generally",
              " considered",
              " to",
              " have",
              " better",
              " performance",
              ".",
              "\n",
              "\n",
              "2",
              ".",
              " **",
              "Training",
              " optimization",
              "**:",
              " Per",
              "plex",
              "ity",
              " can",
              " be",
              " used",
              " as",
              " a",
              " loss",
              " function",
              " during",
              " training",
              ",",
              " guid",
              "ing",
              " the",
              " model",
              " to",
              " minimize",
              " uncertainty",
              " in",
              " its",
              " predictions",
              ".",
              " Lower",
              " per",
              "plex",
              "ity",
              " during",
              " training",
              " indicates",
              " that",
              " the",
              " model",
              " is",
              " learning",
              " to",
              " make",
              " more",
              " accurate",
              " predictions",
              ".",
              "\n",
              "\n",
              "3",
              ".",
              " **",
              "Transfer",
              " learning",
              " and",
              " fine",
              "-",
              "tuning",
              "**:",
              " Per",
              "plex",
              "ity",
              " can",
              " help",
              " assess",
              " the",
              " impact",
              " of",
              " transfer",
              " learning",
              " or",
              " fine",
              "-",
              "tuning",
              " on",
              " pre",
              "-",
              "trained",
              " language",
              " models",
              ".",
              " A",
              " decrease",
              " in",
              " per",
              "plex",
              "ity",
              " after",
              " applying",
              " these",
              " techniques",
              " suggests",
              " improved",
              " performance",
              ".",
              "\n",
              "\n",
              "4",
              ".",
              " **",
              "Under",
              "standing",
              " model",
              " behavior",
              "**:",
              " Per",
              "plex",
              "ity",
              " can",
              " offer",
              " insights",
              " into",
              " how",
              " well",
              " the",
              " model",
              " captures",
              " the",
              " underlying",
              " patterns",
              " and",
              " structures",
              " of",
              " the",
              " language",
              ".",
              "\n",
              "\n",
              "However",
              ",",
              " it",
              "'s",
              " essential",
              " to",
              " consider",
              " the",
              " limitations",
              " of",
              " per",
              "plex",
              "ity",
              ".",
              " It",
              " doesn",
              "'t",
              " always",
              " corre",
              "late",
              " with",
              " human",
              "-",
              "evalu",
              "ated",
              " quality",
              ",",
              " especially",
              " for",
              " specific",
              " tasks",
              " or",
              " domains",
              ".",
              " More",
              "over",
              ",",
              " it",
              " t",
              "ends",
              " to",
              " favor",
              " models",
              " that",
              " assign",
              " very",
              " low",
              " probabilities",
              " to",
              " a",
              " small",
              " subset",
              " of",
              " words",
              ",",
              " which",
              " might",
              " not",
              " necessarily",
              " indicate",
              " better",
              " performance",
              " in",
              " practical",
              " applications",
              ".",
              "\n",
              "\n",
              "In",
              " summary",
              ",",
              " per",
              "plex",
              "ity",
              " is",
              " a",
              " valuable"
            ],
            "prompt": "How is perplexity measured for LLMs and why is it useful?"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Leave blank to randomize the seed.",
          "top_k": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering).",
          "top_p": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751).",
          "prompt": "User prompt to send to the model.",
          "max_tokens": "The maximum number of tokens the model should generate as output.",
          "min_tokens": "The minimum number of tokens the model should generate as output.",
          "temperature": "The value used to modulate the next token probabilities.",
          "chat_template": "A template to format the prompt with. If not provided, the default prompt template will be used.",
          "system_prompt": "System prompt to send to the model.The chat template provides a good default.",
          "stop_sequences": "A comma-separated list of sequences to stop generation at. For example, '<end>,<stop>' will stop generation at the first instance of 'end' or '<stop>'.",
          "presence_penalty": "Presence penalty",
          "frequency_penalty": "Frequency penalty"
        }
      }
    },
    {
      "id": "luma/ray-flash-2-720p",
      "name": "ray-flash-2-720p",
      "displayName": "ray-flash-2-720p",
      "provider": "replicate",
      "category": "video",
      "endpoint": "luma/ray-flash-2-720p",
      "version": "e86901a31ed565509d8f8f755ae3b8327dbbf5980cbbaedc1bb92ba0e8e2240a",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "start_image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate 5s and 9s 720p videos, faster and cheaper than Ray 2",
        "runCount": 24063,
        "confidence": 0.9,
        "qualityScore": 78.81367818911548,
        "createdAt": "2025-07-25T11:52:13.494724Z",
        "owner": "luma",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/05ed2738-a4ed-412e-a4c9-fd2ce48f4e3d/replicate-prediction-af9qsmzk.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://lumalabs.ai/dream-machine/api/terms",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "loop": false,
              "prompt": "A cinematic anime character intimate closeup, she is sitting at a cafe on a busy city street in the morning, it is cold",
              "duration": 5,
              "aspect_ratio": "16:9"
            },
            "output": "https://replicate.delivery/xezq/xexTDQWeTTtwy0ghRl7YVWKSj4WYYzTBEbrP939Q6Qn8MbYUA/tmp_a397eyu.mp4",
            "prompt": "A cinematic anime character intimate closeup, she is sitting at a cafe on a busy city street in the morning, it is cold"
          }
        ],
        "parameterDescriptions": {
          "loop": "Whether the video should loop, with the last frame matching the first frame for smooth, continuous playback.",
          "prompt": "Text prompt for video generation",
          "concepts": "List of camera concepts to apply to the video generation. Concepts include: truck_left, pan_right, pedestal_down, low_angle, pedestal_up, selfie, pan_left, roll_right, zoom_in, over_the_shoulder, orbit_right, orbit_left, static, tiny_planet, high_angle, bolt_cam, dolly_zoom, overhead, zoom_out, handheld, roll_left, pov, aerial_drone, push_in, crane_down, truck_right, tilt_down, elevator_doors, tilt_up, ground_level, pull_out, aerial, crane_up, eye_level",
          "duration": "Duration of the video in seconds",
          "end_image": "An optional last frame of the video to use as the ending frame.",
          "start_image": "An optional first frame of the video to use as the starting frame.",
          "aspect_ratio": "Aspect ratio of the generated video",
          "end_image_url": "URL of an image to use as the ending frame",
          "start_image_url": "URL of an image to use as the starting frame"
        }
      }
    },
    {
      "id": "black-forest-labs/flux-fill-dev",
      "name": "flux-fill-dev",
      "displayName": "flux-fill-dev",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-fill-dev",
      "version": "a053f84125613d83e65328a289e14eb6639e10725c243e8fb0c24128e5573f4c",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Open-weight inpainting model for editing and extending images. Guidance-distilled from FLUX.1 Fill [pro].",
        "runCount": 647630,
        "confidence": 0.6,
        "qualityScore": 78.11327628850199,
        "createdAt": "2025-03-31T18:53:19.541501Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/b109cc9e-f3c2-4899-8428-df46a988c3f0/https___replicate.deliver_tmlMO9j.jpg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "mask": "https://replicate.delivery/pbxt/M0hxLu8a1YBcybWuumSsfoEec8ooer6JZ2fR28vuM1U0CN9m/74b40bb1-364a-461a-bec5-200a38c7bc87.png",
              "image": "https://replicate.delivery/pbxt/M0hxMJeO7wFCMr7QYNZsjRxzHhz6ntlLllMteRQNsRD7f3Nf/flux-fill-dev.webp",
              "prompt": "a spaceship",
              "guidance": 30,
              "num_outputs": 1,
              "output_format": "webp",
              "output_quality": 80,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/XAOCdYKsGYZ9FNTeeEQPbl8DM9eoDf050jLfSAZMuWVYJdZeE/out-0.webp"
            ],
            "prompt": "a spaceship"
          }
        ],
        "parameterDescriptions": {
          "mask": "A black-and-white image that describes the part of the image to inpaint. Black areas will be preserved while white areas will be inpainted.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "The image to inpaint. Can contain alpha mask. If the image width or height are not multiples of 32, they will be scaled to the closest multiple of 32. If the image dimensions don't fit within 1440x1440, it will be scaled down to fit.",
          "prompt": "Prompt for generated image",
          "guidance": "Guidance for generated image",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image. Use match_input to match the size of the input (with an upper limit of 1440x1440 pixels)",
          "num_outputs": "Number of outputs to generate",
          "lora_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "output_format": "Format of the output images",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "num_inference_steps": "Number of denoising steps. Recommended range is 28-50, and lower number of steps produce lower quality outputs, faster.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "nvidia/sana-sprint-1.6b",
      "name": "sana-sprint-1.6b",
      "displayName": "sana-sprint-1.6b",
      "provider": "replicate",
      "category": "image",
      "endpoint": "nvidia/sana-sprint-1.6b",
      "version": "038aee6907b53a5c148780983e39a50ce7cd0747b4e2642e78387f48cf36039a",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "SANA-Sprint: One-Step Diffusion with Continuous-Time Consistency Distillation",
        "runCount": 594728,
        "confidence": 0.9,
        "qualityScore": 77.74319115954978,
        "createdAt": "2025-07-23T22:43:37.694376Z",
        "owner": "nvidia",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/af71dfeb-e2d0-4d1e-9f1f-6254dbaff1d0/replicate-prediction-6nm3tkrd1.jpg",
        "githubUrl": "https://github.com/lucataco/cog-sana-sprint-1.6b",
        "paperUrl": "https://arxiv.org/abs/2503.09641",
        "licenseUrl": "https://github.com/NVlabs/Sana?tab=Apache-2.0-1-ov-file#readme",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "width": 1024,
              "height": 1024,
              "prompt": "a tiny astronaut hatching from an egg on the moon",
              "output_format": "jpg",
              "guidance_scale": 4.5,
              "output_quality": 80,
              "inference_steps": 2,
              "intermediate_timesteps": 1.3
            },
            "output": "https://replicate.delivery/xezq/tbAO9mMLiSKFMVNefs91HKfNwsW6mPLsDm4whM4FoPeMhK6RB/output.jpg",
            "prompt": "a tiny astronaut hatching from an egg on the moon"
          }
        ],
        "parameterDescriptions": {
          "seed": "Seed value. Set to a value less than 0 to randomize the seed",
          "width": "Width of output image",
          "height": "Height of output image",
          "prompt": "Input prompt",
          "output_format": "Format of the output images",
          "guidance_scale": "CFG guidance scale",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "inference_steps": "Number of sampling steps",
          "intermediate_timesteps": "Intermediate timestep value (only used when inference_steps=2, recommended values: 1.0-1.4)"
        }
      }
    },
    {
      "id": "minimax/video-01",
      "name": "video-01",
      "displayName": "video-01",
      "provider": "replicate",
      "category": "video",
      "endpoint": "minimax/video-01",
      "version": "818e219770b9137bc7fcc3c1506a6a21c32bdddbec118c138edb19eee3da3a39",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate 6s videos with prompts or images. (Also known as Hailuo). Use a subject reference to make a video with a character and the S2V-01 model.",
        "runCount": 548663,
        "confidence": 0.9,
        "qualityScore": 77.39306465364183,
        "createdAt": "2025-06-19T11:37:05.182758Z",
        "owner": "minimax",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/b56c831c-4c68-4443-b69e-b71b105afe7f/minimax.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://intl.minimaxi.com/protocol/terms-of-service",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "a woman is walking through a busy Tokyo street at night, she is wearing dark sunglasses",
              "prompt_optimizer": true
            },
            "output": "https://replicate.delivery/xezq/sKwL789E0KrLCZFX8oVqO6dQfP952RZFhuwGRt1cyICzSNcKA/tmppyhy1cg1.mp4",
            "prompt": "a woman is walking through a busy Tokyo street at night, she is wearing dark sunglasses"
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for generation",
          "prompt_optimizer": "Use prompt optimizer",
          "first_frame_image": "First frame image for video generation. The output video will have the same aspect ratio as this image.",
          "subject_reference": "An optional character reference image to use as the subject in the generated video (this will use the S2V-01 model)"
        }
      }
    },
    {
      "id": "ideogram-ai/ideogram-v3-turbo",
      "name": "ideogram-v3-turbo",
      "displayName": "ideogram-v3-turbo",
      "provider": "replicate",
      "category": "image",
      "endpoint": "ideogram-ai/ideogram-v3-turbo",
      "version": "f8a8eb2c75d7d86ec58e3b8309cee63acb437fbab2695bc5004acf64d2de61a7",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Turbo is the fastest and cheapest Ideogram v3. v3 creates images with stunning realism, creative designs, and consistent styles",
        "runCount": 515351,
        "confidence": 0.9,
        "qualityScore": 77.12103965813823,
        "createdAt": "2025-04-30T14:14:19.027379Z",
        "owner": "ideogram-ai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/b55e9f9e-5f43-4cf8-99c8-c33cc8486f23/tmp0s1h52uw-1.webp",
        "githubUrl": null,
        "paperUrl": "https://about.ideogram.ai/3.0",
        "licenseUrl": "https://about.ideogram.ai/legal/api-tos",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "The text \"V3 Turbo\" in the center middle. A color film-inspired portrait of a young man looking to the side with a shallow depth of field that blurs the surrounding elements, drawing attention to his eye. The fine grain and cast suggest a high ISO film stock, while the wide aperture lens creates a motion blur effect, enhancing the candid and natural documentary style.",
              "resolution": "None",
              "style_type": "None",
              "aspect_ratio": "3:2",
              "magic_prompt_option": "Auto"
            },
            "output": "https://replicate.delivery/xezq/WHz71UTYXvrTNNeSSZr8ZW9q6W2MwgbcKiTgqumFpBElwIUKA/tmp0s1h52uw.png",
            "prompt": "The text \"V3 Turbo\" in the center middle. A color film-inspired portrait of a young man looking to the side with a shallow depth of field that blurs the surrounding elements, drawing attention to his eye. The fine grain and cast suggest a high ISO film stock, while the wide aperture lens creates a motion blur effect, enhancing the candid and natural documentary style."
          }
        ],
        "parameterDescriptions": {
          "mask": "A black and white image. Black pixels are inpainted, white pixels are preserved. The mask will be resized to match the image size.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "An image file to use for inpainting. You must also use a mask.",
          "prompt": "Text prompt for image generation",
          "resolution": "Resolution. Overrides aspect ratio. Ignored if an inpainting image is given.",
          "style_type": "The styles help define the specific aesthetic of the image you want to generate.",
          "aspect_ratio": "Aspect ratio. Ignored if a resolution or inpainting image is given.",
          "magic_prompt_option": "Magic Prompt will interpret your prompt and optimize it to maximize variety and quality of the images generated. You can also use it to write prompts in different languages.",
          "style_reference_images": "A list of images to use as style references."
        }
      }
    },
    {
      "id": "black-forest-labs/flux-depth-dev",
      "name": "flux-depth-dev",
      "displayName": "flux-depth-dev",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-depth-dev",
      "version": "fc4f1401056237174d207056c49cd2afd44ede232ba286a3d40eb6376b726600",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Open-weight depth-aware image generation. Edit images while preserving spatial relationships.",
        "runCount": 514777,
        "confidence": 0.6,
        "qualityScore": 77.11619978242521,
        "createdAt": "2025-03-14T23:22:09.198847Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/4cfef8f5-5fcb-413c-bdaa-d6d4f41e5930/flux-depth-dev.jpg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "A tropical beach",
              "guidance": 10,
              "megapixels": "1",
              "num_outputs": 1,
              "control_image": "https://replicate.delivery/pbxt/M0mJ4lphqO0HOGDb7jwYb4nMjmn0fh3joS0PxeQ90TPN0Skb/IMG_2270.jpg",
              "output_format": "webp",
              "output_quality": 80,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/JnlhyMG4GD6uEpGsfoXVG7wc8pIvQ3UtfRRhyef2aXkQQfZeE/out-0.webp"
            ],
            "prompt": "A tropical beach"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Prompt for generated image",
          "guidance": "Guidance for generated image",
          "megapixels": "Approximate number of megapixels for generated image. Use match_input to match the size of the input (with an upper limit of 1440x1440 pixels)",
          "num_outputs": "Number of outputs to generate",
          "control_image": "Image used to control the generation. The depth map will be automatically generated.",
          "output_format": "Format of the output images",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "num_inference_steps": "Number of denoising steps. Recommended range is 28-50, and lower number of steps produce lower quality outputs, faster.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "anthropic/claude-4-sonnet",
      "name": "claude-4-sonnet",
      "displayName": "claude-4-sonnet",
      "provider": "replicate",
      "category": "image",
      "endpoint": "anthropic/claude-4-sonnet",
      "version": "3380fe4ca9cac053c89d1df86a5ba850e61cbef1d474a24abded9516e5a73a04",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Claude Sonnet 4 is a significant upgrade to 3.7, delivering superior coding and reasoning while responding more precisely to your instructions",
        "runCount": 489027,
        "confidence": 0.6,
        "qualityScore": 76.89333725989388,
        "createdAt": "2025-06-13T19:42:14.293392Z",
        "owner": "anthropic",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/a4e07111-b44f-43b1-a346-5be824f64913/9890d1bb39c15c41772af22d2282e.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "Give me a recipe for tasty smashed avocado on sourdough toast that could feed all of California.",
              "max_tokens": 8192,
              "system_prompt": "You are a helpful assistant",
              "max_image_resolution": 0.5
            },
            "output": [
              "Here's a recipe to",
              " feed all of California (about 39",
              " million people)! ",
              "🥑\n\n## California",
              "-Sized Smashed Avoca",
              "do Toast\n\n### Ingredients:\n- **",
              "780 million avocados** (",
              "20 per person - hey, it's California!)",
              "\n- **39 million slices**",
              " of sourdough bread\n- **39",
              " million limes** (ju",
              "iced)\n- **19.",
              "5 million red onions** (f",
              "inely diced)\n- **",
              "390,000 pounds** of sea",
              " salt\n- **195,000 pounds** of",
              " black pepper\n- **39",
              " million Roma tomatoes** (",
              "diced, optional)\n- **19",
              ".5 million jalapeños** (min",
              "ced, for the brave)",
              "\n\n### Instructions:\n1.",
              " Recruit every resident to help prep",
              " (mandatory participation law pending)\n2. Use",
              " the entire Central Valley as your prep",
              " kitchen\n3. Mash av",
              "ocados in swimming pools (cleane",
              "d first, obviously)\n4",
              ". Toast bread using solar power from",
              " the Mojave Desert\n5",
              ". Assembly line from San Diego to the",
              " Oregon border\n6.",
              " Distribute via a fleet of food trucks,",
              " drones, and very patient",
              " pelicans\n\n###",
              " Serving suggestion:\nServe on",
              " the beaches simultaneously at 12 ",
              "PM PT for the ultimate California experience!\n\n**",
              "Estimated cost:** Approximately the",
              " GDP of a small country\n**Prep",
              " time:** 6 months with",
              " full state cooperation\n**Clean",
              "-up time:** We don't talk",
              " about clean-up time",
              "\n\n*Note: May cause a",
              " global avocado shortage an",
              "d significantly impact the housing market (",
              "even more expensive now).*"
            ],
            "prompt": "Give me a recipe for tasty smashed avocado on sourdough toast that could feed all of California."
          }
        ],
        "parameterDescriptions": {
          "image": "Optional input image. Images are priced as (width px * height px)/750 input tokens",
          "prompt": "Input prompt",
          "max_tokens": "Maximum number of output tokens",
          "system_prompt": "System prompt",
          "extended_thinking": "Whether to enable extended thinking mode (only supported for Sonnet 3.7 and Sonnet 4)",
          "max_image_resolution": "Maximum image resolution in megapixels. Scales down image before sending it to Claude, to save time and money.",
          "thinking_budget_tokens": "Maximum number of tokens to use for extended thinking when enabled (only supported for Sonnet 3.7 and Sonnet 4)"
        }
      }
    },
    {
      "id": "prunaai/flux-kontext-dev",
      "name": "flux-kontext-dev",
      "displayName": "flux-kontext-dev",
      "provider": "replicate",
      "category": "image",
      "endpoint": "prunaai/flux-kontext-dev",
      "version": "2f311ad6069d6cb2ec28d46bb0d1da5148a983b56f4f2643d2d775d39d11e44b",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Fast endpoint for Flux Kontext, optimized with pruna framework",
        "runCount": 414114,
        "confidence": 0.6,
        "qualityScore": 76.17120961724896,
        "createdAt": "2025-07-12T18:09:09.025946Z",
        "owner": "prunaai",
        "coverImage": "https://replicate.delivery/xezq/Ka4mxeY02FVTZycyOJ60Wf4FxiKwQOkPTuGMmpdvfMhSHLAqA/output_-1_0.jpeg",
        "githubUrl": "https://github.com/black-forest-labs/flux",
        "paperUrl": "https://blackforestlabs.ai/announcing-black-forest-labs/",
        "licenseUrl": "https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "prompt": "Replace “schnell” by “Kontext” and make the prune blue",
              "guidance": 2.5,
              "image_size": 1024,
              "speed_mode": "Real Time",
              "aspect_ratio": "match_input_image",
              "img_cond_path": "https://replicate.delivery/pbxt/NFoiYQ8DdIEQFepICB7SpZB6mI2HC4xZjiHl9mXFqMhZS9sY/flux_schnell.png",
              "output_format": "jpg",
              "output_quality": 80,
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/xezq/Ka4mxeY02FVTZycyOJ60Wf4FxiKwQOkPTuGMmpdvfMhSHLAqA/output_-1_0.jpeg",
            "prompt": "Replace “schnell” by “Kontext” and make the prune blue"
          }
        ],
        "parameterDescriptions": {
          "seed": "Seed",
          "prompt": "Prompt",
          "guidance": "Guidance scale",
          "image_size": "Base image size (longest side)",
          "speed_mode": "Speed optimization level",
          "aspect_ratio": "Aspect ratio of the output image",
          "img_cond_path": "Input image for image to image mode. The aspect ratio of your output will match this image",
          "output_format": "Output format",
          "output_quality": "Output quality (for jpg and webp)",
          "num_inference_steps": "Number of inference steps"
        }
      }
    },
    {
      "id": "wavespeedai/wan-2.1-i2v-480p",
      "name": "wan-2.1-i2v-480p",
      "displayName": "wan-2.1-i2v-480p",
      "provider": "replicate",
      "category": "video",
      "endpoint": "wavespeedai/wan-2.1-i2v-480p",
      "version": "ae5bc519ee414f255f66c7ac22062e01bbbd6050c04f888d002d5ee0dc087a0c",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Accelerated inference for Wan 2.1 14B image to video, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation.",
        "runCount": 386604,
        "confidence": 0.9,
        "qualityScore": 75.87267466501555,
        "createdAt": "2025-03-27T21:57:39.833164Z",
        "owner": "wavespeedai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/75f0346d-ec4c-4078-bb40-6705578c0d21/replicate-prediction-br080xq9.webp",
        "githubUrl": "https://github.com/Wan-Video/Wan2.1",
        "paperUrl": null,
        "licenseUrl": "https://github.com/Wan-Video/Wan2.1/blob/main/LICENSE.txt",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/MZZyui7brAbh1d2AsyPtgPIByUwzSv6Uou8objC7zXEjLySc/1a8nt7yw5drm80cn05r89mjce0.png",
              "prompt": "A woman is talking",
              "max_area": "832x480",
              "fast_mode": "Balanced",
              "num_frames": 81,
              "sample_shift": 3,
              "sample_steps": 30,
              "frames_per_second": 16,
              "sample_guide_scale": 5
            },
            "output": "https://replicate.delivery/xezq/B08EdKGBIAK8E9rbNTX9jWO9ScVNbFivMaeXZM9ZUb5HAaKKA/output.mp4",
            "prompt": "A woman is talking"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Leave blank for random",
          "image": "Input image to start generating from",
          "prompt": "Prompt for video generation",
          "max_area": "Maximum area of generated image. The input image will shrink to fit these dimensions",
          "fast_mode": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "num_frames": "Number of video frames. 81 frames give the best results",
          "lora_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "sample_shift": "Sample shift factor",
          "sample_steps": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts",
          "frames_per_second": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps",
          "sample_guide_scale": "Higher guide scale makes prompt adherence better, but can reduce variation"
        }
      }
    },
    {
      "id": "ibm-granite/granite-3.2-8b-instruct",
      "name": "granite-3.2-8b-instruct",
      "displayName": "granite-3.2-8b-instruct",
      "provider": "replicate",
      "category": "image",
      "endpoint": "ibm-granite/granite-3.2-8b-instruct",
      "version": "f60c214a9afb10e68da3675b87ffe298afb72ef3eb232e3327d886e6d4a4eaf4",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Granite-3.2-8B-Instruct is a 8-billion parameter 128K context length language model fine-tuned for reasoning and instruction-following capabilities.",
        "runCount": 354365,
        "confidence": 0.6,
        "qualityScore": 75.49452046395791,
        "createdAt": "2025-03-05T23:47:41.115468Z",
        "owner": "ibm-granite",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/8da78269-a1df-41fa-af4c-6d181669cbd7/Granite_2D_B_Low_no_Grain.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://www.apache.org/licenses/LICENSE-2.0",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "top_p": 0.9,
              "prompt": "How is perplexity measured for LLMs and why is it useful?",
              "max_tokens": 512,
              "min_tokens": 0,
              "temperature": 0.6,
              "system_prompt": "You are a helpful assistant.",
              "presence_penalty": 0,
              "frequency_penalty": 0
            },
            "output": [
              "",
              "Per",
              "plex",
              "ity",
              " is",
              " a",
              " common",
              " metric",
              " used",
              " to",
              " evaluate",
              " the",
              " performance",
              " of",
              " language",
              " models",
              ",",
              " including",
              " large",
              " language",
              " models",
              " (",
              "LL",
              "Ms",
              ").",
              " It",
              "'s",
              " a",
              " measure",
              " of",
              " how",
              " well",
              " a",
              " model",
              " predict",
              "s",
              " a",
              " sample",
              ".",
              "\n",
              "\n",
              "Per",
              "plex",
              "ity",
              " is",
              " calculated",
              " based",
              " on",
              " the",
              " concept",
              " of",
              " cross",
              "-",
              "entropy",
              ".",
              " In",
              " simpler",
              " terms",
              ",",
              " it",
              "'s",
              " a",
              " way",
              " to",
              " measure",
              " how",
              " sur",
              "pri",
              "sed",
              " the",
              " model",
              " is",
              " by",
              " the",
              " test",
              " data",
              ".",
              " The",
              " lower",
              " the",
              " per",
              "plex",
              "ity",
              ",",
              " the",
              " less",
              " sur",
              "pri",
              "sed",
              " the",
              " model",
              " is",
              ",",
              " and",
              " the",
              " better",
              " it",
              " predict",
              "s",
              " the",
              " data",
              ".",
              "\n",
              "\n",
              "Here",
              "'s",
              " a",
              " simple",
              " break",
              "down",
              " of",
              " how",
              " it",
              "'s",
              " calculated",
              ":",
              "\n",
              "\n",
              "1",
              ".",
              " The",
              " model",
              " is",
              " given",
              " a",
              " test",
              " set",
              " of",
              " sentences",
              ".",
              "\n",
              "2",
              ".",
              " For",
              " each",
              " word",
              " in",
              " the",
              " sentence",
              ",",
              " the",
              " model",
              " calculates",
              " the",
              " probability",
              " of",
              " that",
              " word",
              " given",
              " all",
              " the",
              " previous",
              " words",
              ".",
              "\n",
              "3",
              ".",
              " The",
              " per",
              "plex",
              "ity",
              " is",
              " then",
              " the",
              " inverse",
              " probability",
              " of",
              " the",
              " entire",
              " sentence",
              ",",
              " aver",
              "aged",
              " over",
              " the",
              " whole",
              " test",
              " set",
              ".",
              "\n",
              "\n",
              "The",
              " formula",
              " for",
              " per",
              "plex",
              "ity",
              " (",
              "PP",
              ")",
              " is",
              ":",
              "\n",
              "\n",
              "PP",
              "(",
              "W",
              ")",
              " =",
              " exp",
              "(-",
              "1",
              "/",
              "N",
              " *",
              "",
              " Σ",
              " log",
              " P",
              "(",
              "wi",
              "|",
              "w",
              "1",
              "...",
              "wi",
              "-",
              "1",
              "))",
              "\n",
              "\n",
              "Where",
              ":",
              "\n",
              "-",
              " W",
              " is",
              " the",
              " test",
              " set",
              " of",
              " sentences",
              ",",
              "\n",
              "-",
              " N",
              " is",
              " the",
              " number",
              " of",
              " words",
              " in",
              " the",
              " test",
              " set",
              ",",
              "\n",
              "-",
              " wi",
              " is",
              " each",
              " word",
              " in",
              " the",
              " test",
              " set",
              ",",
              "\n",
              "-",
              " P",
              "(",
              "wi",
              "|",
              "w",
              "1",
              "...",
              "wi",
              "-",
              "1",
              ")",
              " is",
              " the",
              " probability",
              " assigned",
              " by",
              " the",
              " model",
              " to",
              " word",
              " wi",
              " given",
              " the",
              " previous",
              " words",
              ".",
              "\n",
              "\n",
              "Per",
              "plex",
              "ity",
              " is",
              " useful",
              " for",
              " several",
              " reasons",
              ":",
              "\n",
              "\n",
              "1",
              ".",
              " **",
              "Model",
              " Comparison",
              "**:",
              " It",
              " provides",
              " a",
              " standard",
              " way",
              " to",
              " compare",
              " different",
              " models",
              ".",
              " A",
              " lower",
              " per",
              "plex",
              "ity",
              " score",
              " generally",
              " indicates",
              " a",
              " better",
              " model",
              ".",
              "\n",
              "\n",
              "2",
              ".",
              " **",
              "Model",
              " Impro",
              "vement",
              "**:",
              " It",
              " helps",
              " in",
              " identifying",
              " areas",
              " where",
              " the",
              " model",
              " is",
              " strug",
              "gling",
              ".",
              " If",
              " a",
              " certain",
              " type",
              " of",
              " sentence",
              " or",
              " vocabulary",
              " consistently",
              " results",
              " in",
              " high",
              " per",
              "plex",
              "ity",
              ",",
              " it",
              " indicates",
              " a",
              " weak",
              "ness",
              " in",
              " the",
              " model",
              " that",
              " can",
              " be",
              " addressed",
              " through",
              " further",
              " training",
              " or",
              " adjust",
              "ments",
              ".",
              "\n",
              "\n",
              "3",
              ".",
              " **",
              "Under",
              "standing",
              " Model",
              " Behavior",
              "**:",
              " It",
              " gives",
              " insights",
              " into",
              " how",
              " the",
              " model",
              " understand",
              "s",
              " language",
              ".",
              " A",
              " lower",
              " per",
              "plex",
              "ity",
              " suggests",
              " the",
              " model",
              " has",
              " a",
              " better",
              " gr",
              "asp",
              " of",
              " the",
              " language",
              "'s",
              " structure",
              " and",
              " usage",
              ".",
              "\n",
              "\n",
              "4",
              ".",
              " **",
              "Evaluation",
              " of",
              " Un",
              "seen",
              " Data",
              "**:",
              " While",
              " it",
              "'s",
              " trained",
              " on",
              " a",
              " specific",
              " corpus",
              ",",
              " per",
              "plex",
              "ity",
              " can",
              " be",
              " calculated",
              " on",
              " un",
              "seen",
              " data",
              " to",
              " evaluate",
              " the",
              " model",
              "'s",
              " general",
              "ization",
              " capability",
              ".",
              "\n",
              "\n",
              "However",
              ",",
              " it",
              "'s",
              " important",
              " to",
              " note",
              " that",
              " while",
              " per",
              "plex",
              "ity",
              " is",
              " a",
              " widely",
              " used",
              " metric",
              ",",
              " it",
              "'s",
              " not",
              " without",
              " its",
              " limitations",
              ".",
              " For",
              " instance",
              ",",
              " it",
              " doesn",
              "'t",
              " directly",
              " corre",
              "late",
              " with",
              " human",
              " jud",
              "gment",
              " of",
              " fl",
              "u",
              "ency",
              " or",
              " co",
              "her",
              "ence",
              ",",
              " and"
            ],
            "prompt": "How is perplexity measured for LLMs and why is it useful?"
          }
        ],
        "parameterDescriptions": {
          "top_k": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering).",
          "top_p": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751).",
          "prompt": "Prompt",
          "max_tokens": "The maximum number of tokens the model should generate as output.",
          "min_tokens": "The minimum number of tokens the model should generate as output.",
          "temperature": "The value used to modulate the next token probabilities.",
          "system_prompt": "System prompt to send to the model. This is prepended to the prompt and helps guide system behavior. Ignored for non-chat models.",
          "stop_sequences": "A comma-separated list of sequences to stop generation at. For example, '<end>,<stop>' will stop generation at the first instance of 'end' or '<stop>'.",
          "presence_penalty": "Presence penalty",
          "frequency_penalty": "Frequency penalty"
        }
      }
    },
    {
      "id": "ideogram-ai/ideogram-v3-quality",
      "name": "ideogram-v3-quality",
      "displayName": "ideogram-v3-quality",
      "provider": "replicate",
      "category": "image",
      "endpoint": "ideogram-ai/ideogram-v3-quality",
      "version": "7a0ab9aed1a1a37b9857e3c4e684e499b9200270ba717449e69fc10940a2831c",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "The highest quality Ideogram v3 model. v3 creates images with stunning realism, creative designs, and consistent styles",
        "runCount": 318786,
        "confidence": 0.9,
        "qualityScore": 75.03500602738566,
        "createdAt": "2025-04-30T14:13:50.653237Z",
        "owner": "ideogram-ai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/f285d3d6-40bb-4f15-aa82-c163e33c6000/tmpx4azqibw.webp",
        "githubUrl": null,
        "paperUrl": "https://about.ideogram.ai/3.0",
        "licenseUrl": "https://about.ideogram.ai/legal/api-tos",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "The text \"V3 Quality\" in the center middle. A color film-inspired portrait of a young woman with a shallow depth of field that blurs the surrounding elements, drawing attention to the eye. The fine grain and cast suggest a high ISO film stock, while the wide aperture lens creates a pleasing bokeh effect, enhancing the candid and natural documentary style.",
              "resolution": "None",
              "style_type": "None",
              "aspect_ratio": "3:2",
              "magic_prompt_option": "Off"
            },
            "output": "https://replicate.delivery/xezq/dKCu2YZQCjoSB9S4ugKlBfYF8SkRDZG2Tq5y6S1fw2lKfiQpA/tmpx4azqibw.png",
            "prompt": "The text \"V3 Quality\" in the center middle. A color film-inspired portrait of a young woman with a shallow depth of field that blurs the surrounding elements, drawing attention to the eye. The fine grain and cast suggest a high ISO film stock, while the wide aperture lens creates a pleasing bokeh effect, enhancing the candid and natural documentary style."
          }
        ],
        "parameterDescriptions": {
          "mask": "A black and white image. Black pixels are inpainted, white pixels are preserved. The mask will be resized to match the image size.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "An image file to use for inpainting. You must also use a mask.",
          "prompt": "Text prompt for image generation",
          "resolution": "Resolution. Overrides aspect ratio. Ignored if an inpainting image is given.",
          "style_type": "The styles help define the specific aesthetic of the image you want to generate.",
          "aspect_ratio": "Aspect ratio. Ignored if a resolution or inpainting image is given.",
          "magic_prompt_option": "Magic Prompt will interpret your prompt and optimize it to maximize variety and quality of the images generated. You can also use it to write prompts in different languages.",
          "style_reference_images": "A list of images to use as style references."
        }
      }
    },
    {
      "id": "black-forest-labs/flux-canny-pro",
      "name": "flux-canny-pro",
      "displayName": "flux-canny-pro",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-canny-pro",
      "version": "3e03126bd3fbb9349783930f4139eb6c488aef2197c4d3fd2a826b35ccecea3d",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Professional edge-guided image generation. Control structure and composition using Canny edge detection",
        "runCount": 311905,
        "confidence": 0.9,
        "qualityScore": 74.9402372917147,
        "createdAt": "2025-03-31T11:24:06.268912Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/4c07cacc-d206-4587-9357-8e4e81cd761a/https___replicate.deli_lsMxQWe.jpg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://replicate.com/black-forest-labs/flux-canny-pro#license",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "steps": 28,
              "prompt": "a photo of a car on a city street",
              "guidance": 25,
              "control_image": "https://replicate.delivery/pbxt/M0j11UQhwUWoxUQ9hJCOaALsAHTeoPZcGGtUf6n3BJxtKHul/output-14.webp",
              "output_format": "jpg",
              "safety_tolerance": 2,
              "prompt_upsampling": false
            },
            "output": "https://replicate.delivery/czjl/yRS3V6IYC877GF3DnejR0WJvcz5eg6LTlbE3cJPC6CJQqMzTA/tmp8gs0wfw3.jpg",
            "prompt": "a photo of a car on a city street"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "steps": "Number of diffusion steps. Higher values yield finer details but increase processing time.",
          "prompt": "Text prompt for image generation",
          "guidance": "Controls the balance between adherence to the text as well as image prompt and image quality/diversity. Higher values make the output more closely match the prompt but may reduce overall image quality. Lower values allow for more creative freedom but might produce results less relevant to the prompt.",
          "control_image": "Image to use as control input. Must be jpeg, png, gif, or webp.",
          "output_format": "Format of the output images.",
          "safety_tolerance": "Safety tolerance, 1 is most strict and 6 is most permissive",
          "prompt_upsampling": "Automatically modify the prompt for more creative generation"
        }
      }
    },
    {
      "id": "google/imagen-3-fast",
      "name": "imagen-3-fast",
      "displayName": "imagen-3-fast",
      "provider": "replicate",
      "category": "image",
      "endpoint": "google/imagen-3-fast",
      "version": "5125f62df7e6d1ccb0ce5ac60f141646486c0cb74a2e3d9e8b63ed486c48313e",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A faster and cheaper Imagen 3 model, for when price or speed are more important than final image quality",
        "runCount": 277721,
        "confidence": 0.9,
        "qualityScore": 74.43610284144059,
        "createdAt": "2025-07-18T15:59:08.133921Z",
        "owner": "google",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/980d64f7-991a-4610-9e94-1a59d1482329/tmpuxt6kt2a.webp",
        "githubUrl": null,
        "paperUrl": "https://deepmind.google/technologies/imagen-3/",
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "Bullet train cutting through cherry blossom petals at dusk, creating a vortex of pink and white. The polished silver exterior reflects the setting sun in a continuous streak of fire. Station lights blend into a single continuous line as the train cleaves through space. The world outside the windows is nothing but beautiful motion blur.",
              "aspect_ratio": "16:9",
              "safety_filter_level": "block_medium_and_above"
            },
            "output": "https://replicate.delivery/xezq/BsWBsl2clpLSGJLy4m4Gyce5cXU1aSO22xbmq4sWcf6k5kMUA/tmpuxt6kt2a.png",
            "prompt": "Bullet train cutting through cherry blossom petals at dusk, creating a vortex of pink and white. The polished silver exterior reflects the setting sun in a continuous streak of fire. Station lights blend into a single continuous line as the train cleaves through space. The world outside the windows is nothing but beautiful motion blur."
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for image generation",
          "aspect_ratio": "Aspect ratio of the generated image",
          "output_format": "Format of the output image",
          "safety_filter_level": "block_low_and_above is strictest, block_medium_and_above blocks some prompts, block_only_high is most permissive but some prompts will still be blocked"
        }
      }
    },
    {
      "id": "openai/gpt-4.1-mini",
      "name": "gpt-4.1-mini",
      "displayName": "gpt-4.1-mini",
      "provider": "replicate",
      "category": "image",
      "endpoint": "openai/gpt-4.1-mini",
      "version": "dc3524b86587bdb0b3a922f21e6b0078b194a7ad525c5d15db968b1c71090591",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Fast, affordable version of GPT-4.1",
        "runCount": 795966,
        "confidence": 0.6,
        "qualityScore": 74.00895062693715,
        "createdAt": "2025-06-23T21:19:49.520225Z",
        "owner": "openai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/6f1609f1-ba45-4513-bfd6-7dfcb95efad8/Screenshot_2025-05-01_at_12.03.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://openai.com/policies/",
        "pricing": {
          "tier": "premium"
        },
        "examples": [
          {
            "input": {
              "prompt": "Explain this image in excruciating detail",
              "image_input": [
                "https://replicate.delivery/pbxt/MvoFggJfmpSOBa0TiiQbvxLc0eS7u6CpH2WHaq30FZCVIvFa/test.jpg"
              ],
              "temperature": 1,
              "system_prompt": "You are a helpful assistant."
            },
            "output": "This image depicts a digital painting of two individuals sitting on yellow chairs facing each other. The style of the artwork has a highly textured and brushstroke-rich appearance, giving it a classic oil painting effect.\n\nThe person on the left is an older man with distinctive features resembling the iconic image of Albert Einstein. He has white, wild, and voluminous hair that flows back from his head, along with a white mustache. His skin is light with detailed wrinkles, suggesting age. He wears dark aviator-style sunglasses that cover his eyes. His outfit consists of a black or dark charcoal jacket over a grey shirt. His posture is relaxed yet engaged; he is sitting with his legs crossed and his hands intertwined in front of him, leaning slightly forward as if involved in a deep conversation.\n\nOpposite him, on the right, is a young woman also wearing sunglasses; hers are larger, black, and have a fashionable cat-eye shape. Her hair is long, light brown, and pulled back into a high ponytail secured with a black hair tie, revealing her neck and ears adorned with small pearl earrings. She wears a modern sporty outfit: a fitted black sleeveless crop top with white, red, and green horizontal stripes below the bust, showcasing her midriff, paired with high-waisted black leggings. Her makeup is notable with vivid red lipstick and subtle blush on her cheeks, enhancing her poised facial expression. Her body language is attentive, sitting upright with one arm resting on her leg, facing the man directly as if listening intently or engaged in serious discussion.\n\nThe background is muted, a gradient of soft, light greyish and beige tones with smooth texture and faint brush marks, which ensures the vibrant yellow chairs and the figures stand out prominently. The contrast between the elderly man dressed in classic, somber tones and the young woman in trendy athletic wear suggests a dialogue across generations or a fusion of intellect and modernity.\n\nOverall, the image conveys an intimate, intense moment of exchange, blending timelessness with contemporary style, framed in a polished painterly technique that enhances the emotional depth and character of each subject.",
            "prompt": "Explain this image in excruciating detail"
          }
        ],
        "parameterDescriptions": {
          "top_p": "Nucleus sampling parameter - the model considers the results of the tokens with top_p probability mass. (0.1 means only the tokens comprising the top 10% probability mass are considered.)",
          "prompt": "The prompt to send to the model. Do not use if using messages.",
          "image_input": "List of images to send to the model",
          "temperature": "Sampling temperature between 0 and 2",
          "system_prompt": "System prompt to set the assistant's behavior",
          "presence_penalty": "Presence penalty parameter - positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.",
          "frequency_penalty": "Frequency penalty parameter - positive values penalize the repetition of tokens.",
          "max_completion_tokens": "Maximum number of completion tokens to generate"
        }
      }
    },
    {
      "id": "meta/llama-4-maverick-instruct",
      "name": "llama-4-maverick-instruct",
      "displayName": "llama-4-maverick-instruct",
      "provider": "replicate",
      "category": "image",
      "endpoint": "meta/llama-4-maverick-instruct",
      "version": "25bdfe11f52b557ade65599fad30b1a6f6d87ede91043974bbd320d6a4c1c841",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A 17 billion parameter model with 128 experts",
        "runCount": 770886,
        "confidence": 0.6,
        "qualityScore": 73.86990721925,
        "createdAt": "2025-04-05T23:08:53.570217Z",
        "owner": "meta",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/98360ab9-dce0-4404-89ea-33aac8976393/meta-logo.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://www.llama.com/llama4/license/",
        "pricing": {
          "tier": "premium"
        },
        "examples": [
          {
            "input": {
              "top_p": 1,
              "prompt": "Hello, Llama!",
              "max_tokens": 1024,
              "temperature": 0.6,
              "presence_penalty": 0,
              "frequency_penalty": 0
            },
            "output": [
              "",
              "Hello!",
              " It's nice to meet you.",
              " Is there something I can help",
              " you with or would you like",
              " to chat?",
              ""
            ],
            "prompt": "Hello, Llama!"
          }
        ],
        "parameterDescriptions": {
          "top_p": "Top-p (nucleus) sampling",
          "prompt": "Prompt",
          "max_tokens": "The maximum number of tokens the model should generate as output.",
          "temperature": "The value used to modulate the next token probabilities.",
          "presence_penalty": "Presence penalty",
          "frequency_penalty": "Frequency penalty"
        }
      }
    },
    {
      "id": "black-forest-labs/flux-depth-pro",
      "name": "flux-depth-pro",
      "displayName": "flux-depth-pro",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-depth-pro",
      "version": "2adc354795b24c0f2cb51b7f0e2915f790fbb02463042ea434a8815971bcfa8d",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Professional depth-aware image generation. Edit images while preserving spatial relationships.",
        "runCount": 217035,
        "confidence": 0.9,
        "qualityScore": 73.36531776726929,
        "createdAt": "2025-06-03T10:34:47.297088Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/e365ecff-4023-49f8-96ba-abd710c4bdd9/https___replicate.deliver_xWYu8lC.jpg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://replicate.com/black-forest-labs/flux-depth-pro#license",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "steps": 50,
              "prompt": "abstract 3D render with the word \"DEPTH\"",
              "guidance": 7,
              "control_image": "https://replicate.delivery/pbxt/M0ivr5QCMktmdUi3t0TFrKtw3DSPenPTU5NAOEKjTfW98HaB/https___replicate.delivery_czjl_z4gE33oPjuLPB91f9eO5Np4zaqwm20UYPOZhjpTfXRJVzYmnA_tmppi3by3z7.jpg",
              "output_format": "jpg",
              "safety_tolerance": 2,
              "prompt_upsampling": false
            },
            "output": "https://replicate.delivery/czjl/YmnJr3uJFwaLHpyE2YQZEsGD6DsN3h6opElksQJ4UUzUJz8E/tmp_zp5p3b2.jpg",
            "prompt": "abstract 3D render with the word \"DEPTH\""
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "steps": "Number of diffusion steps. Higher values yield finer details but increase processing time.",
          "prompt": "Text prompt for image generation",
          "guidance": "Controls the balance between adherence to the text as well as image prompt and image quality/diversity. Higher values make the output more closely match the prompt but may reduce overall image quality. Lower values allow for more creative freedom but might produce results less relevant to the prompt.",
          "control_image": "Image to use as control input. Must be jpeg, png, gif, or webp.",
          "output_format": "Format of the output images.",
          "safety_tolerance": "Safety tolerance, 1 is most strict and 6 is most permissive",
          "prompt_upsampling": "Automatically modify the prompt for more creative generation"
        }
      }
    },
    {
      "id": "kwaivgi/kling-v2.1",
      "name": "kling-v2.1",
      "displayName": "kling-v2.1",
      "provider": "replicate",
      "category": "video",
      "endpoint": "kwaivgi/kling-v2.1",
      "version": "97da1f6c1fae926420a16b3c538b778f7fc317b8a16b3750f6bc39b106747793",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "start_image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Use Kling v2.1 to generate 5s and 10s videos in 720p and 1080p resolution from a starting image (image-to-video)",
        "runCount": 199217,
        "confidence": 0.9,
        "qualityScore": 72.99328575792018,
        "createdAt": "2025-06-19T18:53:08.467206Z",
        "owner": "kwaivgi",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/a7690882-d1d2-44fb-b487-f41bd367adcf/replicate-prediction-2epyczsz.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "mode": "standard",
              "prompt": "a woman takes her hands out her pockets and gestures to the words with both hands, she is excited, behind her it is raining",
              "duration": 5,
              "start_image": "https://replicate.delivery/xezq/rfKExHkg7L2UAyYNJj3p1YrW1M3ZROTQQXupJSOyM5RkwQcKA/tmpowaafuyw.png",
              "negative_prompt": ""
            },
            "output": "https://replicate.delivery/xezq/yitkxodvCK7eJK9BFufsMBaHIfnHgJhlNNIiaQi8g8QebGiTB/tmpby0sgn7w.mp4",
            "prompt": "a woman takes her hands out her pockets and gestures to the words with both hands, she is excited, behind her it is raining"
          }
        ],
        "parameterDescriptions": {
          "mode": "Standard has a resolution of 720p, pro is 1080p. Both are 24fps.",
          "prompt": "Text prompt for video generation",
          "duration": "Duration of the video in seconds",
          "start_image": "First frame of the video. You must use a start image with kling-v2.1.",
          "negative_prompt": "Things you do not want to see in the video"
        }
      }
    },
    {
      "id": "usamaehsan/flux-multi-controlnet",
      "name": "flux-multi-controlnet",
      "displayName": "flux-multi-controlnet",
      "provider": "replicate",
      "category": "image",
      "endpoint": "usamaehsan/flux-multi-controlnet",
      "version": "40d4c564c30ce12f3d0ebd17584b8460bb61572caf96e7cab1f8d3cf038bbc15",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Fast FLUX DEV -> Flux Controlnet Canny, Controlnet Depth , Controlnet Line Art, Controlnet Upscaler - You can use just one controlnet or All - LORAs: HyperFlex LoRA , Add Details LoRA , Realism LoRA",
        "runCount": 190600,
        "confidence": 0.9,
        "qualityScore": 72.80125174861294,
        "createdAt": "2025-04-04T18:08:40.482312Z",
        "owner": "usamaehsan",
        "coverImage": "https://replicate.delivery/pbxt/GMmnCZwaIf1WCCqjz9I2Ge8PzWwzYiWGNqgf9lDDBBL7AqTnA/output.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "seed": 55,
              "steps": 8,
              "prompt": "A girl in city, 25 years old, cool, futuristic",
              "widthh": 0,
              "heightt": 0,
              "control_image": "https://replicate.delivery/pbxt/LqdGuSlst5YSQdRgZtOpl6l5ngRBnc4V6SeJ14WszN0km2K4/ComfyUI_00001_.webp",
              "guidance_scale": 3.5,
              "controlnet_type": "canny",
              "control_strength": 0.6,
              "realism_lora_weight": 0,
              "hyperflex_lora_weight": 0.125,
              "add_details_lora_weight": 0
            },
            "output": "https://replicate.delivery/pbxt/GMmnCZwaIf1WCCqjz9I2Ge8PzWwzYiWGNqgf9lDDBBL7AqTnA/output.png",
            "prompt": "A girl in city, 25 years old, cool, futuristic"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducibility",
          "image": "Input image for inpainting",
          "steps": "Number of denoising steps",
          "prompt": "The text prompt that guides image generation",
          "widthh": "Output image width in pixels",
          "heightt": "Output image height in pixels",
          "strength": "Strength of inpainting (how much to repaint masked area)",
          "auto_mask": "Whether to use automatic masking",
          "mask_image": "Mask image for inpainting (white pixels will be repainted)",
          "canny_image": "Input image for Canny ControlNet",
          "depth_image": "Input image for Depth ControlNet",
          "lineart_image": "Input image for Lineart ControlNet",
          "canny_strength": "Strength for Canny ControlNet",
          "depth_strength": "Strength for Depth ControlNet",
          "guidance_scale": "Controls how closely the image follows the prompt",
          "pm_lora_weight": "Weight of sparklers-visual-effect LoRA",
          "upscaler_image": "Input image for Upscaler ControlNet",
          "negative_prompt": "The negative text prompt that guides image generation",
          "auto_mask_prompt": "Text prompt for automatic object detection and masking",
          "ip_adapter_image": "Reference image for IP Adapter",
          "ip_adapter_scale": "Scale of influence for IP Adapter",
          "lineart_strength": "Strength for Lineart ControlNet",
          "padding_mask_crop": "Size of padding when cropping the mask",
          "upscaler_strength": "Strength for Upscaler ControlNet",
          "consis_lora_weight": "Weight of sparklers-visual-effect LoRA",
          "ip_adapter_image_2": "Second reference image for IP Adapter",
          "ip_adapter_image_3": "Third reference image for IP Adapter",
          "ip_adapter_scale_2": "Scale of influence for second IP Adapter image",
          "ip_adapter_scale_3": "Scale of influence for third IP Adapter image",
          "canny_detector_type": "Detector type to use with Canny ControlNet",
          "depth_detector_type": "Detector type to use with Depth ControlNet",
          "realism_lora_weight": "Weight of the Realism LoRA adaptation",
          "use_background_mask": "Whether to use background mask instead of object mask",
          "control_guidance_end": "Percentage of steps at which ControlNet stops applying",
          "ppt_templates_weight": "Weight of ppt-templates LoRA",
          "couple_profile_weight": "Weight of couple-profile LoRA",
          "hyperflex_lora_weight": "Weight of the HyperFlex LoRA adaptation",
          "lineart_detector_type": "Detector type to use with Lineart ControlNet",
          "control_guidance_start": "Percentage of steps at which ControlNet starts applying",
          "home_decoration_weight": "Weight of home-decoration LoRA",
          "add_details_lora_weight": "Weight of the Add Details LoRA adaptation",
          "auto_mask_box_threshold": "Box threshold for automatic masking",
          "use_weighted_embeddings": "Whether to use weighted text embeddings",
          "auto_mask_text_threshold": "Text threshold for automatic masking",
          "migrationloracloth_weight": "Weight of sparklers-visual-effect LoRA",
          "negative_ip_adapter_image": "Negative reference image for IP Adapter",
          "negative_ip_adapter_scale": "Scale of influence for negative IP Adapter image",
          "portrait_photography_weight": "Weight of portrait-photography LoRA",
          "portrait_illustration_weight": "Weight of portrait-illustration LoRA",
          "visual_identity_design_weight": "Weight of visual-identity-design LoRA"
        }
      }
    },
    {
      "id": "recraft-ai/recraft-v3-svg",
      "name": "recraft-v3-svg",
      "displayName": "recraft-v3-svg",
      "provider": "replicate",
      "category": "image",
      "endpoint": "recraft-ai/recraft-v3-svg",
      "version": "81deed12bf1c7e762e46f53df3f85b4369abf876b1df1777ce795e0d7d5849e4",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Recraft V3 SVG (code-named red_panda) is a text-to-image model with the ability to generate high quality SVG images including logotypes, and icons. The model supports a wide list of styles.",
        "runCount": 186582,
        "confidence": 0.6,
        "qualityScore": 72.7087207165848,
        "createdAt": "2025-03-24T10:33:30.343659Z",
        "owner": "recraft-ai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/223c73a9-0347-4daa-9710-3878f95479e3/svg-cover.webp",
        "githubUrl": null,
        "paperUrl": "https://recraft.ai",
        "licenseUrl": "https://recraft.ai/terms",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "size": "1024x1024",
              "style": "any",
              "prompt": "a portrait of a cute red panda using a laptop, the poster has the title \"Red panda is Recraft v3\", against a red background"
            },
            "output": "https://replicate.delivery/czjl/eo0lNdtlDq0DLayETXSyBEwxMRKxoBPfaKKEW0sLvKhe6JYnA/output.svg",
            "prompt": "a portrait of a cute red panda using a laptop, the poster has the title \"Red panda is Recraft v3\", against a red background"
          }
        ],
        "parameterDescriptions": {
          "size": "Width and height of the generated image. Size is ignored if an aspect ratio is set.",
          "style": "Style of the generated image.",
          "prompt": "Text prompt for image generation",
          "aspect_ratio": "Aspect ratio of the generated image"
        }
      }
    },
    {
      "id": "wavespeedai/wan-2.1-t2v-480p",
      "name": "wan-2.1-t2v-480p",
      "displayName": "wan-2.1-t2v-480p",
      "provider": "replicate",
      "category": "video",
      "endpoint": "wavespeedai/wan-2.1-t2v-480p",
      "version": "067897beabcf7ff30fe6b10dc9f99eeebd2b4d6fdab52eb08d3b47d7116dfa19",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Accelerated inference for Wan 2.1 14B text to video, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation.",
        "runCount": 169883,
        "confidence": 0.9,
        "qualityScore": 72.30152478110236,
        "createdAt": "2025-03-27T21:57:51.941562Z",
        "owner": "wavespeedai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/38089c83-8e9f-44e9-aa22-ed6918c85f09/replicate-prediction-vagx41q1.webp",
        "githubUrl": "https://github.com/Wan-Video/Wan2.1",
        "paperUrl": null,
        "licenseUrl": "https://github.com/Wan-Video/Wan2.1/blob/main/LICENSE.txt",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "A cat is doing an acrobatic dive into a swimming pool at the olympics, from a 10m high diving board, flips and spins",
              "fast_mode": "Balanced",
              "num_frames": 81,
              "aspect_ratio": "16:9",
              "sample_shift": 5,
              "sample_steps": 30,
              "frames_per_second": 16,
              "sample_guide_scale": 5
            },
            "output": "https://replicate.delivery/xezq/1Cr8exFBJ9X5BqOvabmkoxe5eHC2FFE6GDlw8Xva064yAopoA/output.mp4",
            "prompt": "A cat is doing an acrobatic dive into a swimming pool at the olympics, from a 10m high diving board, flips and spins"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Leave blank for random",
          "prompt": "Prompt for video generation",
          "fast_mode": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "num_frames": "Number of video frames. 81 frames give the best results",
          "aspect_ratio": "Aspect ratio of video. 16:9 corresponds to 832x480px, and 9:16 is 480x832px",
          "lora_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "sample_shift": "Sample shift factor",
          "sample_steps": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts",
          "frames_per_second": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps",
          "sample_guide_scale": "Higher guide scale makes prompt adherence better, but can reduce variation"
        }
      }
    },
    {
      "id": "danila013/ghibli-easycontrol",
      "name": "ghibli-easycontrol",
      "displayName": "ghibli-easycontrol",
      "provider": "replicate",
      "category": "image",
      "endpoint": "danila013/ghibli-easycontrol",
      "version": "6c4785d791d08ec65ff2ca5e9a7a0c2b0ac4e07ffadfb367231aa16bc7a52cbb",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Ghiblify your image – ChatGPT-level quality, 10× faster and cheaper.",
        "runCount": 168420,
        "confidence": 0.9,
        "qualityScore": 72.2639624165003,
        "createdAt": "2025-04-17T16:29:00.596384Z",
        "owner": "danila013",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/14341a9d-0387-4ecb-abfc-9d9920f0a3ca/ghibli.jpg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "prompt": "Ghibli Studio style, Charming hand-drawn anime-style illustration",
              "input_image": "https://replicate.delivery/pbxt/MqtnzqdpB6rxXM7nzTecxEV3ROQopNhwpHDIIrDVgQAxdTLf/pexels-augustocarneirojr-30861477.jpg",
              "lora_weight": 1,
              "guidance_scale": 3.5,
              "num_inference_steps": 25
            },
            "output": "https://replicate.delivery/xezq/UHNfsza3JWz0cCe2O0meG7DblpTbHjfdXwE7Y4m7iRvFykOSB/3428c51c-ddb0-46f0-8ec9-012f8524fd46.png",
            "prompt": "Ghibli Studio style, Charming hand-drawn anime-style illustration"
          }
        ],
        "parameterDescriptions": {
          "seed": "Seed for reproducibility. -1 for random.",
          "prompt": "Prompt for the image generation. Include trigger words 'Ghibli Studio style, Charming hand-drawn anime-style illustration'",
          "input_image": "Input image to apply Ghibli style to.",
          "lora_weight": "Weight for the Ghibli LoRA",
          "guidance_scale": "Guidance scale",
          "num_inference_steps": "Number of inference steps"
        }
      }
    },
    {
      "id": "google/imagen-4-fast",
      "name": "imagen-4-fast",
      "displayName": "imagen-4-fast",
      "provider": "replicate",
      "category": "image",
      "endpoint": "google/imagen-4-fast",
      "version": "0e0b2d7a428011274e5b3ba10fc7b77d3603371c4ec86fb3cbd3cdfdca49e0d4",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Use this fast version of Imagen 4 when speed and cost are more important than quality",
        "runCount": 156992,
        "confidence": 0.9,
        "qualityScore": 71.95880288529314,
        "createdAt": "2025-07-18T16:20:52.260816Z",
        "owner": "google",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/73c5af65-f578-4113-b62c-2a56971cff2f/replicate-prediction-trmpwr78.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "The photo: Create a cinematic, photorealistic medium shot capturing the dynamic energy of a high-octane action film. The focus is a young woman with wind-swept dark hair streaked with pink highlights and determined features, looking directly and intently into the camera lens, she is slightly off-center. She wears a fitted pink and gold racing jacket over a black tank top with \"Imagen 4 Fast\" in motion-stylized lettering and on the next line \"on Replicate\" emblazoned across the chest and aviator sunglasses pushed up on her head. The lighting is dramatic with motion blur streaks and neon reflections from passing city lights, creating dynamic lens flares and light trails (they do not cover her face). The background shows a blurred urban nightscape with streaking car headlights and illuminated skyscrapers rushing past, rendered with heavy motion blur and shallow depth of field. High contrast lighting, vibrant neon color palette with deep blues and electric yellows, and razor-sharp focus on her intense eyes enhance the fast-paced, electrifying atmosphere. She is illuminated while the background is darker.",
              "aspect_ratio": "4:3",
              "output_format": "jpg",
              "safety_filter_level": "block_only_high"
            },
            "output": "https://replicate.delivery/xezq/iKriMK0zXbbiNRr6WgOJtchWTXTEf9SD62XlFUpdxA3r6CbKA/tmp_2u2189v.jpg",
            "prompt": "The photo: Create a cinematic, photorealistic medium shot capturing the dynamic energy of a high-octane action film. The focus is a young woman with wind-swept dark hair streaked with pink highlights and determined features, looking directly and intently into the camera lens, she is slightly off-center. She wears a fitted pink and gold racing jacket over a black tank top with \"Imagen 4 Fast\" in motion-stylized lettering and on the next line \"on Replicate\" emblazoned across the chest and aviator sunglasses pushed up on her head. The lighting is dramatic with motion blur streaks and neon reflections from passing city lights, creating dynamic lens flares and light trails (they do not cover her face). The background shows a blurred urban nightscape with streaking car headlights and illuminated skyscrapers rushing past, rendered with heavy motion blur and shallow depth of field. High contrast lighting, vibrant neon color palette with deep blues and electric yellows, and razor-sharp focus on her intense eyes enhance the fast-paced, electrifying atmosphere. She is illuminated while the background is darker."
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for image generation",
          "aspect_ratio": "Aspect ratio of the generated image",
          "output_format": "Format of the output image",
          "safety_filter_level": "block_low_and_above is strictest, block_medium_and_above blocks some prompts, block_only_high is most permissive but some prompts will still be blocked"
        }
      }
    },
    {
      "id": "google/imagen-4-ultra",
      "name": "imagen-4-ultra",
      "displayName": "imagen-4-ultra",
      "provider": "replicate",
      "category": "image",
      "endpoint": "google/imagen-4-ultra",
      "version": "eb08b03f79ebc3d4b2542baacca07cc1e0729d24ed1730945555409f0ee30e1a",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Use this ultra version of Imagen 4 when quality matters more than speed and cost",
        "runCount": 155231,
        "confidence": 0.9,
        "qualityScore": 71.9098125294597,
        "createdAt": "2025-07-18T16:04:27.980951Z",
        "owner": "google",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/de4e6a23-fc3a-46cd-9001-23d395228ce7/replicate-prediction-2rhm6xx1.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "The photo: Create a cinematic, photorealistic medium shot capturing the nostalgic warmth of a mid-2000s indie film. The focus is a young woman with a sleek, straight bob haircut in cool platinum white with freckled skin, looking directly and intently into the camera lens with a knowing smirk, her head is looking up slightly. She wears an oversized band t-shirt that says \"Imagen 4 Ultra on Replicate\" in huge stylized text over a long-sleeved striped top and simple silver stud earrings. The lighting is soft, golden hour sunlight creating lens flare and illuminating dust motes in the air. The background shows a blurred outdoor urban setting with graffiti-covered walls (the graffiti says \"ultra\" in stylized graffiti lettering), rendered with a shallow depth of field. Natural film grain, a warm, slightly muted color palette, and sharp focus on her expressive eyes enhance the intimate, authentic feel",
              "aspect_ratio": "16:9",
              "output_format": "jpg",
              "safety_filter_level": "block_only_high"
            },
            "output": "https://replicate.delivery/xezq/eAsULzF8tzzXVSUtp7rvlDPqEkePBcLeTTWnqsSaCKYRtLspA/tmpikc6119g.jpg",
            "prompt": "The photo: Create a cinematic, photorealistic medium shot capturing the nostalgic warmth of a mid-2000s indie film. The focus is a young woman with a sleek, straight bob haircut in cool platinum white with freckled skin, looking directly and intently into the camera lens with a knowing smirk, her head is looking up slightly. She wears an oversized band t-shirt that says \"Imagen 4 Ultra on Replicate\" in huge stylized text over a long-sleeved striped top and simple silver stud earrings. The lighting is soft, golden hour sunlight creating lens flare and illuminating dust motes in the air. The background shows a blurred outdoor urban setting with graffiti-covered walls (the graffiti says \"ultra\" in stylized graffiti lettering), rendered with a shallow depth of field. Natural film grain, a warm, slightly muted color palette, and sharp focus on her expressive eyes enhance the intimate, authentic feel"
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for image generation",
          "aspect_ratio": "Aspect ratio of the generated image",
          "output_format": "Format of the output image",
          "safety_filter_level": "block_low_and_above is strictest, block_medium_and_above blocks some prompts, block_only_high is most permissive but some prompts will still be blocked"
        }
      }
    },
    {
      "id": "luma/reframe-video",
      "name": "reframe-video",
      "displayName": "reframe-video",
      "provider": "replicate",
      "category": "video",
      "endpoint": "luma/reframe-video",
      "version": "1db9ab79fd3b1f494e99446d9916a2408f64636ac571669192e4e18908d08224",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "videoUrl": "video"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Change the aspect ratio of any video up to 30 seconds long, outputs will be 720p",
        "runCount": 4696,
        "confidence": 0.9,
        "qualityScore": 71.7182056018325,
        "createdAt": "2025-07-25T11:49:19.654170Z",
        "owner": "luma",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/a3d9c60a-0a0b-4907-980d-275483b78a45/replicate-prediction-j6fp3jym.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "A woman is standing in a room as part of a podcast show",
              "video_url": "https://replicate.delivery/pbxt/NAOh1kWFGdaSfwvwYzE7eIKypI9JB5rBs0kAb1HVeGDmmNtg/A_podcast_show_202506111026_uikpa.mp4",
              "aspect_ratio": "9:16"
            },
            "output": "https://replicate.delivery/xezq/KSUvcJrFAHJ0IhsvD8eew2AvOesvFl85CqLfzjaMiaBfMfbNF/tmp5e959bwx.mp4",
            "prompt": "A woman is standing in a room as part of a podcast show"
          }
        ],
        "parameterDescriptions": {
          "video": "The video to reframe. Maximum video duration is 10 seconds.",
          "x_end": "The x end of the crop bounds, in pixels. Defines the right boundary where your source will be placed in the output frame. The distance between x_start and x_end determines the resized width of your content.",
          "y_end": "The y end of the crop bounds, in pixels. Defines the bottom boundary where your source will be placed in the output frame. The distance between y_start and y_end determines the resized height of your content.",
          "prompt": "A prompt to guide the reframing generation",
          "x_start": "The x start of the crop bounds, in pixels. Defines the left boundary where your source will be placed in the output frame. The distance between x_start and x_end determines the resized width of your content.",
          "y_start": "The y start of the crop bounds, in pixels. Defines the top boundary where your source will be placed in the output frame. The distance between y_start and y_end determines the resized height of your content.",
          "video_url": "URL of the video to reframe. Maximum video duration is 10 seconds.",
          "aspect_ratio": "Aspect ratio of the output",
          "grid_position_x": "The x position of the input in the grid, in pixels. Controls horizontal positioning of the source within the target output dimensions.",
          "grid_position_y": "The y position of the input in the grid, in pixels. Controls vertical positioning of the source within the target output dimensions."
        }
      }
    },
    {
      "id": "luma/reframe-image",
      "name": "reframe-image",
      "displayName": "reframe-image",
      "provider": "replicate",
      "category": "image",
      "endpoint": "luma/reframe-image",
      "version": "3f2552db20b9bde9ec89d06a2c2a58e0f41ad84093f8fadedfe1360598c769ab",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Change the aspect ratio of any photo using AI (not cropping)",
        "runCount": 4606,
        "confidence": 0.9,
        "qualityScore": 71.6341821225268,
        "createdAt": "2025-07-25T11:50:24.865554Z",
        "owner": "luma",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/6718c188-d6a3-4572-953c-bd5455c359ca/tmp5_8g7kz2.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "An explosion",
              "image_url": "https://replicate.delivery/czjl/6iZ89qakg74mCVjFYeDk0GljoYQReoV0k7WwSjxXmCLcV53TA/tmpyf9dx02r.jpg",
              "aspect_ratio": "9:16"
            },
            "output": "https://replicate.delivery/xezq/bt872wxjx6bebi4U0Hh96ryqTpb31fhzceDUffmPVTPfnxiNF/tmpkcgr1ze5.jpg",
            "prompt": "An explosion"
          }
        ],
        "parameterDescriptions": {
          "image": "The image to reframe",
          "model": "The model to use for the reframe generation",
          "x_end": "The x end of the crop bounds, in pixels. Defines the right boundary where your source will be placed in the output frame. The distance between x_start and x_end determines the resized width of your content.",
          "y_end": "The y end of the crop bounds, in pixels. Defines the bottom boundary where your source will be placed in the output frame. The distance between y_start and y_end determines the resized height of your content.",
          "prompt": "A prompt to guide the reframing generation",
          "x_start": "The x start of the crop bounds, in pixels. Defines the left boundary where your source will be placed in the output frame. The distance between x_start and x_end determines the resized width of your content.",
          "y_start": "The y start of the crop bounds, in pixels. Defines the top boundary where your source will be placed in the output frame. The distance between y_start and y_end determines the resized height of your content.",
          "image_url": "URL of the image to reframe",
          "aspect_ratio": "Aspect ratio of the output",
          "grid_position_x": "The x position of the input in the grid, in pixels. Controls horizontal positioning of the source within the target output dimensions.",
          "grid_position_y": "The y position of the input in the grid, in pixels. Controls vertical positioning of the source within the target output dimensions."
        }
      }
    },
    {
      "id": "minimax/video-01-live",
      "name": "video-01-live",
      "displayName": "video-01-live",
      "provider": "replicate",
      "category": "video",
      "endpoint": "minimax/video-01-live",
      "version": "b3fd893b518666a710738c15185940144fce6987432a31768a8e0ffba7f3359b",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "An image-to-video (I2V) model specifically trained for Live2D and general animation use cases",
        "runCount": 141009,
        "confidence": 0.9,
        "qualityScore": 71.49249912590281,
        "createdAt": "2025-06-19T11:35:43.335756Z",
        "owner": "minimax",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/c202ad97-edd0-40b6-afaf-c99d71398d44/video-01-live-cover.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://intl.minimaxi.com/protocol/terms-of-service",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "a man is talking angrily",
              "prompt_optimizer": true,
              "first_frame_image": "https://replicate.delivery/pbxt/M9jlcXgeaypBr2yQYGf9JXgxUCJWRt8ODUDvt90UWPUsQBXC/back-to-the-future.png"
            },
            "output": "https://replicate.delivery/czjl/sbnhNsfxliTKUaSGhr5C2gfLQzfVY2eiIRn7YB9J927pKRuPB/tmp0t22y4g9.output.mp4",
            "prompt": "a man is talking angrily"
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for generation",
          "prompt_optimizer": "Use prompt optimizer",
          "first_frame_image": "First frame image for video generation. The output video will have the same aspect ratio as this image."
        }
      }
    },
    {
      "id": "openai/dall-e-3",
      "name": "dall-e-3",
      "displayName": "dall-e-3",
      "provider": "replicate",
      "category": "image",
      "endpoint": "openai/dall-e-3",
      "version": "2d47bab50154749d1faa149db2be73bc68701a0a96a040a6437be005ea786d8a",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "An AI system that can create realistic images and art from a description in natural language.",
        "runCount": 3970,
        "confidence": 0.6,
        "qualityScore": 70.98899887063882,
        "createdAt": "2025-07-18T11:12:51.400722Z",
        "owner": "openai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/ba533833-d3a4-401d-8db6-cca1c85bf764/Screenshot_2025-05-12_at_1.31.02P.png",
        "githubUrl": null,
        "paperUrl": "https://cdn.openai.com/papers/dall-e-3.pdf",
        "licenseUrl": "https://openai.com/index/dall-e-3/",
        "pricing": {
          "tier": "premium"
        },
        "examples": [
          {
            "input": {
              "n": 1,
              "size": "1024x1024",
              "style": "vivid",
              "prompt": "astronaut riding a rainbow unicorn",
              "quality": "hd"
            },
            "output": [
              "https://replicate.delivery/czjl/boV0OIH5dl4oEdPQDD8fK6RFlJb8i4p6aVpXOc38NWEBFUnJA/out-0.png"
            ],
            "prompt": "astronaut riding a rainbow unicorn"
          }
        ],
        "parameterDescriptions": {
          "style": "The style of the generated images",
          "prompt": "A text description of the desired image",
          "aspect_ratio": "The aspect ratio of the generated image"
        }
      }
    },
    {
      "id": "google/veo-3",
      "name": "veo-3",
      "displayName": "veo-3",
      "provider": "replicate",
      "category": "video",
      "endpoint": "google/veo-3",
      "version": "aa61b11710dc016f1f292a41808c94dadf23f549ccaf6755a852c491c6edc248",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Sound on: Google’s flagship Veo 3 text to video model, with audio",
        "runCount": 123975,
        "confidence": 0.9,
        "qualityScore": 70.93337620030141,
        "createdAt": "2025-07-18T15:54:54.830074Z",
        "owner": "google",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/0ca4ee69-0f6e-4dc8-9dc6-3063b97b0a50/replicate-prediction-whcj9787.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "A breaking news ident, followed by a TV news presenter excitedly telling us: We interrupt this programme to bring you some breaking news... Veo 3 is now live on Replicate. Then she shouts: Let's go!\n\nThe TV presenter is an epic and cool punk with pink and green hair and a t-shirt that says \"Veo 3 on Replicate\""
            },
            "output": "https://replicate.delivery/xezq/lZfr3rskBEVLDCytear4lUo92fOpAcoblFWzk6e06WEnC3PTB/tmpny051d_c.mp4",
            "prompt": "A breaking news ident, followed by a TV news presenter excitedly telling us: We interrupt this programme to bring you some breaking news... Veo 3 is now live on Replicate. Then she shouts: Let's go!\n\nThe TV presenter is an epic and cool punk with pink and green hair and a t-shirt that says \"Veo 3 on Replicate\""
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Omit for random generations",
          "prompt": "Text prompt for video generation",
          "negative_prompt": "Description of what to discourage in the generated video"
        }
      }
    },
    {
      "id": "black-forest-labs/flux-canny-dev",
      "name": "flux-canny-dev",
      "displayName": "flux-canny-dev",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-canny-dev",
      "version": "aeb2a8dbfe2580e25d41d8881cc1df1a0b1e52c87de99c1a65fc587ac3918179",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Open-weight edge-guided image generation. Control structure and composition using Canny edge detection.",
        "runCount": 123425,
        "confidence": 0.6,
        "qualityScore": 70.91406654568681,
        "createdAt": "2025-03-14T23:18:59.531971Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/788cf228-ae38-473a-a992-1e650aab0519/flux-canny-dev.jpg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "A red vintage convertible driving through an old town",
              "guidance": 30,
              "megapixels": "1",
              "num_outputs": 1,
              "control_image": "https://replicate.delivery/pbxt/M0mUcvKOwNSS4axvv7LAngBAR5Iuv2GsIcnSKdpQRJA62f8G/Screenshot%202024-11-21%20at%2016.08.20.png",
              "output_format": "webp",
              "output_quality": 80,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/4bt5HoegzYR9EKqv70zsBoHnhFkcaB9Yk1naaQJai6rtfPzTA/out-0.webp"
            ],
            "prompt": "A red vintage convertible driving through an old town"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Prompt for generated image",
          "guidance": "Guidance for generated image",
          "megapixels": "Approximate number of megapixels for generated image. Use match_input to match the size of the input (with an upper limit of 1440x1440 pixels)",
          "num_outputs": "Number of outputs to generate",
          "control_image": "Image used to control the generation. The canny edge detection will be automatically generated.",
          "output_format": "Format of the output images",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "num_inference_steps": "Number of denoising steps. Recommended range is 28-50, and lower number of steps produce lower quality outputs, faster.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "ideogram-ai/ideogram-v3-balanced",
      "name": "ideogram-v3-balanced",
      "displayName": "ideogram-v3-balanced",
      "provider": "replicate",
      "category": "image",
      "endpoint": "ideogram-ai/ideogram-v3-balanced",
      "version": "e78d8251b33015f3d743e83e8631b6cf53fed99057e4ddbaa6ee52340b4c2910",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Balance speed, quality and cost. Ideogram v3 creates images with stunning realism, creative designs, and consistent styles",
        "runCount": 118846,
        "confidence": 0.9,
        "qualityScore": 70.74988223507282,
        "createdAt": "2025-04-30T14:14:41.656185Z",
        "owner": "ideogram-ai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/efc494c7-8e1b-4127-9e95-9e5376f7eb78/tmphco6mpqu.webp",
        "githubUrl": null,
        "paperUrl": "https://about.ideogram.ai/3.0",
        "licenseUrl": "https://about.ideogram.ai/legal/api-tos",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "The text \"V3 Balanced\" in the center middle. A color film-inspired portrait of a young man and a young woman looking at each other, a shallow depth of field that blurs the surrounding elements, drawing attention to their eyes. The fine grain and cast suggest a high ISO film stock, while the wide aperture lens creates a pleasing bokeh effect, enhancing the candid and natural documentary style.",
              "resolution": "None",
              "style_type": "None",
              "aspect_ratio": "3:2",
              "magic_prompt_option": "Auto"
            },
            "output": "https://replicate.delivery/xezq/lAJSBuWxfIyQGa23NBQSrPMeTEmfsi1GCApyu4fDGDo4UGhSB/tmphco6mpqu.png",
            "prompt": "The text \"V3 Balanced\" in the center middle. A color film-inspired portrait of a young man and a young woman looking at each other, a shallow depth of field that blurs the surrounding elements, drawing attention to their eyes. The fine grain and cast suggest a high ISO film stock, while the wide aperture lens creates a pleasing bokeh effect, enhancing the candid and natural documentary style."
          }
        ],
        "parameterDescriptions": {
          "mask": "A black and white image. Black pixels are inpainted, white pixels are preserved. The mask will be resized to match the image size.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "An image file to use for inpainting. You must also use a mask.",
          "prompt": "Text prompt for image generation",
          "resolution": "Resolution. Overrides aspect ratio. Ignored if an inpainting image is given.",
          "style_type": "The styles help define the specific aesthetic of the image you want to generate.",
          "aspect_ratio": "Aspect ratio. Ignored if a resolution or inpainting image is given.",
          "magic_prompt_option": "Magic Prompt will interpret your prompt and optimize it to maximize variety and quality of the images generated. You can also use it to write prompts in different languages.",
          "style_reference_images": "A list of images to use as style references."
        }
      }
    },
    {
      "id": "ibm-granite/granite-vision-3.2-2b",
      "name": "granite-vision-3.2-2b",
      "displayName": "granite-vision-3.2-2b",
      "provider": "replicate",
      "category": "image",
      "endpoint": "ibm-granite/granite-vision-3.2-2b",
      "version": "2dd748835ec71ee87ec3f6d7d63aff63b276f0cf903c5afcaf57f9f3ca99d7a8",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Granite-Vision-3.2-2B is a compact and efficient vision-language model, specifically designed for visual document understanding.",
        "runCount": 108585,
        "confidence": 0.6,
        "qualityScore": 70.35773835246519,
        "createdAt": "2025-03-05T23:46:47.977930Z",
        "owner": "ibm-granite",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/c9456432-451f-40e7-8807-04016195fbf5/Granite_2D_B_Low_no_Grain.png",
        "githubUrl": null,
        "paperUrl": "https://arxiv.org/abs/2502.09927",
        "licenseUrl": "https://www.apache.org/licenses/LICENSE-2.0",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "image": "https://upload.wikimedia.org/wikipedia/commons/e/e1/FullMoon2010.jpg",
              "top_p": 0.9,
              "prompt": "Describe this image",
              "max_tokens": 512,
              "temperature": 0.6,
              "system_prompt": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions."
            },
            "output": [
              "",
              "The",
              " image",
              " de",
              "pict",
              "s",
              " a",
              " detailed",
              " view",
              " of",
              " the",
              " Mo",
              "on",
              ",",
              " show",
              "c",
              "asing",
              " its",
              " surface",
              " with",
              " remark",
              "able",
              " cl",
              "arity",
              " and",
              " detail",
              ".",
              " The",
              " Mo",
              "on",
              " appears",
              " to",
              " be",
              " captured",
              " in",
              " a",
              " black",
              "-",
              "and",
              "-",
              "white",
              " photo",
              "graph",
              ",",
              " which",
              " en",
              "h",
              "ances",
              " the",
              " contrast",
              " between",
              " the",
              " l",
              "un",
              "ar",
              " surface",
              " and",
              " the",
              " dark",
              " background",
              ".",
              " The",
              " l",
              "un",
              "ar",
              " surface",
              " is",
              " dotted",
              " with",
              " numero",
              "us",
              " cr",
              "aters",
              ",",
              " which",
              " are",
              " small",
              ",",
              " circular",
              " de",
              "press",
              "ions",
              " formed",
              " by",
              " me",
              "teor",
              "ite",
              " impact",
              "s",
              ".",
              " These",
              " cr",
              "aters",
              " vary",
              " in",
              " size",
              ",",
              " with",
              " some",
              " being",
              " relatively",
              " small",
              " and",
              " others",
              " significantly",
              " larger",
              ".",
              "\n",
              "\n",
              "The",
              " central",
              " region",
              " of",
              " the",
              " Mo",
              "on",
              " ex",
              "hib",
              "its",
              " a",
              " distinct",
              " bright",
              " spot",
              ",",
              " known",
              " as",
              " the",
              " \"",
              "dark",
              " side",
              "\"",
              " or",
              " \"",
              "far",
              " side",
              ",\"",
              " which",
              " is",
              " not",
              " illum",
              "inated",
              " by",
              " the",
              " Sun",
              ".",
              " This",
              " dark",
              " area",
              " is",
              " due",
              " to",
              " the",
              " Mo",
              "on",
              "'s",
              " lack",
              " of",
              " a",
              " global",
              " magnetic",
              " field",
              ",",
              " which",
              " means",
              " it",
              " does",
              " not",
              " have",
              " a",
              " strong",
              " magnetic",
              " field",
              " to",
              " def",
              "lect",
              " solar",
              " wind",
              " and",
              " cos",
              "mic",
              " rad",
              "iation",
              ".",
              " The",
              " bright",
              " side",
              " of",
              " the",
              " Mo",
              "on",
              ",",
              " on",
              " the",
              " other",
              " hand",
              ",",
              " is",
              " bright",
              "ly",
              " illum",
              "inated",
              " by",
              " the",
              " Sun",
              ",",
              " creating",
              " a",
              " st",
              "ark",
              " contrast",
              " between",
              " the",
              " lit",
              " and",
              " shadow",
              "ed",
              " areas",
              ".",
              "\n",
              "\n",
              "The",
              " Mo",
              "on",
              "'s",
              " surface",
              " is",
              " r",
              "ug",
              "ged",
              " and",
              " un",
              "even",
              ",",
              " with",
              " numero",
              "us",
              " rid",
              "ges",
              " and",
              " val",
              "le",
              "ys",
              ".",
              " These",
              " features",
              " are",
              " formed",
              " by",
              " anc",
              "ient",
              " vol",
              "can",
              "ic",
              " activity",
              " and",
              " t",
              "ect",
              "onic",
              " mov",
              "ements",
              " that",
              " have",
              " sh",
              "aped",
              " the",
              " Mo",
              "on",
              " over",
              " bill",
              "ions",
              " of",
              " years",
              ".",
              " The",
              " Mo",
              "on",
              "'s",
              " surface",
              " is",
              " composed",
              " primarily",
              " of",
              " rock",
              " and",
              " dust",
              ",",
              " with",
              " some",
              " areas",
              " displaying",
              " a",
              " more",
              " por",
              "ous",
              " texture",
              ",",
              " which",
              " reflect",
              "s",
              " light",
              " differently",
              ".",
              "\n",
              "\n",
              "In",
              " the",
              " central",
              " region",
              ",",
              " there",
              " is",
              " a",
              " prom",
              "inent",
              " central",
              " peak",
              " or",
              " mount",
              "ain",
              ",",
              " which",
              " is",
              " likely",
              " a",
              " result",
              " of",
              " anc",
              "ient",
              " impact",
              "s",
              " and",
              " vol",
              "can",
              "ic",
              " activity",
              ".",
              " The",
              " l",
              "un",
              "ar",
              " cr",
              "aters",
              " vary",
              " in",
              " size",
              " and",
              " distribution",
              ",",
              " with",
              " some",
              " appearing",
              " closer",
              " to",
              " the",
              " center",
              " of",
              " the",
              " Mo",
              "on",
              " and",
              " others",
              " scatter",
              "ed",
              " more",
              " towards",
              " the",
              " edges",
              ".",
              " The",
              " distribution",
              " of",
              " cr",
              "aters",
              " is",
              " not",
              " uniform",
              ",",
              " indicating",
              " that",
              " the",
              " Mo",
              "on",
              " has",
              " been",
              " geo",
              "logic",
              "ally",
              " active",
              " over",
              " a",
              " long",
              " period",
              ".",
              "\n",
              "\n",
              "The",
              " photo",
              "graph",
              " captures",
              " the",
              " Mo",
              "on",
              "'s",
              " surface",
              " in",
              " a",
              " way",
              " that",
              " highlight",
              "s",
              " its",
              " geo",
              "logical",
              " divers",
              "ity",
              " and",
              " the",
              " impact",
              "s",
              " that",
              " have",
              " sh",
              "aped",
              " its",
              " history",
              ".",
              " The",
              " lack",
              " of",
              " at",
              "mosphere",
              " and",
              " magnetic",
              " field",
              " on",
              " the",
              " Mo",
              "on",
              " means",
              " that",
              " it",
              " does",
              " not",
              " experience",
              " weather",
              "ing",
              " or",
              " eros",
              "ion",
              ",",
              " which",
              " allows",
              " for",
              " the",
              " pre",
              "servation",
              " of",
              " its",
              " anc",
              "ient",
              " features",
              ".",
              "\n",
              "\n",
              "In",
              " summary",
              ",",
              " the",
              " image",
              " provides",
              " a",
              " detailed",
              " view",
              " of",
              " the",
              " Mo",
              "on",
              "'s",
              " surface",
              ",",
              " show",
              "c",
              "asing",
              " its",
              " r",
              "ug",
              "ged",
              " and",
              " var",
              "ied",
              " terrain",
              ",",
              " numero",
              "us",
              " cr",
              "aters",
              ",",
              " and",
              " the",
              " contrast",
              " between",
              " the",
              " illum",
              "inated",
              " and",
              " dark",
              " sides",
              ".",
              " The",
              " lack",
              " of",
              " at",
              "mosphere"
            ],
            "prompt": "Describe this image"
          }
        ],
        "parameterDescriptions": {
          "top_k": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering).",
          "top_p": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751).",
          "prompt": "Prompt",
          "max_tokens": "The maximum number of tokens the model should generate as output.",
          "min_tokens": "The minimum number of tokens the model should generate as output.",
          "temperature": "The value used to modulate the next token probabilities.",
          "system_prompt": "System prompt to send to the model. This is prepended to the prompt and helps guide system behavior. Ignored for non-chat models.",
          "stop_sequences": "A comma-separated list of sequences to stop generation at. For example, '<end>,<stop>' will stop generation at the first instance of 'end' or '<stop>'.",
          "presence_penalty": "Presence penalty",
          "frequency_penalty": "Frequency penalty"
        }
      }
    },
    {
      "id": "pixverse/pixverse-v4.5",
      "name": "pixverse-v4.5",
      "displayName": "pixverse-v4.5",
      "provider": "replicate",
      "category": "video",
      "endpoint": "pixverse/pixverse-v4.5",
      "version": "39827be02e1b829971fc35dbb79c6ced494450231d2582935e04e7405c587235",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Quickly make 5s or 8s videos at 540p, 720p or 1080p. It has enhanced motion, prompt coherence and handles complex actions well.",
        "runCount": 98408,
        "confidence": 0.9,
        "qualityScore": 69.93034818671165,
        "createdAt": "2025-07-07T19:57:21.664214Z",
        "owner": "pixverse",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/ce4c6567-8cdb-4e87-8824-aa361f33f29f/replicate-prediction-s57k61y2.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://docs.pixverse.ai/PixVerse-Platform-Terms-of-Service-1773e99bf35080c6a802fae0e3629708",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "style": "None",
              "effect": "None",
              "prompt": "a snow leopard is walking carefully, snowy landscape scene at twilight",
              "quality": "1080p",
              "duration": 5,
              "motion_mode": "normal",
              "aspect_ratio": "16:9",
              "negative_prompt": ""
            },
            "output": "https://replicate.delivery/xezq/nCLgz2veEJzhJqhMOQuIM6K2Of5Ryy1NPBB0kmp03R1uLMtUA/tmpcxcacfc2.mp4",
            "prompt": "a snow leopard is walking carefully, snowy landscape scene at twilight"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "image": "Image to use for the first frame of the video",
          "style": "Style of the video",
          "effect": "Special effect to apply to the video. Does not work with last_frame_image.",
          "prompt": "Text prompt for video generation",
          "quality": "Resolution of the video. 360p and 540p cost the same, but 720p and 1080p cost more. See the README for details.",
          "duration": "Duration of the video in seconds. 8 second videos cost twice as much as 5 second videos. (1080p does not support 8 second duration)",
          "motion_mode": "Motion mode for the video. Smooth videos generate more frames, so they cost twice as much. (smooth is only available when using a 5 second duration, 1080p does not support smooth motion)",
          "aspect_ratio": "Aspect ratio of the video",
          "negative_prompt": "Negative prompt to avoid certain elements in the video",
          "last_frame_image": "Use to generate a video that transitions from the first image to the last image. Must be used with image.",
          "sound_effect_switch": "Enable background music or sound effects",
          "sound_effect_content": "Sound effect prompt. If not given, a random sound effect will be generated."
        }
      }
    },
    {
      "id": "flux-kontext-apps/multi-image-kontext-max",
      "name": "multi-image-kontext-max",
      "displayName": "multi-image-kontext-max",
      "provider": "replicate",
      "category": "image",
      "endpoint": "flux-kontext-apps/multi-image-kontext-max",
      "version": "433c55029af55eb6ede9ea266cd559613f76ae1201cda5487b66afddf536f862",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "An experimental FLUX Kontext model that can combine two input images",
        "runCount": 96196,
        "confidence": 0.9,
        "qualityScore": 69.8316152833967,
        "createdAt": "2025-07-24T20:01:27.979724Z",
        "owner": "flux-kontext-apps",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/034b26ea-3843-465e-8c21-34ac7b4869bf/multi-cover.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "Put the woman into a white t-shirt with the text on it",
              "aspect_ratio": "1:1",
              "input_image_1": "https://replicate.delivery/pbxt/N5rSeJrCafWpmJuLb62moY8pSMEpSBBwSf7N6hxyIn4fNYMa/w8msa88d01rm80cq3hzsqrdehg.png",
              "input_image_2": "https://replicate.delivery/pbxt/N5rSdTCgBqIRvbkedcfLfS5xTSEEOqMtX9FsR1hLK9JYryml/0_1.webp"
            },
            "output": "https://replicate.delivery/xezq/7wlLiKHs0arKBtHaijl2tM1fFU2R18b57eR3nWzA2KlTUixUA/tmpe2rpyzyh.png",
            "prompt": "Put the woman into a white t-shirt with the text on it"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Text description of how to combine or transform the two input images",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "input_image_1": "First input image. Must be jpeg, png, gif, or webp.",
          "input_image_2": "Second input image. Must be jpeg, png, gif, or webp.",
          "output_format": "Output format for the generated image",
          "safety_tolerance": "Safety tolerance, 0 is most strict and 2 is most permissive. 2 is currently the maximum allowed."
        }
      }
    },
    {
      "id": "google/veo-2",
      "name": "veo-2",
      "displayName": "veo-2",
      "provider": "replicate",
      "category": "video",
      "endpoint": "google/veo-2",
      "version": "0546b4e90d4f215c7fc42c9b8d815df3a7b6e47a754ee94ddb62b3f667fea9a5",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "State of the art video generation model. Veo 2 can faithfully follow simple and complex instructions, and convincingly simulates real-world physics as well as a wide range of visual styles.",
        "runCount": 92202,
        "confidence": 0.9,
        "qualityScore": 69.64745051880631,
        "createdAt": "2025-05-23T11:07:03.594522Z",
        "owner": "google",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/d58d1243-1045-4cb0-ab94-454757139c9d/replicate-prediction-pgghdpmn.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "a dog riding a skateboard",
              "duration": 5,
              "aspect_ratio": "16:9",
              "enhance_prompt": true
            },
            "output": "https://replicate.delivery/xezq/WB9h80FyAYKRINH8bcNP4lvvw0bwmhIJ0Olz8fP1YUaBTfSUA/tmpgbhdxrta.mp4",
            "prompt": "a dog riding a skateboard"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Omit for random generations",
          "image": "Input image to start generating from. Ideal images are 16:9 or 9:16 and 1280x720 or 720x1280, depending on the aspect ratio you choose.",
          "prompt": "Text prompt for video generation",
          "duration": "Video duration",
          "aspect_ratio": "Video aspect ratio"
        }
      }
    },
    {
      "id": "flux-kontext-apps/multi-image-kontext-pro",
      "name": "multi-image-kontext-pro",
      "displayName": "multi-image-kontext-pro",
      "provider": "replicate",
      "category": "image",
      "endpoint": "flux-kontext-apps/multi-image-kontext-pro",
      "version": "f3545943bdffdf06420f0d8ececf86a36ce401b9df0ad5ec0124234c0665cfed",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "An experimental model with FLUX Kontext Pro that can combine two input images",
        "runCount": 90548,
        "confidence": 0.9,
        "qualityScore": 69.56883658439365,
        "createdAt": "2025-07-24T21:32:16.590089Z",
        "owner": "flux-kontext-apps",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/fce2f7bb-1cef-44a9-824f-9036adb567c4/Screenshot_2025-06-03_at_2.25..png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "Put the woman next to the house",
              "aspect_ratio": "match_input_image",
              "input_image_1": "https://replicate.delivery/pbxt/N7gRAUNcVF6HarL0hdAQA2JYNMlJD52LP1wyaIWRUXWeHzqT/0_1-1.webp",
              "input_image_2": "https://replicate.delivery/pbxt/N7gRAK5kbPwdsbOpqgyAIOFQX45U6suTlbL6ws2N74SnGFpo/test.jpg",
              "output_format": "png",
              "safety_tolerance": 2
            },
            "output": "https://replicate.delivery/xezq/U6C6Sv9a185eU6VesDUyc167QOfHFOjhijVJ28W2eKR276MTB/tmp7exxygto.png",
            "prompt": "Put the woman next to the house"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Text description of how to combine or transform the two input images",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "input_image_1": "First input image. Must be jpeg, png, gif, or webp.",
          "input_image_2": "Second input image. Must be jpeg, png, gif, or webp.",
          "output_format": "Output format for the generated image",
          "safety_tolerance": "Safety tolerance, 0 is most strict and 2 is most permissive. 2 is currently the maximum allowed."
        }
      }
    },
    {
      "id": "openai/gpt-4o-transcribe",
      "name": "gpt-4o-transcribe",
      "displayName": "gpt-4o-transcribe",
      "provider": "replicate",
      "category": "image",
      "endpoint": "openai/gpt-4o-transcribe",
      "version": "1302d9240d7caa85f014a03f1e901b878ec6df3a37dac854699ddd6f560a4518",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A speech-to-text model that uses GPT-4o to transcribe audio",
        "runCount": 2827,
        "confidence": 0.6,
        "qualityScore": 69.51479405124861,
        "createdAt": "2025-05-20T15:11:43.237144Z",
        "owner": "openai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/b1aa75b9-0353-401e-a38f-5e129bee9658/4o-transcribe.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://openai.com/policies/",
        "pricing": {
          "tier": "premium"
        },
        "examples": [
          {
            "input": {
              "language": "en",
              "audio_file": "https://replicate.delivery/xezq/XoxHeakty0z3KKc46cMLPKC2ct54ekT3EtvcwDQuRIuxfJdpA/tmpsglqtqn5.mp3",
              "temperature": 0
            },
            "output": [
              "So",
              " we",
              " just",
              " added",
              " GPT",
              "-",
              "4",
              "o",
              " trans",
              "cribe",
              " to",
              " Rep",
              "licate",
              " and",
              " thought",
              " you'd",
              " want",
              " to",
              " know",
              ".",
              " It's",
              " basically",
              " a",
              " speech",
              "-to",
              "-text",
              " model",
              " that",
              " uses",
              " GPT",
              "-",
              "4",
              "o",
              " to",
              " turn",
              " your",
              " audio",
              " into",
              " text",
              ".",
              " The",
              " cool",
              " thing",
              " is",
              " that",
              " it's",
              " noticeably",
              " better",
              " than",
              " the",
              " Whisper",
              " models",
              " we've",
              " been",
              " using",
              ",",
              " fewer",
              " errors",
              ",",
              " better",
              " at",
              " recognizing",
              " different",
              " languages",
              ",",
              " and",
              " just",
              " more",
              " accurate",
              " overall",
              ".",
              " If",
              " you've",
              " ever",
              " been",
              " frustrated",
              " with",
              " transcripts",
              " that",
              " mess",
              " up",
              " technical",
              " terms",
              " or",
              " struggle",
              " with",
              " different",
              " accents",
              ",",
              " you'll",
              " probably",
              " appreciate",
              " this",
              " upgrade",
              ".",
              " It",
              " just",
              " works",
              " better",
              ".",
              " Some",
              " quick",
              " tech",
              " specs",
              " if",
              " you're",
              " curious",
              ".",
              " It",
              " has",
              " a",
              " ",
              "16",
              ",",
              "000",
              " token",
              " context",
              " window",
              ",",
              " which",
              " means",
              " it",
              " can",
              " handle",
              " longer",
              " audio",
              " clips",
              " in",
              " one",
              " go",
              ".",
              " And",
              " it",
              " can",
              " output",
              " up",
              " to",
              " ",
              "2",
              ",",
              "000",
              " tokens",
              ",",
              " so",
              " you'll",
              " get",
              " nice",
              " complete",
              " transcripts",
              ".",
              " The",
              " model",
              "'s",
              " knowledge",
              " is",
              " current",
              " up",
              " to",
              " June",
              " ",
              "202",
              "4",
              ",",
              " so",
              " it's",
              " pretty",
              " up",
              "-to",
              "-date",
              " with",
              " language",
              " and",
              " terminology",
              "."
            ]
          }
        ],
        "parameterDescriptions": {
          "prompt": "An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language.",
          "language": "The language of the input audio. Supplying the input language in ISO-639-1 (e.g. en) format will improve accuracy and latency.",
          "audio_file": "The audio file to transcribe. Supported formats: mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm",
          "temperature": "Sampling temperature between 0 and 1"
        }
      }
    },
    {
      "id": "wavespeedai/wan-2.1-i2v-720p",
      "name": "wan-2.1-i2v-720p",
      "displayName": "wan-2.1-i2v-720p",
      "provider": "replicate",
      "category": "video",
      "endpoint": "wavespeedai/wan-2.1-i2v-720p",
      "version": "aa535ad6050bb18feee0e0ba99f345b0807b28baa81c95adfc4777f61f3ac41f",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Accelerated inference for Wan 2.1 14B image to video with high resolution, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation.",
        "runCount": 80418,
        "confidence": 0.9,
        "qualityScore": 69.05358668404021,
        "createdAt": "2025-03-27T21:56:32.613609Z",
        "owner": "wavespeedai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/cd768779-a7bf-41cd-ac59-6ab1531c1697/replicate-prediction-ce1zy3hv.webp",
        "githubUrl": "https://github.com/Wan-Video/Wan2.1",
        "paperUrl": null,
        "licenseUrl": "https://github.com/Wan-Video/Wan2.1/blob/main/LICENSE.txt",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/MZaQKJ2pmyS4uQojMWk05hZd6N6tnJHVLvVFbDofTCjOEBku/9tynyd7pk5rme0cmzabr7rhaym.png",
              "prompt": "A warrior swings her swords in preparation for battle",
              "max_area": "720x1280",
              "fast_mode": "Balanced",
              "num_frames": 81,
              "sample_shift": 5,
              "sample_steps": 30,
              "frames_per_second": 16,
              "sample_guide_scale": 5
            },
            "output": "https://replicate.delivery/xezq/O1nQl9BQ6uZoAFI7gTT40OJhjbvwWhKiDJR9Y9VJC2xlANFF/output.mp4",
            "prompt": "A warrior swings her swords in preparation for battle"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Leave blank for random",
          "image": "Input image to start generating from",
          "prompt": "Prompt for video generation",
          "max_area": "Maximum area of generated image. The input image will shrink to fit these dimensions",
          "fast_mode": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "num_frames": "Number of video frames. 81 frames give the best results",
          "lora_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "sample_shift": "Sample shift factor",
          "sample_steps": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts",
          "frames_per_second": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps",
          "sample_guide_scale": "Higher guide scale makes prompt adherence better, but can reduce variation"
        }
      }
    },
    {
      "id": "runwayml/gen4-image",
      "name": "gen4-image",
      "displayName": "gen4-image",
      "provider": "replicate",
      "category": "image",
      "endpoint": "runwayml/gen4-image",
      "version": "e851fff54fcda4eb99dc172d853c651bcd0b27d887984ded494123789e1fe42e",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Runway's Gen-4 Image model with references. Use up to 3 reference images to create the exact image you need. Capture every angle.",
        "runCount": 59889,
        "confidence": 0.9,
        "qualityScore": 67.77354313084209,
        "createdAt": "2025-07-22T10:13:46.402909Z",
        "owner": "runwayml",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/73594862-9c0f-4166-a960-ef7201822c78/combined-gen-4.webp",
        "githubUrl": null,
        "paperUrl": "https://runwayml.com/news/introducing-runway-api-for-gen-4-images",
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "a close up portrait of @woman and @man standing in @park, hands in pockets, looking cool. She is wearing her pink sweater and bangles.",
              "resolution": "1080p",
              "aspect_ratio": "4:3",
              "reference_tags": [
                "park",
                "woman",
                "man"
              ],
              "reference_images": [
                "https://replicate.delivery/pbxt/NHVhGWPplgrmOE8EGTVhbeSqWuZBcZLHyMQrgrTH4Hpa1ljU/m4hjkmbk79rma0cqrnxt67cqnw.jpg",
                "https://replicate.delivery/pbxt/NHVhFhdxAAmuXKUyT4r10KIalYrXf9vp5B40CmAeXlPieuOs/w99em95b01rmc0cqrny8chf49w.jpg",
                "https://replicate.delivery/pbxt/NHVhGE5GSJlAfL9RkGFvUbx70KVl7l7KamUNLHOAUd1sQVuF/psjdbkzgm1rmc0cqrnysbg93cm.jpg"
              ]
            },
            "output": "https://replicate.delivery/xezq/eWbp1p7iKZzLS65MUKRpWSvHwQVrjpf9kbm98CsWfXAJKt4pA/tmpq55tt0im.png",
            "prompt": "a close up portrait of @woman and @man standing in @park, hands in pockets, looking cool. She is wearing her pink sweater and bangles."
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Text prompt for image generation",
          "resolution": "Image resolution",
          "aspect_ratio": "Image aspect ratio",
          "reference_tags": "An optional tag for each of your reference images. Tags must be alphanumeric and start with a letter. You can reference them in your prompt using @tag_name. Tags must be between 3 and 15 characters.",
          "reference_images": "Up to 3 reference images. Images must be between 0.5 and 2 aspect ratio."
        }
      }
    },
    {
      "id": "flux-kontext-apps/multi-image-list",
      "name": "multi-image-list",
      "displayName": "multi-image-list",
      "provider": "replicate",
      "category": "image",
      "endpoint": "flux-kontext-apps/multi-image-list",
      "version": "ff27171315a3ccd3b5d84849c50cf55b923149b5f8307747d5668bca1838cd47",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "FLUX Kontext max with list input for multiple images",
        "runCount": 55581,
        "confidence": 0.9,
        "qualityScore": 67.44934169885335,
        "createdAt": "2025-07-24T21:33:35.061216Z",
        "owner": "flux-kontext-apps",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/1a5aacf0-9163-4f57-affe-e9a0ae637aaa/output.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "Combine these photos into one fluid scene. Make the woman in the first image wear the futuristic headgear in the second image. Then put the same woman the third image's scene.",
              "aspect_ratio": "1:1",
              "input_images": [
                "https://replicate.delivery/pbxt/N83LmkC1NAWFfeIkF6HBSkQGN2W3tr6Q7XIxhRcA1Eoh0uAC/tmp04o2q0cj.png",
                "https://replicate.delivery/pbxt/N83LmgcB5EguqxLt5gQnmI2LXRa8H0eayIrtVw931df2xvtt/test_4.jpg",
                "https://replicate.delivery/pbxt/N83Ln0m0xhzTsR5rY4RAREEpPLwzfXSB90Fmp24gQFHKoQ2D/test.jpg"
              ],
              "output_format": "png",
              "safety_tolerance": 2
            },
            "output": "https://replicate.delivery/xezq/V5Jq4qxecfgB108KOinxJDo2G3hGWdifMfUUXXBp9ju0QSOTB/tmpamy1gm7s.png",
            "prompt": "Combine these photos into one fluid scene. Make the woman in the first image wear the futuristic headgear in the second image. Then put the same woman the third image's scene."
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Text description of how to combine or transform the input images",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "input_images": "List of input images. Must be jpeg, png, gif, or webp.",
          "output_format": "Output format for the generated image",
          "safety_tolerance": "Safety tolerance, 0 is most strict and 2 is most permissive. 2 is currently the maximum allowed."
        }
      }
    },
    {
      "id": "black-forest-labs/flux-1.1-pro-ultra-finetuned",
      "name": "flux-1.1-pro-ultra-finetuned",
      "displayName": "flux-1.1-pro-ultra-finetuned",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-1.1-pro-ultra-finetuned",
      "version": "df93e57884eed71af473d8fc6ebad4c49384aff50592fa2cfa4c9ebf735bcdde",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Inference model for FLUX 1.1 [pro] Ultra using custom `finetune_id`. Supports 4MP images and raw mode for realism",
        "runCount": 52700,
        "confidence": 0.9,
        "qualityScore": 67.2181885601637,
        "createdAt": "2025-06-03T12:25:47.475786Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/c15b72ab-9626-436d-acdd-b53e4b1c9444/20250429_1820_Flux_Pro_Text_Alte.webp",
        "githubUrl": null,
        "paperUrl": "https://blackforestlabs.ai/flux-1-1-ultra/",
        "licenseUrl": "https://replicate.com/black-forest-labs/flux-pro#license",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "raw": false,
              "prompt": "A formula one CYBERCAB car",
              "finetune_id": "fc14d7bf-95bd-4dde-92c1-2dd7317721f6",
              "aspect_ratio": "3:2",
              "output_format": "jpg",
              "safety_tolerance": 2,
              "finetune_strength": 1,
              "image_prompt_strength": 0.1
            },
            "output": "https://replicate.delivery/xezq/BPqfMaZuhJUKO6zPMLAMKDjo4TBVuK0Kfr8QLzDLIxp5ypnUA/tmpfuuoj5f9.jpg",
            "prompt": "A formula one CYBERCAB car"
          }
        ],
        "parameterDescriptions": {
          "raw": "Generate less processed, more natural-looking images",
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Text prompt for image generation",
          "finetune_id": "Finetune ID for making images using a previously trained fine-tune. Only IDs from trainings made using Replicate's Flux Pro fine-tuning model are supported.",
          "aspect_ratio": "Aspect ratio for the generated image",
          "image_prompt": "Image to use with Flux Redux. This is used together with the text prompt to guide the generation towards the composition of the image_prompt. Must be jpeg, png, gif, or webp.",
          "output_format": "Format of the output images.",
          "safety_tolerance": "Safety tolerance, 1 is most strict and 6 is most permissive",
          "finetune_strength": "Controls finetune influence",
          "image_prompt_strength": "Blend between the prompt and the image prompt."
        }
      }
    },
    {
      "id": "openai/gpt-4o",
      "name": "gpt-4o",
      "displayName": "gpt-4o",
      "provider": "replicate",
      "category": "image",
      "endpoint": "openai/gpt-4o",
      "version": "f15cb05fae0a9bc3c241c310eb51236c65d711f148f95cebaad261592c0137a3",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "OpenAI's high-intelligence chat model",
        "runCount": 139881,
        "confidence": 0.6,
        "qualityScore": 66.45761833122154,
        "createdAt": "2025-06-23T21:12:18.987646Z",
        "owner": "openai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/c0841fcc-b236-4634-8f13-65627b2d5af6/Screenshot_2025-05-18_at_1.14.36.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://openai.com/policies/",
        "pricing": {
          "tier": "premium"
        },
        "examples": [
          {
            "input": {
              "top_p": 1,
              "prompt": "Who was the 16th president of the United States?",
              "image_input": [],
              "temperature": 1,
              "system_prompt": "You are a helpful assistant.",
              "presence_penalty": 0,
              "frequency_penalty": 0,
              "max_completion_tokens": 4096
            },
            "output": [
              "",
              "The",
              " ",
              "16",
              "th",
              " president",
              " of",
              " the",
              " United",
              " States",
              " was",
              " Abraham",
              " Lincoln",
              ".",
              " He",
              " served",
              " from",
              " March",
              " ",
              "4",
              ",",
              " ",
              "186",
              "1",
              ",",
              " until",
              " his",
              " assassination",
              " on",
              " April",
              " ",
              "15",
              ",",
              " ",
              "186",
              "5",
              ".",
              "",
              ""
            ],
            "prompt": "Who was the 16th president of the United States?"
          }
        ],
        "parameterDescriptions": {
          "top_p": "Nucleus sampling parameter - the model considers the results of the tokens with top_p probability mass. (0.1 means only the tokens comprising the top 10% probability mass are considered.)",
          "prompt": "The prompt to send to the model. Do not use if using messages.",
          "image_input": "List of images to send to the model",
          "temperature": "Sampling temperature between 0 and 2",
          "system_prompt": "System prompt to set the assistant's behavior",
          "presence_penalty": "Presence penalty parameter - positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.",
          "frequency_penalty": "Frequency penalty parameter - positive values penalize the repetition of tokens.",
          "max_completion_tokens": "Maximum number of completion tokens to generate"
        }
      }
    },
    {
      "id": "prunaai/flux.1-juiced",
      "name": "flux.1-juiced",
      "displayName": "flux.1-juiced",
      "provider": "replicate",
      "category": "image",
      "endpoint": "prunaai/flux.1-juiced",
      "version": "6c7af2f8c6ad10467ac22f5f9cc892f4ef789e071d64f19199d5cc070cf6a32d",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This a pruna optimised version of the flux 1.dev model.",
        "runCount": 40976,
        "confidence": 0.9,
        "qualityScore": 66.12540159747515,
        "createdAt": "2025-05-14T10:19:34.537281Z",
        "owner": "prunaai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/b47565ad-aeb7-4027-86ae-2cedeb3ae6af/flux.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "seed": 2,
              "prompt": "a tiny astronaut hatching from an egg on the moon",
              "guidance": 3.5,
              "image_size": 1024,
              "speed_mode": "Extra Juiced 🔥 (more speed)",
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "output_quality": 80,
              "num_inference_steps": 28
            },
            "output": "https://replicate.delivery/xezq/ANjQ1v2E1g7nNhUZPWB6N0SJjG1maergfyMxy4MfNeYFQc3SB/output_2_0.webp",
            "prompt": "a tiny astronaut hatching from an egg on the moon"
          }
        ],
        "parameterDescriptions": {
          "seed": "Seed",
          "prompt": "Prompt",
          "guidance": "Guidance scale",
          "image_size": "Base image size (longest side)",
          "speed_mode": "Speed optimization level",
          "aspect_ratio": "Aspect ratio of the output image",
          "output_format": "Output format",
          "output_quality": "Output quality (for jpg and webp)",
          "num_inference_steps": "Number of inference steps"
        }
      }
    },
    {
      "id": "openai/o4-mini",
      "name": "o4-mini",
      "displayName": "o4-mini",
      "provider": "replicate",
      "category": "image",
      "endpoint": "openai/o4-mini",
      "version": "0e40331173ae291e1eee088e02c6538740af3181a4a47118a878412986df51a4",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "OpenAI's fast, lightweight reasoning model",
        "runCount": 124999,
        "confidence": 0.6,
        "qualityScore": 65.96910013008056,
        "createdAt": "2025-06-13T14:32:58.182341Z",
        "owner": "openai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/f01a4135-119e-4257-80db-bb7a3e5e29bb/Screenshot_2025-05-01_at_2.49..png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://openai.com/policies/",
        "pricing": {
          "tier": "premium"
        },
        "examples": [
          {
            "input": {
              "prompt": "What is the theme of the Iliad?",
              "system_prompt": "You only speak in mathematical terms.",
              "reasoning_effort": "high",
              "max_completion_tokens": 4096
            },
            "output": "Let us encode the main theme in purely mathematical terms.\n\n1. Basic objects  \n   • Let t ∈ [0,T] be “narrative time.”  \n   • Let R(t) ∈ ℝ₊ be Achilles’ wrath‐intensity at time t.  \n   • Let D(t) ∈ ℝ₊ be the cumulative death‐count (“destruction”) up to time t.  \n   • Let H(t) ∈ ℝ₊ be Achilles’ honor (kleos) at time t.  \n   • Let F be a fixed vector of “fate‐parameters” determined by the gods (constant w.r.t. t).  \n\n2. Governing relations  \n   (i)  dD/dt = α⋅R(t) + β⋅G(t)  \n        – here G(t) models discrete divine interventions; α,β>0.  \n   (ii) dH/dt = γ⋅R(t) – δ⋅D(t)  \n        – honor rises with wrath but is eroded by mounting destruction; γ,δ>0.  \n   (iii) R(0)=R₀>0,   H(0)=H₀≥0,   D(0)=0,   F fixed.  \n\n3. Central result (thematic “theorem”)  \n   Under these conditions the solution satisfies  \n     ∂D/∂R > 0  for all t>0,  \n   i.e. D(t) is a strictly increasing function of R(t).  \n\n4. Interpretation  \n   The epic thus examines the map  \n     R(·) ↦ D(·)  \n   under the boundary/fate constraints F.  Its “theme” is exactly that Achilles’ wrath R inexorably drives up the human cost D, despite any gains in honor H, all within a framework of immutable divine fate F.",
            "prompt": "What is the theme of the Iliad?"
          }
        ],
        "parameterDescriptions": {
          "prompt": "The prompt to send to the model. Do not use if using messages.",
          "messages": "A JSON string representing a list of messages. For example: [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]. If provided, prompt and system_prompt are ignored.",
          "image_input": "List of images to send to the model",
          "system_prompt": "System prompt to set the assistant's behavior",
          "reasoning_effort": "Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.",
          "max_completion_tokens": "Maximum number of completion tokens to generate"
        }
      }
    },
    {
      "id": "wan-video/wan-2.1-1.3b",
      "name": "wan-2.1-1.3b",
      "displayName": "wan-2.1-1.3b",
      "provider": "replicate",
      "category": "video",
      "endpoint": "wan-video/wan-2.1-1.3b",
      "version": "121bbb762bf449889f090d36e3598c72c50c7a8cc2ce250433bc521a562aae61",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate 5s 480p videos. Wan is an advanced and powerful visual generation model developed by Tongyi Lab of Alibaba Group",
        "runCount": 38867,
        "confidence": 0.9,
        "qualityScore": 65.895921940578,
        "createdAt": "2025-02-27T12:51:27.684289Z",
        "owner": "wan-video",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/a07f6849-fd97-4f6b-9166-887e84b0cb47/replicate-prediction-0s06z711.webp",
        "githubUrl": "https://github.com/Wan-Video/Wan2.1",
        "paperUrl": "https://wanxai.com/",
        "licenseUrl": "https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "a dog is riding on a skateboard down a hill",
              "frame_num": 81,
              "resolution": "480p",
              "aspect_ratio": "16:9",
              "sample_shift": 8,
              "sample_steps": 30,
              "sample_guide_scale": 6
            },
            "output": "https://replicate.delivery/xezq/GNJ72Mi0oi7gCtf6idzTwoSAwxfYfvg31N2A3uWbNcTv2fMRB/t2v-1.3B_832x480_a_dog_is_riding_on_a_skateboar_20250226_171756.mp4",
            "prompt": "a dog is riding on a skateboard down a hill"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible results (leave blank for random)",
          "prompt": "Text prompt describing what you want to generate",
          "frame_num": "Video duration in frames (based on standard 16fps playback)",
          "resolution": "Video resolution",
          "aspect_ratio": "Video aspect ratio",
          "sample_shift": "Sampling shift factor for flow matching (recommended range: 8-12)",
          "sample_steps": "Number of sampling steps (higher = better quality but slower)",
          "sample_guide_scale": "Classifier free guidance scale (higher values strengthen prompt adherence)"
        }
      }
    },
    {
      "id": "delta-lock/noobai-xl",
      "name": "noobai-xl",
      "displayName": "noobai-xl",
      "provider": "replicate",
      "category": "image",
      "endpoint": "delta-lock/noobai-xl",
      "version": "d09db5fc24b8b6573b095c2bd845b58242dce8f996b034fa865130bf1075858f",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Models fine-tuned from NoobAI-XL/Illustrious-XL series.",
        "runCount": 36625,
        "confidence": 0.6,
        "qualityScore": 65.637894910701,
        "createdAt": "2025-05-11T11:10:39.912876Z",
        "owner": "delta-lock",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/4f9c9ca5-b6f3-44e0-a5b7-d851719bdff5/noobxl.webp",
        "githubUrl": "https://github.com/LagPixelLOL/cog-sdxl",
        "paperUrl": null,
        "licenseUrl": "https://github.com/LagPixelLOL/cog-sdxl/blob/main/LICENSE",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "vae": "default",
              "seed": -1,
              "model": "miaomiaoHarem_vpred11",
              "steps": 35,
              "width": 1184,
              "height": 864,
              "prompt": "1girl",
              "strength": 0.7,
              "cfg_scale": 5,
              "clip_skip": 1,
              "pag_scale": 3,
              "scheduler": "Euler a",
              "batch_size": 1,
              "blur_factor": 5,
              "negative_prompt": "animal, cat, dog, big breasts",
              "guidance_rescale": 0.5,
              "prepend_preprompt": true
            },
            "output": [
              "https://replicate.delivery/xezq/CVoDPTJw2Tb7GFewtqcOM0t7iQTeA7y6Vv73oWQFvetmAHXpA/0.png"
            ],
            "prompt": "1girl"
          }
        ],
        "parameterDescriptions": {
          "vae": "The VAE to use",
          "mask": "The mask for inpainting, white areas will be modified and black preserved (will be scaled then cropped to the set width and height)",
          "seed": "The seed used when generating, set to -1 to use a random seed",
          "image": "The image for image to image or as the base for inpainting (will be scaled then cropped to the set width and height)",
          "loras": "The LoRAs to use, must be either a string with format \"URL:Strength,URL:Strength,...\" (strength is optional, default to 1), or a JSON list dumped as a string containing key \"url\" (required), \"strength\" (optional, default to 1), and \"civitai_token\" (optional, for downloading from CivitAI) (NOTICE: Will download the weights, might take a while if the LoRAs are huge or the download is slow, WILL CHARGE WHEN DOWNLOADING)",
          "model": "The model to use",
          "steps": "The steps when generating",
          "width": "The width of the image",
          "height": "The height of the image",
          "prompt": "The prompt, uses Compel weighting syntax",
          "strength": "How much noise to add (for image to image and inpainting only, larger value indicates more noise added to the input image)",
          "cfg_scale": "CFG scale defines how much attention the model pays to the prompt when generating, set to 1 to disable",
          "clip_skip": "How many CLIP layers to skip, 1 is actually no skip, this is the behavior in A1111 so it's aligned to it",
          "pag_scale": "PAG scale is similar to CFG but it literally makes the result better, it's compatible with CFG too, set to 0 to disable",
          "scheduler": "The scheduler to use",
          "batch_size": "Number of images to generate (1-4), note if you set this to 4, some high resolution gens might fail because of not enough VRAM",
          "blur_factor": "The factor to blur the inpainting mask for smoother transition between masked and unmasked",
          "negative_prompt": "The negative prompt (for things you don't want), uses Compel weighting syntax",
          "guidance_rescale": "The amount to rescale CFG generated noise to avoid generating overexposed images, set to 0 or 1 to disable",
          "prepend_preprompt": "Prepend preprompt (Prompt: \"masterpiece, best quality, absurdres, \" | Negative Prompt: \"worst quality, english text, japanese text, twitter username, watermark, (bad feet)1.5, jpeg artifacts, \")"
        }
      }
    },
    {
      "id": "luma/modify-video",
      "name": "modify-video",
      "displayName": "modify-video",
      "provider": "replicate",
      "category": "video",
      "endpoint": "luma/modify-video",
      "version": "5b99606615d6230f799d110c563361f65f3b4f24ff75b48a8b8de213acf05b52",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "videoUrl": "video"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Modify a video with style transfer and prompt-based editing",
        "runCount": 1147,
        "confidence": 0.9,
        "qualityScore": 65.59941888061955,
        "createdAt": "2025-07-25T11:44:35.471918Z",
        "owner": "luma",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/ffe579c8-e5b6-442b-82ff-1e5a032f2971/replicate-luma-modify-vid.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "mode": "flex_1",
              "prompt": "make it anime",
              "video_url": "https://replicate.delivery/pbxt/NHXa8wBNdkuezb6D4K930uTE1GxQEdavDzPE85Iz0LEX5S6j/A_ferrari_f40_202506211556_4g8tu.mp4",
              "first_frame_url": "https://replicate.delivery/xezq/7e5CfHf76AXHSpMHn7r8SNN65Fw0Nu4Gxrsp9a5HryPsww4pA/tmpia3hkkv5.png"
            },
            "output": "https://replicate.delivery/xezq/chPtcfYvt0xXUyZaMAuP7AN0WChqvuUfbwxoylV1kmhbsa8UA/tmp3h7ea2l_.mp4",
            "prompt": "make it anime"
          }
        ],
        "parameterDescriptions": {
          "mode": "How closely the output should follow the source video. Adhere: very close, for subtle enhancements. Flex: allows more stylistic change while keeping recognizable elements. Reimagine: loosely follows the source, for dramatic or transformative changes.",
          "video": "The video to modify. Maximum video size is 100mb. Maximum video duration is 30 seconds.",
          "prompt": "A prompt to guide the video modification",
          "video_url": "Deprecated: Use video instead.",
          "first_frame": "An optional first frame of the video to modify. This should be a modified version of the original first frame, it will be used to guide the video modification.",
          "first_frame_url": "Deprecated: Use first_frame instead."
        }
      }
    },
    {
      "id": "prunaai/hidream-l1-dev",
      "name": "hidream-l1-dev",
      "displayName": "hidream-l1-dev",
      "provider": "replicate",
      "category": "image",
      "endpoint": "prunaai/hidream-l1-dev",
      "version": "4dfcd146c0def4812455415f55556f6bc84025dcb15193cf1977f01bd384d191",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This is an optimised version of the hidream-l1-dev model using the pruna ai optimisation toolkit!",
        "runCount": 35026,
        "confidence": 0.6,
        "qualityScore": 65.44402942363683,
        "createdAt": "2025-07-12T10:43:43.481256Z",
        "owner": "prunaai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/b5e6ec63-e2f4-4853-80e6-1f6c4b2b3f91/replicate-prediction-ba4msq0t.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "prompt": "a purple cheetah holding a sign that says \"pip install pruna\"",
              "model_type": "dev",
              "resolution": "1024 × 1024 (Square)",
              "speed_mode": "Juiced 🔥 (more speed)",
              "output_format": "jpg",
              "output_quality": 80
            },
            "output": "https://replicate.delivery/xezq/5esqQtfO9pmLE0XFKJTduLa69HZLRmv32d2BwrrlXQibjffTB/output_282642_0.jpeg",
            "prompt": "a purple cheetah holding a sign that says \"pip install pruna\""
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed (-1 for random)",
          "prompt": "Prompt",
          "model_type": "Model type",
          "resolution": "Output resolution",
          "speed_mode": "Speed optimization level",
          "output_format": "Output format",
          "output_quality": "Output quality (for jpg and webp)"
        }
      }
    },
    {
      "id": "wavespeedai/wan-2.1-t2v-720p",
      "name": "wan-2.1-t2v-720p",
      "displayName": "wan-2.1-t2v-720p",
      "provider": "replicate",
      "category": "video",
      "endpoint": "wavespeedai/wan-2.1-t2v-720p",
      "version": "df22ae8e2769aff950b2dfb121879bfe8068cbd96b23ee7a29d88303bf48979a",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Accelerated inference for Wan 2.1 14B text to video with high resolution, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation.",
        "runCount": 33658,
        "confidence": 0.9,
        "qualityScore": 65.27101209057119,
        "createdAt": "2025-03-27T21:57:49.393668Z",
        "owner": "wavespeedai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/7103ba38-865d-45c4-9860-bf92176556c3/replicate-prediction-f9vj14ba.webp",
        "githubUrl": "https://github.com/Wan-Video/Wan2.1",
        "paperUrl": null,
        "licenseUrl": "https://github.com/Wan-Video/Wan2.1/blob/main/LICENSE.txt",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "A smiling woman walking in London at night",
              "fast_mode": "Balanced",
              "num_frames": 81,
              "aspect_ratio": "16:9",
              "sample_shift": 5,
              "sample_steps": 30,
              "frames_per_second": 16,
              "sample_guide_scale": 5
            },
            "output": "https://replicate.delivery/xezq/0nyHDVe6ZkzsMKgc9ftDGHmpf0SfmrBg3jgkLg79IZCAKQTRB/output.mp4",
            "prompt": "A smiling woman walking in London at night"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Leave blank for random",
          "prompt": "Prompt for video generation",
          "fast_mode": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "num_frames": "Number of video frames. 81 frames give the best results",
          "aspect_ratio": "Aspect ratio of video. 16:9 corresponds to 1280x720px, 9:16 is 720x1280px, and 1:1 is 1024x1024px",
          "lora_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "sample_shift": "Sample shift factor",
          "sample_steps": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts",
          "frames_per_second": "Frames per second. Note that the pricing of this model is based on the video duration at 16 fps",
          "sample_guide_scale": "Higher guide scale makes prompt adherence better, but can reduce variation"
        }
      }
    },
    {
      "id": "prunaai/hidream-l1-full",
      "name": "hidream-l1-full",
      "displayName": "hidream-l1-full",
      "provider": "replicate",
      "category": "image",
      "endpoint": "prunaai/hidream-l1-full",
      "version": "03d58532fd29e39fd2ed80e86c3da1cebec28ef2734081cf1366710d30388f42",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This is an optimised version of the hidream-full model using the pruna ai optimisation toolkit!",
        "runCount": 25562,
        "confidence": 0.9,
        "qualityScore": 64.07611820025932,
        "createdAt": "2025-07-12T10:53:06.473517Z",
        "owner": "prunaai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/918d863a-64b7-4acc-bccf-7e7563140b74/replicate-prediction-ba4msq0t.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "seed": 1,
              "prompt": "a purple cheetah holding a sign that says \"pip install pruna\"",
              "model_type": "full",
              "resolution": "1024 × 1024 (Square)",
              "speed_mode": "Juiced 🔥 (more speed)",
              "output_format": "webp",
              "output_quality": 80
            },
            "output": "https://replicate.delivery/xezq/e3QREI1qAL35MaDmWkmI32KfcVFACwdowLMpKegEVoPeUefPF/output_1_0.webp",
            "prompt": "a purple cheetah holding a sign that says \"pip install pruna\""
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed (-1 for random)",
          "prompt": "Prompt",
          "model_type": "Model type",
          "resolution": "Output resolution",
          "speed_mode": "Speed optimization level",
          "output_format": "Output format",
          "output_quality": "Output quality (for jpg and webp)"
        }
      }
    },
    {
      "id": "resemble-ai/chatterbox",
      "name": "chatterbox",
      "displayName": "chatterbox",
      "provider": "replicate",
      "category": "audio",
      "endpoint": "resemble-ai/chatterbox",
      "version": "1b8422bc49635c20d0a84e387ed20879c0dd09254ecdb4e75dc4bec10ff94e97",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate expressive, natural speech. Features unique emotion control, instant voice cloning from short audio, and built-in watermarking.",
        "runCount": 24681,
        "confidence": 0.9,
        "qualityScore": 63.9238034797756,
        "createdAt": "2025-06-20T17:54:52.911035Z",
        "owner": "resemble-ai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/be316028-3121-4e4e-8bdf-7e6a8b02430f/Screenshot_2025-06-12_at_11.54.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/mit.md",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "seed": 0,
              "prompt": "We're excited to introduce Chatterbox, our first production-grade open source TTS model. Licensed under MIT, Chatterbox has been benchmarked against leading closed-source systems like ElevenLabs, and is consistently preferred in side-by-side evaluations.\n\nWhether you're working on memes, videos, games, or AI agents, Chatterbox brings your content to life. It's also the first open source TTS model to support emotion exaggeration control, a powerful feature that makes your voices stand out. Try it now on our Hugging Face Gradio app.\n\nIf you like the model but need to scale or finetune it for higher accuracy, check out our competitively priced TTS service (link). It delivers reliable performance with ultra-low latency of sub 200ms—ideal for production use in agents, applications, or interactive media.",
              "cfg_weight": 0.5,
              "temperature": 0.8,
              "exaggeration": 0.5
            },
            "output": "https://replicate.delivery/xezq/xx8Wscg0ve0gfko6krsG77SUuy7ZsQINBrJuRgq6GfCzJVspA/output.wav",
            "prompt": "We're excited to introduce Chatterbox, our first production-grade open source TTS model. Licensed under MIT, Chatterbox has been benchmarked against leading closed-source systems like ElevenLabs, and is consistently preferred in side-by-side evaluations.\n\nWhether you're working on memes, videos, games, or AI agents, Chatterbox brings your content to life. It's also the first open source TTS model to support emotion exaggeration control, a powerful feature that makes your voices stand out. Try it now on our Hugging Face Gradio app.\n\nIf you like the model but need to scale or finetune it for higher accuracy, check out our competitively priced TTS service (link). It delivers reliable performance with ultra-low latency of sub 200ms—ideal for production use in agents, applications, or interactive media."
          }
        ],
        "parameterDescriptions": {
          "seed": "Seed (0 for random)",
          "prompt": "Text to synthesize",
          "cfg_weight": "CFG/Pace weight",
          "temperature": "Temperature",
          "audio_prompt": "Path to the reference audio file (Optional)",
          "exaggeration": "Exaggeration (Neutral = 0.5, extreme values can be unstable)"
        }
      }
    },
    {
      "id": "pixverse/pixverse-v4",
      "name": "pixverse-v4",
      "displayName": "pixverse-v4",
      "provider": "replicate",
      "category": "video",
      "endpoint": "pixverse/pixverse-v4",
      "version": "b6e0ce28b9be22034e7e5b27022aeeac76f0ffa6aad3316c0a0a463dcf5d60ba",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Quickly generate smooth 5s or 8s videos at 540p, 720p or 1080p",
        "runCount": 22345,
        "confidence": 0.9,
        "qualityScore": 63.49199794429999,
        "createdAt": "2025-07-07T16:50:49.386885Z",
        "owner": "pixverse",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/daa1c364-fa52-4a13-922a-1bea888d62da/replicate-prediction-t1wrshv5.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://docs.pixverse.ai/PixVerse-Platform-Terms-of-Service-1773e99bf35080c6a802fae0e3629708",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "style": "None",
              "prompt": "a cute panda eating in the forest",
              "quality": "1080p",
              "duration": 5,
              "motion_mode": "normal",
              "aspect_ratio": "16:9",
              "negative_prompt": ""
            },
            "output": "https://replicate.delivery/xezq/mDkBKBJCUe3oTqbYB98SWOOQebwqWeTrwDVNN3C7wCfxJLpSB/tmpmc15wyjc.mp4",
            "prompt": "a cute panda eating in the forest"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "image": "Image to use for the first frame of the video",
          "style": "Style of the video",
          "effect": "Special effect to apply to the video. Does not work with last_frame_image.",
          "prompt": "Text prompt for video generation",
          "quality": "Resolution of the video. 360p and 540p cost the same, but 720p and 1080p cost more. See the README for details.",
          "duration": "Duration of the video in seconds. 8 second videos cost twice as much as 5 second videos. (1080p does not support 8 second duration)",
          "motion_mode": "Motion mode for the video. Smooth videos generate more frames, so they cost twice as much. (smooth is only available when using a 5 second duration, 1080p does not support smooth motion)",
          "aspect_ratio": "Aspect ratio of the video",
          "negative_prompt": "Negative prompt to avoid certain elements in the video",
          "last_frame_image": "Use to generate a video that transitions from the first image to the last image. Must be used with image.",
          "sound_effect_switch": "Enable background music or sound effects",
          "sound_effect_content": "Sound effect prompt. If not given, a random sound effect will be generated."
        }
      }
    },
    {
      "id": "prunaai/hidream-e1",
      "name": "hidream-e1",
      "displayName": "hidream-e1",
      "provider": "replicate",
      "category": "image",
      "endpoint": "prunaai/hidream-e1",
      "version": "ea6549775ccda226776338114de4369854113dd9ce2ab1249dc229b90357572e",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This is the hidream-e1 model accelerated with the pruna optimisation engine.",
        "runCount": 20744,
        "confidence": 0.9,
        "qualityScore": 63.16913439164992,
        "createdAt": "2025-05-02T12:45:09.919355Z",
        "owner": "prunaai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/c44ea7c8-9e4e-4567-b088-ea88c8ab3656/hi_dream_e1.png",
        "githubUrl": "https://github.com/HiDream-ai/HiDream-E1",
        "paperUrl": null,
        "licenseUrl": "https://github.com/HiDream-ai/HiDream-E1/blob/main/LICENSE",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "image": "https://raw.githubusercontent.com/HiDream-ai/HiDream-E1/refs/heads/main/assets/test_1.png",
              "prompt": "Convert the image into a 3D animated style.",
              "speed_mode": "Juiced 🔥 (more speed)",
              "output_format": "webp",
              "guidance_scale": 3.5,
              "output_quality": 80,
              "num_inference_steps": 28,
              "image_guidance_scale": 2
            },
            "output": "https://replicate.delivery/xezq/qfpKFquQmWzVSSFiqw9I6gl7WrpkyAU1zs59maNYXpW6iTUKA/output_943945_0.webp",
            "prompt": "Convert the image into a 3D animated style."
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed (-1 for random)",
          "image": "Input image to edit.",
          "prompt": "Prompt",
          "speed_mode": "Speed optimization level",
          "output_format": "Output format",
          "guidance_scale": "Guidance scale",
          "output_quality": "Output quality (for jpg and webp)",
          "num_inference_steps": "Number of inference steps",
          "image_guidance_scale": "Image guidance scale"
        }
      }
    },
    {
      "id": "kwaivgi/kling-v2.1-master",
      "name": "kling-v2.1-master",
      "displayName": "kling-v2.1-master",
      "provider": "replicate",
      "category": "video",
      "endpoint": "kwaivgi/kling-v2.1-master",
      "version": "78b4eaa27c7ecc43822977e219c94b2e62584324ca193c55e88268b866e3e9d8",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "start_image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A premium version of Kling v2.1 with superb dynamics and prompt adherence. Generate 1080p 5s and 10s videos from text or an image",
        "runCount": 19382,
        "confidence": 0.9,
        "qualityScore": 62.87420995759831,
        "createdAt": "2025-06-19T20:58:48.378502Z",
        "owner": "kwaivgi",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/a7bd1bde-7a3e-4173-ad04-bf4071cb7592/replicate-kling-v21.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "a woman walking in a park",
              "duration": 5,
              "aspect_ratio": "16:9",
              "negative_prompt": ""
            },
            "output": "https://replicate.delivery/xezq/9uK7fv8Ahn3Kbam2dLehxXjxzsFiedPdWG086eeBRPdDZLEnC/tmp_07jswu0.mp4",
            "prompt": "a woman walking in a park"
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for video generation",
          "duration": "Duration of the video in seconds",
          "start_image": "First frame of the video (optional)",
          "aspect_ratio": "Aspect ratio of the video. Ignored if start_image is provided.",
          "negative_prompt": "Things you do not want to see in the video"
        }
      }
    },
    {
      "id": "openai/gpt-4.1",
      "name": "gpt-4.1",
      "displayName": "gpt-4.1",
      "provider": "replicate",
      "category": "image",
      "endpoint": "openai/gpt-4.1",
      "version": "42234efbcedd493f42e257df783bbe4bc9f9149ed40c52805df1784af867ec6b",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "OpenAI's Flagship GPT model for complex tasks.",
        "runCount": 53431,
        "confidence": 0.6,
        "qualityScore": 62.27801430456678,
        "createdAt": "2025-06-13T04:32:47.276556Z",
        "owner": "openai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/8dbaab0b-d3e7-4bae-8772-d7e1f879d537/gpt-4.1.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://openai.com/policies/",
        "pricing": {
          "tier": "premium"
        },
        "examples": [
          {
            "input": {
              "prompt": "What is happening in this image?",
              "image_input": [
                "https://replicate.delivery/pbxt/MvnA4wptE8FOHD44bKsfVj8hQdXSvdDAcFgYs5GEODou9OP9/4b2ebb2d-89d8-43de-bc84-51c380365a40.jpg"
              ],
              "temperature": 1,
              "system_prompt": "You are a helpful assistant."
            },
            "output": "In the image, someone is spreading butter on a slice of toast using a product labeled \"BUTTER STICK TYPE.\" The product resembles a glue stick, but it is meant for butter, allowing the user to easily apply butter to toast by rubbing the stick directly onto the bread. This is a creative and convenient way to spread butter, especially while the toast is still warm and the butter softens and melts quickly.",
            "prompt": "What is happening in this image?"
          }
        ],
        "parameterDescriptions": {
          "top_p": "Nucleus sampling parameter - the model considers the results of the tokens with top_p probability mass. (0.1 means only the tokens comprising the top 10% probability mass are considered.)",
          "prompt": "The prompt to send to the model. Do not use if using messages.",
          "messages": "A JSON string representing a list of messages. For example: [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]. If provided, prompt and system_prompt are ignored.",
          "image_input": "List of images to send to the model",
          "temperature": "Sampling temperature between 0 and 2",
          "system_prompt": "System prompt to set the assistant's behavior",
          "presence_penalty": "Presence penalty parameter - positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.",
          "frequency_penalty": "Frequency penalty parameter - positive values penalize the repetition of tokens.",
          "max_completion_tokens": "Maximum number of completion tokens to generate"
        }
      }
    },
    {
      "id": "openai/gpt-4o-mini-transcribe",
      "name": "gpt-4o-mini-transcribe",
      "displayName": "gpt-4o-mini-transcribe",
      "provider": "replicate",
      "category": "image",
      "endpoint": "openai/gpt-4o-mini-transcribe",
      "version": "be0f82db25554832bc0acbdbef3289bcb8be02fac4e2b1a120b28c45c1fd7bbd",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A speech-to-text model that uses GPT-4o mini to transcribe audio",
        "runCount": 512,
        "confidence": 0.6,
        "qualityScore": 62.10117365111816,
        "createdAt": "2025-05-20T15:10:22.573691Z",
        "owner": "openai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/08a83750-902c-4609-90ec-9f4517cee44f/4o-mini-transcribe.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://openai.com/policies/",
        "pricing": {
          "tier": "premium"
        },
        "examples": [
          {
            "input": {
              "language": "en",
              "audio_file": "https://replicate.delivery/xezq/ejt5KPWzFp25fUGtjPhwFmeeG5nFpCvu5zSMIySXnemTWn0lC/tmptuxz6n1z.mp3",
              "temperature": 0
            },
            "output": [
              "So",
              " we",
              " just",
              " added",
              " GPT",
              "-",
              "4",
              "o",
              " Mini",
              " Trans",
              "cribe",
              " to",
              " Rep",
              "licate",
              ",",
              " and",
              " thought",
              " you'd",
              " want",
              " to",
              " know",
              ".",
              " It's",
              " basically",
              " a",
              " speech",
              "-to",
              "-text",
              " model",
              " that",
              " uses",
              " GPT",
              "-",
              "4",
              "o",
              " Mini",
              " to",
              " turn",
              " your",
              " audio",
              " into",
              " text",
              ".",
              " The",
              " cool",
              " thing",
              " is",
              " that",
              " it's",
              " noticeably",
              " better",
              " than",
              " the",
              " Whisper",
              " models",
              " we've",
              " been",
              " using",
              ".",
              " F",
              "ewer",
              " errors",
              ",",
              " better",
              " at",
              " recognizing",
              " different",
              " languages",
              ",",
              " and",
              " just",
              " more",
              " accurate",
              " overall",
              ".",
              " If",
              " you've",
              " ever",
              " been",
              " frustrated",
              " with",
              " transcripts",
              " that",
              " mess",
              " up",
              " technical",
              " terms",
              " or",
              " struggle",
              " with",
              " different",
              " accents",
              ",",
              " you'll",
              " probably",
              " appreciate",
              " this",
              " upgrade",
              ".",
              " It",
              " just",
              " works",
              " better",
              ".",
              " Some",
              " quick",
              " tech",
              " specs",
              " if",
              " you're",
              " curious",
              ".",
              " It",
              " has",
              " a",
              " ",
              "16",
              ",",
              "000",
              " token",
              " context",
              " window",
              ",",
              " which",
              " means",
              " it",
              " can",
              " handle",
              " longer",
              " audio",
              " clips",
              " in",
              " one",
              " go",
              ".",
              " And",
              " it",
              " can",
              " output",
              " up",
              " to",
              " ",
              "2",
              ",",
              "000",
              " tokens",
              ",",
              " so",
              " you'll",
              " get",
              " nice",
              " complete",
              " transcripts",
              ".",
              " The",
              " model",
              "'s",
              " knowledge",
              " is",
              " current",
              " up",
              " to",
              " June",
              " ",
              "202",
              "4",
              "."
            ]
          }
        ],
        "parameterDescriptions": {
          "prompt": "An optional text to guide the model's style or continue a previous audio segment. The prompt should match the audio language.",
          "language": "The language of the input audio. Supplying the input language in ISO-639-1 (e.g. en) format will improve accuracy and latency.",
          "audio_file": "The audio file to transcribe. Supported formats: mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm",
          "temperature": "Sampling temperature between 0 and 1"
        }
      }
    },
    {
      "id": "minimax/hailuo-02",
      "name": "hailuo-02",
      "displayName": "hailuo-02",
      "provider": "replicate",
      "category": "video",
      "endpoint": "minimax/hailuo-02",
      "version": "5a1267d7f3883d30b47a8ddfe5eb25cc16d00aa667ba26552295fc48477759ad",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Hailuo 2 is a text-to-video and image-to-video model that can make 6s or 10s videos at 720p (standard) or 1080p (pro). It excels at real world physics.",
        "runCount": 15585,
        "confidence": 0.9,
        "qualityScore": 61.92734671903164,
        "createdAt": "2025-07-08T09:28:02.610117Z",
        "owner": "minimax",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/e2953b9d-ef83-4a4a-b90f-1ef168223bf2/tmpbufkswx1.mp4",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "a dog speed climbs up a climbing wall at the olympics",
              "duration": 6,
              "resolution": "1080p",
              "prompt_optimizer": false
            },
            "output": "https://replicate.delivery/xezq/NLybk0ySU6qKANmOJ5xzKJx28Q8x5rk4PZey7eeoC7qiIg5pA/tmpbufkswx1.mp4",
            "prompt": "a dog speed climbs up a climbing wall at the olympics"
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for generation",
          "duration": "Duration of the video in seconds. 10 seconds is only available for 768p resolution.",
          "resolution": "Pick between standard 768p, or pro 1080p resolution. The pro model is not just high resolution, it is also higher quality.",
          "prompt_optimizer": "Use prompt optimizer",
          "first_frame_image": "First frame image for video generation. The output video will have the same aspect ratio as this image."
        }
      }
    },
    {
      "id": "lucataco/flux-dev-multi-lora",
      "name": "flux-dev-multi-lora",
      "displayName": "flux-dev-multi-lora",
      "provider": "replicate",
      "category": "image",
      "endpoint": "lucataco/flux-dev-multi-lora",
      "version": "ad0314563856e714367fdc7244b19b160d25926d305fec270c9e00f64665d352",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "FLUX.1-Dev Multi LoRA Explorer",
        "runCount": 1534192,
        "confidence": 0.6,
        "qualityScore": 61.858799968767315,
        "createdAt": "2025-06-11T18:42:43.531147Z",
        "owner": "lucataco",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/3d4f9bfe-ba25-4cb7-8835-8c1ef22446ec/hf-explorer.png",
        "githubUrl": "https://github.com/lucataco/cog-flux-dev-multi-lora",
        "paperUrl": null,
        "licenseUrl": "https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "pnt style Illustration of TOK with purple hair",
              "hf_loras": [
                "https://replicate.delivery/yhqm/9vSmRCa8Vv7bFtKfCfXTRzTq4X71tZW0LtLCb1l49bTSo8TTA/trained_model.tar",
                "https://civitai.com/api/download/models/735262?type=Model&format=SafeTensor"
              ],
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3.5,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/yhqm/bwfxyfj2Phvg3kO4eBQZOqryT6m7aNzW2oQ2o2hnZCMQC4HnA/out-0.webp"
            ],
            "prompt": "pnt style Illustration of TOK with purple hair"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image mode. The aspect ratio of your output will match this image",
          "prompt": "Prompt for generated image",
          "hf_loras": "Huggingface path, or URL to the LoRA weights. Ex: alvdansen/frosting_lane_flux",
          "lora_scales": "Scale for the LoRA weights. Default value is 0.8",
          "num_outputs": "Number of images to output.",
          "aspect_ratio": "Aspect ratio for the generated image",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength (or denoising strength) when using image to image. 1.0 corresponds to full destruction of information in image.",
          "num_inference_steps": "Number of inference steps",
          "disable_safety_checker": "Disable safety checker for generated images. This feature is only available through the API. See [https://replicate.com/docs/how-does-replicate-work#safety](https://replicate.com/docs/how-does-replicate-work#safety)"
        }
      }
    },
    {
      "id": "zsxkib/step1x-edit",
      "name": "step1x-edit",
      "displayName": "step1x-edit",
      "provider": "replicate",
      "category": "image",
      "endpoint": "zsxkib/step1x-edit",
      "version": "12b5a5a61e3419f792eb56cfc16eed046252740ebf5d470228f9b4cf2c861610",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "✍️Step1X-Edit by stepfun-ai, Edit an image using text prompt📸",
        "runCount": 13995,
        "confidence": 0.9,
        "qualityScore": 61.460039338108686,
        "createdAt": "2025-04-30T15:01:55.536251Z",
        "owner": "zsxkib",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/76860a08-e642-448c-a1f0-c36c02c8be17/step1.webp",
        "githubUrl": "https://github.com/zsxkib/cog-Step1X-Edit/",
        "paperUrl": "https://arxiv.org/abs/2504.17761",
        "licenseUrl": "https://github.com/stepfun-ai/Step1X-Edit#Apache-2.0-1-ov-file",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/MvZmCkr5rzQLtsfOGziHpX7OK2kbRC5fAmAcVk39JQotwzmD/image.png",
              "prompt": "replace moth with a small humming bird",
              "size_level": 512,
              "output_format": "webp",
              "output_quality": 80
            },
            "output": "https://replicate.delivery/yhqm/jk5dmx205greBCNJCEwo3Ugexu1TR0GoorXxfrPjUyd14qQpA/step1x_edit_output.webp",
            "prompt": "replace moth with a small humming bird"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible results (leave blank for random)",
          "image": "Input image",
          "prompt": "Editing instruction prompt",
          "size_level": "Internal resolution (larger values process slower but may capture finer details)",
          "output_format": "Output image format",
          "output_quality": "Compression quality for JPEG / WebP (1-100)"
        }
      }
    },
    {
      "id": "google/lyria-2",
      "name": "lyria-2",
      "displayName": "lyria-2",
      "provider": "replicate",
      "category": "audio",
      "endpoint": "google/lyria-2",
      "version": "a7e8d3fd87b875af2897e25dbde07888be1621bf18915b40a1a82543f5c0ab01",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Lyria 2 is a music generation model that produces 48kHz stereo audio through text-based prompts",
        "runCount": 13685,
        "confidence": 0.9,
        "qualityScore": 61.36276535660292,
        "createdAt": "2025-05-23T19:42:36.346642Z",
        "owner": "google",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/f3428ac0-77ec-4f35-9595-0bf6f06ba3e9/lyria-cover.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "Futuristic country music, steel guitar, huge 808s, synth wave elements space western cosmic twang soaring vocals"
            },
            "output": "https://replicate.delivery/xezq/Y0x45mFBx2quHtbV2zDziqN7OQregFGz1fQJmlAlo7PzMkvUA/tmp4nd9s3e0.wav",
            "prompt": "Futuristic country music, steel guitar, huge 808s, synth wave elements space western cosmic twang soaring vocals"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Omit for random generations",
          "prompt": "Text prompt for audio generation",
          "negative_prompt": "Description of what to exclude from the generated audio"
        }
      }
    },
    {
      "id": "leonardoai/phoenix-1.0",
      "name": "phoenix-1.0",
      "displayName": "phoenix-1.0",
      "provider": "replicate",
      "category": "image",
      "endpoint": "leonardoai/phoenix-1.0",
      "version": "33aec08b8e8084b71f5d5cda4f7e87f2431839cfaaf7d48d0136bb658bfa5827",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Leonardo AI’s first foundational model produces images up to 5 megapixels (fast, quality and ultra modes)",
        "runCount": 12463,
        "confidence": 0.6,
        "qualityScore": 60.95657440328489,
        "createdAt": "2025-05-28T14:59:52.119803Z",
        "owner": "leonardoai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/fd53e52e-39e9-4046-91da-0625100786ce/replicate-prediction-8wt0k2bgj.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "style": "cinematic",
              "prompt": "A majestic mountain landscape at sunset with snow-capped peaks reflecting golden light",
              "contrast": "medium",
              "num_images": 1,
              "aspect_ratio": "16:9",
              "prompt_enhance": true,
              "generation_mode": "quality"
            },
            "output": [
              "https://replicate.delivery/xezq/TfgAfuRIunuQiE5h0nVOjRAsZnnyftxLqt0G9iQKfcNXY3ETB/tmpn6fg4zxd.png"
            ],
            "prompt": "A majestic mountain landscape at sunset with snow-capped peaks reflecting golden light"
          }
        ],
        "parameterDescriptions": {
          "style": "Style to use for the output image",
          "prompt": "Text prompt for generation",
          "contrast": "Contrast level",
          "num_images": "Number of images to generate",
          "aspect_ratio": "Aspect ratio of the output image",
          "prompt_enhance": "Whether to enhance the prompt",
          "generation_mode": "Generation mode"
        }
      }
    },
    {
      "id": "google/imagen-4",
      "name": "imagen-4",
      "displayName": "imagen-4",
      "provider": "replicate",
      "category": "image",
      "endpoint": "google/imagen-4",
      "version": "a8f9c814c3d5320efea33e3a8780f79bea76966374f37d5d87bae2eb50fbc91a",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Google's Imagen 4 flagship model",
        "runCount": 1236524,
        "confidence": 0.9,
        "qualityScore": 60.922029013299806,
        "createdAt": "2025-07-18T16:01:03.661952Z",
        "owner": "google",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/895ffdc5-07d6-4b16-ac62-b27ba5b24468/4ccgkq0a6xrm80cpykfszajfaw.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "The photo: Create a cinematic, photorealistic medium shot capturing the nostalgic warmth of a late 90s indie film. The focus is a young woman with brightly dyed pink-gold hair and freckled skin, looking directly and intently into the camera lens with a hopeful yet slightly uncertain smile, she is slightly off-center. She wears an oversized, vintage band t-shirt that says \"Replicate\" (slightly worn) over a long-sleeved striped top and simple silver stud earrings. The lighting is soft, golden hour sunlight streaming through a slightly dusty window, creating lens flare and illuminating dust motes in the air. The background shows a blurred, cluttered bedroom with posters on the wall and fairy lights, rendered with a shallow depth of field. Natural film grain, a warm, slightly muted color palette, and sharp focus on her expressive eyes enhance the intimate, authentic feel",
              "aspect_ratio": "16:9",
              "safety_filter_level": "block_medium_and_above"
            },
            "output": "https://replicate.delivery/xezq/vfRlemVaYMuINEe8KCCmeJT6V3Dv7S45rxMhIgnST2Q7wkelC/tmp4mqrs3rp.png",
            "prompt": "The photo: Create a cinematic, photorealistic medium shot capturing the nostalgic warmth of a late 90s indie film. The focus is a young woman with brightly dyed pink-gold hair and freckled skin, looking directly and intently into the camera lens with a hopeful yet slightly uncertain smile, she is slightly off-center. She wears an oversized, vintage band t-shirt that says \"Replicate\" (slightly worn) over a long-sleeved striped top and simple silver stud earrings. The lighting is soft, golden hour sunlight streaming through a slightly dusty window, creating lens flare and illuminating dust motes in the air. The background shows a blurred, cluttered bedroom with posters on the wall and fairy lights, rendered with a shallow depth of field. Natural film grain, a warm, slightly muted color palette, and sharp focus on her expressive eyes enhance the intimate, authentic feel"
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for image generation",
          "aspect_ratio": "Aspect ratio of the generated image",
          "output_format": "Format of the output image",
          "safety_filter_level": "block_low_and_above is strictest, block_medium_and_above blocks some prompts, block_only_high is most permissive but some prompts will still be blocked"
        }
      }
    },
    {
      "id": "devgmstudios/pony-realism-v23",
      "name": "pony-realism-v23",
      "displayName": "pony-realism-v23",
      "provider": "replicate",
      "category": "image",
      "endpoint": "devgmstudios/pony-realism-v23",
      "version": "fc052d05249cf7a1657f004eddc1e5f50618aa11cb2df19b960c377ee8a7ceb3",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Latest Pony Realism Model. Try it with WEIGHTS on creatorframes.com",
        "runCount": 10405,
        "confidence": 0.9,
        "qualityScore": 60.17283821560018,
        "createdAt": "2025-06-18T09:26:52.017693Z",
        "owner": "devgmstudios",
        "coverImage": "https://replicate.delivery/xezq/SvecwVhvYoy9ESpzUOP9scgcBIlvH1M9kzF5TzMs1Gg5dHbKA/output.png",
        "githubUrl": null,
        "paperUrl": "https://creatorframes.com",
        "licenseUrl": "https://creatorframes.com",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "model": "ponyRealism_V23.safetensors",
              "steps": 35,
              "width": 1024,
              "height": 1024,
              "prompt": "1girl, cat girl, cat ears, cat tail, yellow eyes, white hair, bob cut, from side, scenery, sunset",
              "cfg_scale": 7,
              "scheduler": "DPM++ 2M SDE Karras",
              "batch_size": 1,
              "negative_prompt": "animal, cat, dog",
              "guidance_rescale": 0.7,
              "prepend_preprompt": true
            },
            "output": "https://replicate.delivery/xezq/SvecwVhvYoy9ESpzUOP9scgcBIlvH1M9kzF5TzMs1Gg5dHbKA/output.png",
            "prompt": "1girl, cat girl, cat ears, cat tail, yellow eyes, white hair, bob cut, from side, scenery, sunset"
          }
        ],
        "parameterDescriptions": {
          "model": "The model to use",
          "prepend_preprompt": "Prepend quality preprompt"
        }
      }
    },
    {
      "id": "ideogram-ai/ideogram-v2a",
      "name": "ideogram-v2a",
      "displayName": "ideogram-v2a",
      "provider": "replicate",
      "category": "image",
      "endpoint": "ideogram-ai/ideogram-v2a",
      "version": "4f8774263c3eef920c94916a3cb6a064ed04b06a7aef2af1ffebe0803ada3497",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Like Ideogram v2, but faster and cheaper",
        "runCount": 1031199,
        "confidence": 0.9,
        "qualityScore": 60.13342904345347,
        "createdAt": "2025-02-27T11:56:28.015284Z",
        "owner": "ideogram-ai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/6e45e974-f381-435a-b9dd-23f3e6801c19/replicate-prediction-1yv65m0q.webp",
        "githubUrl": null,
        "paperUrl": "https://ideogram.ai/",
        "licenseUrl": "https://about.ideogram.ai/legal/api-tos",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "Vector art of a friendly robot, in a speech bubble it says \"Hello! I'm Ideogram V2A\" in a friendly font, in a second speech bubble it says \"I'm faster!\", the robot is in a 3D garden",
              "resolution": "None",
              "style_type": "None",
              "aspect_ratio": "3:2",
              "magic_prompt_option": "Auto"
            },
            "output": "https://replicate.delivery/xezq/QYvIf0JBe8kd4UDVLm1XxxdtYfva6jVmVUZwJfonkuQOef3EF/tmp682z_d3p.png",
            "prompt": "Vector art of a friendly robot, in a speech bubble it says \"Hello! I'm Ideogram V2A\" in a friendly font, in a second speech bubble it says \"I'm faster!\", the robot is in a 3D garden"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Text prompt for image generation",
          "resolution": "Resolution. Overrides aspect ratio. Ignored if an inpainting image is given.",
          "style_type": "The styles help define the specific aesthetic of the image you want to generate.",
          "aspect_ratio": "Aspect ratio. Ignored if a resolution or inpainting image is given.",
          "magic_prompt_option": "Magic Prompt will interpret your prompt and optimize it to maximize variety and quality of the images generated. You can also use it to write prompts in different languages."
        }
      }
    },
    {
      "id": "prunaai/vace-14b",
      "name": "vace-14b",
      "displayName": "vace-14b",
      "provider": "replicate",
      "category": "video",
      "endpoint": "prunaai/vace-14b",
      "version": "51299232dc3d0946d5f5ed74935d85243e172698f747d291460db1e6ef3669fb",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This is a faster VACE-14B model, optimised with pruna, contact us for more at pruna.ai",
        "runCount": 10179,
        "confidence": 0.9,
        "qualityScore": 60.0774777800074,
        "createdAt": "2025-06-10T16:48:52.970283Z",
        "owner": "prunaai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/e0d87648-b5af-44e0-83cc-0be03e27ccc2/wan-vace-cover.webp",
        "githubUrl": "https://github.com/ali-vilab/VACE",
        "paperUrl": "https://arxiv.org/abs/2503.07598",
        "licenseUrl": "https://github.com/ali-vilab/VACE?tab=Apache-2.0-1-ov-file",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "size": "1280*720",
              "prompt": "The video shows a man riding a horse on a vast grassland. He has long lavender hair and wears a traditional dress of a white top and black pants. The animation style makes him look like he is doing some kind of outdoor activity or performing. The background is a spectacular mountain range and cloud sky, giving a sense of tranquility and vastness. The entire video is shot from a fixed angle, focusing on the rider and his horse.",
              "src_mask": "https://replicate.delivery/pbxt/N323tegI7AuoZmg0U5CuTKa7VBFC4gymhe0kT8Jk3o2sjUUj/src_mask.mp4",
              "frame_num": 81,
              "src_video": "https://replicate.delivery/pbxt/N323u1ljtNYyyaLrgw0ZLmXgepvWlBvxbJWi3sAa2VDPuNus/src_video.mp4",
              "speed_mode": "Extra Juiced 🚀 (even more speed)",
              "sample_shift": 16,
              "sample_steps": 50,
              "sample_solver": "unipc",
              "src_ref_images": [
                "https://replicate.delivery/pbxt/N323t5X69JB1MPD4w4cDIxK4rm0BG0W2JOWBrDrR4O9HTcyp/src_ref_image_1.png"
              ],
              "sample_guide_scale": 5
            },
            "output": "https://replicate.delivery/xezq/C3yTO4cNy45TOlUdAhJLV9oQdm7cFkVQVst0G8hVKCVJkuLF/output.mp4",
            "prompt": "The video shows a man riding a horse on a vast grassland. He has long lavender hair and wears a traditional dress of a white top and black pants. The animation style makes him look like he is doing some kind of outdoor activity or performing. The background is a spectacular mountain range and cloud sky, giving a sense of tranquility and vastness. The entire video is shot from a fixed angle, focusing on the rider and his horse."
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed (-1 for random)",
          "size": "Output resolution",
          "prompt": "Prompt",
          "src_mask": "Input mask video or image to edit.",
          "frame_num": "Number of frames to generate.",
          "src_video": "Input video to edit.",
          "speed_mode": "Speed optimization level",
          "sample_shift": "Sample shift",
          "sample_steps": "Sample steps",
          "sample_solver": "Sample solver",
          "src_ref_images": "Input reference images to edit.",
          "sample_guide_scale": "Sample guide scale"
        }
      }
    },
    {
      "id": "google/veo-3-fast",
      "name": "veo-3-fast",
      "displayName": "veo-3-fast",
      "provider": "replicate",
      "category": "video",
      "endpoint": "google/veo-3-fast",
      "version": "229d87b3f47c88b79767bd55279d20954e86a0dd9ed4383ea4f7c96d5194f2ef",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A faster and cheaper version of Google’s Veo 3 video model, with audio",
        "runCount": 9697,
        "confidence": 0.9,
        "qualityScore": 59.866821797795055,
        "createdAt": "2025-07-18T15:52:41.048294Z",
        "owner": "google",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/9f8c8990-2378-4a72-877e-6a0f09c66f3f/replicate-veo-3-fast.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "A hyper-speed superhero, resembling The Flash, is sprinting through a dense, dark forest at night. The trees blur into streaks of green and black as he moves. Fiery trails burst behind him with every stride, igniting parts of the underbrush in glowing embers. As he weaves between the trees, the blazing trail he leaves behind slowly forms the words 'VEO 3 FAST' in glowing, molten fire on the forest floor. The camera zooms up to show the entire text.",
              "enhance_prompt": true
            },
            "output": "https://replicate.delivery/xezq/xKos9IcrsrqrId3eA5bVZxD5m5jWRednYoECfsSaqASM9OeTB/tmpqa0xpc63.mp4",
            "prompt": "A hyper-speed superhero, resembling The Flash, is sprinting through a dense, dark forest at night. The trees blur into streaks of green and black as he moves. Fiery trails burst behind him with every stride, igniting parts of the underbrush in glowing embers. As he weaves between the trees, the blazing trail he leaves behind slowly forms the words 'VEO 3 FAST' in glowing, molten fire on the forest floor. The camera zooms up to show the entire text."
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Omit for random generations",
          "prompt": "Text prompt for video generation",
          "negative_prompt": "Description of what to discourage in the generated video"
        }
      }
    },
    {
      "id": "lucataco/qwq-32b",
      "name": "qwq-32b",
      "displayName": "qwq-32b",
      "provider": "replicate",
      "category": "image",
      "endpoint": "lucataco/qwq-32b",
      "version": "5a9425923f3ef1101dc663609a80cbd597dea6554a6b0c06483b949cb72603ed",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "QwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning",
        "runCount": 9180,
        "confidence": 0.6,
        "qualityScore": 59.62889987391791,
        "createdAt": "2025-03-06T17:01:29.711510Z",
        "owner": "lucataco",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/80e2b11c-eef7-4a03-bf0f-9325d2c24248/qwen2-padded2.png",
        "githubUrl": "https://github.com/lucataco/cog-ollama-qwq-32b",
        "paperUrl": "https://arxiv.org/abs/2309.00071",
        "licenseUrl": "https://huggingface.co/Qwen/QwQ-32B/blob/main/LICENSE",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": 42,
              "top_p": 1,
              "prompt": "How many r's are in the word: strawberry",
              "max_tokens": 512,
              "temperature": 0.6,
              "repeat_penalty": 1
            },
            "output": [
              "Let",
              "'s",
              " see",
              ".",
              " The",
              " word",
              " is",
              " \"",
              "str",
              "aw",
              "berry",
              ".\"",
              " I",
              " need",
              " to",
              " find",
              " out",
              " how",
              " many",
              " '",
              "r",
              "'s",
              " are",
              " in",
              " it",
              ".",
              " Okay",
              ",",
              " first",
              ",",
              " I",
              "'ll",
              " look",
              " at",
              " the",
              " word",
              ":",
              " s",
              "-t",
              "-r",
              "-a",
              "-w",
              "-b",
              "-e",
              "-r",
              "-r",
              "-y",
              ".",
              " So",
              ",",
              " I",
              " can",
              " see",
              " that",
              " there",
              " are",
              " '",
              "r",
              "'s",
              " in",
              " there",
              ".",
              " Let",
              " me",
              " count",
              " them",
              " one",
              " by",
              " one",
              ".\n\n",
              "First",
              " letter",
              ":",
              " s",
              ",",
              " not",
              " an",
              " '",
              "r",
              "'.\n\n",
              "Second",
              " letter",
              ":",
              " t",
              ",",
              " not",
              " an",
              " '",
              "r",
              "'.\n\n",
              "Third",
              " letter",
              ":",
              " r",
              ",",
              " that",
              "'s",
              " one",
              " '",
              "r",
              "'.\n\n",
              "Fourth",
              " letter",
              ":",
              " a",
              ",",
              " not",
              " an",
              " '",
              "r",
              "'.\n\n",
              "F",
              "ifth",
              " letter",
              ":",
              " w",
              ",",
              " not",
              " an",
              " '",
              "r",
              "'.\n\n",
              "Six",
              "th",
              " letter",
              ":",
              " b",
              ",",
              " not",
              " an",
              " '",
              "r",
              "'.\n\n",
              "Se",
              "venth",
              " letter",
              ":",
              " e",
              ",",
              " not",
              " an",
              " '",
              "r",
              "'.\n\n",
              "E",
              "ighth",
              " letter",
              ":",
              " r",
              ",",
              " that",
              "'s",
              " another",
              " '",
              "r",
              "'.\n\n",
              "N",
              "inth",
              " letter",
              ":",
              " r",
              ",",
              " yet",
              " another",
              " '",
              "r",
              "'.\n\n",
              "T",
              "enth",
              " letter",
              ":",
              " y",
              ",",
              " not",
              " an",
              " '",
              "r",
              "'.\n\n",
              "So",
              ",",
              " I",
              "'ve",
              " found",
              " three",
              " '",
              "r",
              "'s",
              " in",
              " the",
              " word",
              " \"",
              "str",
              "aw",
              "berry",
              ".\"",
              " Wait",
              ",",
              " but",
              " I",
              " remember",
              " that",
              " '",
              "r",
              "'",
              " appears",
              " multiple",
              " times",
              ".",
              " Let",
              " me",
              " double",
              "-check",
              ".\n\n",
              "S",
              "-t",
              "-r",
              "-a",
              "-w",
              "-b",
              "-e",
              "-r",
              "-r",
              "-y",
              ".\n\n",
              "First",
              " '",
              "r",
              "'",
              " is",
              " the",
              " third",
              " letter",
              ".\n\n",
              "Second",
              " '",
              "r",
              "'",
              " is",
              " the",
              " eighth",
              " letter",
              ".\n\n",
              "Third",
              " '",
              "r",
              "'",
              " is",
              " the",
              " ninth",
              " letter",
              ".\n\n",
              "Yes",
              ",",
              " that",
              "'s",
              " three",
              " '",
              "r",
              "'s",
              ".",
              " I",
              " think",
              " that",
              "'s",
              " correct",
              ".\n\n",
              "Alternatively",
              ",",
              " I",
              " could",
              " think",
              " about",
              " the",
              " pronunciation",
              " or",
              " the",
              " spelling",
              ",",
              " but",
              " really",
              ",",
              " it",
              "'s",
              " just",
              " a",
              " matter",
              " of",
              " counting",
              " the",
              " occurrences",
              " of",
              " the",
              " letter",
              " '",
              "r",
              "'",
              " in",
              " the",
              " word",
              ".\n\n",
              "So",
              ",",
              " the",
              " answer",
              " should",
              " be",
              " three",
              ".\n\n",
              "**",
              "Final",
              " Answer",
              "**\n\n",
              "\\[",
              " \\",
              "boxed",
              "{",
              "3",
              "}",
              " \\",
              "]",
              ""
            ],
            "prompt": "How many r's are in the word: strawberry"
          }
        ],
        "parameterDescriptions": {
          "seed": "0 for Random seed",
          "top_p": "Controls diversity of the output. Lower values make the output more focused, higher values make it more diverse.",
          "prompt": "Input text for the model",
          "max_tokens": "Maximum number of tokens it is allowed to generate",
          "temperature": "Controls randomness. Lower values make the model more deterministic, higher values make it more random.",
          "repeat_penalty": "Helps to reduce the repetition of tokens from the input. A higher value makes the model less likely to repeat tokens"
        }
      }
    },
    {
      "id": "zsxkib/infinite-you",
      "name": "infinite-you",
      "displayName": "infinite-you",
      "provider": "replicate",
      "category": "image",
      "endpoint": "zsxkib/infinite-you",
      "version": "b1370c5f5b1bb078eaa87332641c9cc6b89fff1bbd5c61f9e0e81370541b24f0",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Transform your portrait photos into any style or setting while preserving your facial identity",
        "runCount": 8654,
        "confidence": 0.9,
        "qualityScore": 59.37267072211413,
        "createdAt": "2025-04-03T13:22:42.643419Z",
        "owner": "zsxkib",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/447d5081-90a0-422d-b478-6f9a6e285f8e/comparative_results.jpg",
        "githubUrl": "https://github.com/zsxkib/cog-infiniteyou",
        "paperUrl": "https://arxiv.org/abs/2503.16418",
        "licenseUrl": "https://creativecommons.org/licenses/by-nc/4.0/legalcode",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "width": 864,
              "height": 1152,
              "prompt": "a woman with perfect eyes",
              "id_image": "https://replicate.delivery/pbxt/L0gy7uyLE5UP0uz12cndDdSOIgw5R3rV5N6G2pbt7kEK9dCr/0_3.webp",
              "num_steps": 30,
              "model_version": "sim_stage1",
              "enable_realism": true,
              "guidance_scale": 3.5,
              "enable_anti_blur": true,
              "infusenet_guidance_end": 1,
              "infusenet_guidance_start": 0,
              "infusenet_conditioning_scale": 1
            },
            "output": "https://replicate.delivery/xezq/kjv2jiLGfeo4QU4sLzIcG0knrGjUONRUnYM4s0WWUCDTIEfoA/output.webp",
            "prompt": "a woman with perfect eyes"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible results (None generates a random seed)",
          "width": "Output image width in pixels (recommended: 768, 864, or 960)",
          "height": "Output image height in pixels (recommended: 960, 1152, or 1280)",
          "prompt": "Describe how you want the generated image to look. Be specific about details, style, background, etc.",
          "id_image": "Upload a portrait image containing a human face. For multiple faces, only the largest face will be detected.",
          "num_steps": "Number of diffusion steps - higher values (30-50) give better quality but take longer",
          "control_image": "Optional: Upload a second image to control the pose/position of the face in the output",
          "model_version": "Choose the model version - 'aes_stage2' for better text-image alignment and aesthetics, 'sim_stage1' for higher identity similarity",
          "output_format": "Choose the format of the output image",
          "enable_realism": "Apply the realism enhancement LoRA for more realistic-looking results",
          "guidance_scale": "How closely to follow the prompt (higher = more prompt adherence, lower = more freedom)",
          "output_quality": "Set the quality of the output image for jpg and webp (1-100)",
          "enable_anti_blur": "Apply the anti-blur LoRA to reduce blurriness in the results",
          "infusenet_guidance_end": "Advanced: When to stop applying identity guidance (usually keep at 1.0)",
          "infusenet_guidance_start": "Advanced: When to start applying identity guidance (0.0-0.1 recommended)",
          "infusenet_conditioning_scale": "Advanced: Controls how strongly the identity image affects generation (lower values = less identity preservation)"
        }
      }
    },
    {
      "id": "luma/ray-2-720p",
      "name": "ray-2-720p",
      "displayName": "ray-2-720p",
      "provider": "replicate",
      "category": "video",
      "endpoint": "luma/ray-2-720p",
      "version": "ea6eddb9ec29298592b0a8da0aa8783d0cdb2493e87c93f36bbcab28ab133664",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "start_image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate 5s and 9s 720p videos",
        "runCount": 23691,
        "confidence": 0.9,
        "qualityScore": 58.74601723968907,
        "createdAt": "2025-07-25T12:01:02.082323Z",
        "owner": "luma",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/9f7981d1-4a66-4b89-818f-4eaf2d259868/replicate-prediction-_drtaEZI.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://lumalabs.ai/dream-machine/api/terms",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "loop": false,
              "prompt": "A pirate ship in a raging sea",
              "duration": 5,
              "aspect_ratio": "16:9"
            },
            "output": "https://replicate.delivery/czjl/QAYtRuTghFrPH1qgCx3C0a8WrQggBsGJ0yCCZLsSVuye8pEKA/tmpkq6t05vs.mp4",
            "prompt": "A pirate ship in a raging sea"
          }
        ],
        "parameterDescriptions": {
          "loop": "Whether the video should loop, with the last frame matching the first frame for smooth, continuous playback.",
          "prompt": "Text prompt for video generation",
          "concepts": "List of camera concepts to apply to the video generation. Concepts include: truck_left, pan_right, pedestal_down, low_angle, pedestal_up, selfie, pan_left, roll_right, zoom_in, over_the_shoulder, orbit_right, orbit_left, static, tiny_planet, high_angle, bolt_cam, dolly_zoom, overhead, zoom_out, handheld, roll_left, pov, aerial_drone, push_in, crane_down, truck_right, tilt_down, elevator_doors, tilt_up, ground_level, pull_out, aerial, crane_up, eye_level",
          "duration": "Duration of the video in seconds",
          "end_image": "An optional last frame of the video to use as the ending frame.",
          "start_image": "An optional first frame of the video to use as the starting frame.",
          "aspect_ratio": "Aspect ratio of the generated video",
          "end_image_url": "URL of an image to use as the ending frame",
          "start_image_url": "URL of an image to use as the starting frame"
        }
      }
    },
    {
      "id": "ostris/flux-dev-lora-trainer",
      "name": "flux-dev-lora-trainer",
      "displayName": "flux-dev-lora-trainer",
      "provider": "replicate",
      "category": "image",
      "endpoint": "ostris/flux-dev-lora-trainer",
      "version": "26dce37af90b9d997eeb970d92e47de3064d46c300504ae376c75bef6a9022d2",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Fine-tune FLUX.1-dev using ai-toolkit",
        "runCount": 717156,
        "confidence": 0.6,
        "qualityScore": 58.55614241817965,
        "createdAt": "2025-06-04T22:33:16.846524Z",
        "owner": "ostris",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/cf8c3935-e4bd-4b31-a207-b652d708aee0/ostris-cover-2.png",
        "githubUrl": "https://github.com/replicate/flux-fine-tuner",
        "paperUrl": null,
        "licenseUrl": "https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "puppy",
              "lora_scale": 1,
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3.5,
              "output_quality": 80,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/yhqm/udBhvWgBecyeAUYonPXfEAjRqvlUu426ZPYQmSxHQc7WN5pmA/out-0.webp"
            ],
            "prompt": "puppy"
          }
        ],
        "parameterDescriptions": {
          "mask": "Input mask for inpainting mode. Black areas will be preserved, white areas will be inpainted. Must be provided along with 'image' for inpainting mode.",
          "seed": "Random seed. Set for reproducible generation.",
          "image": "Input image for img2img or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inferences with. The dev model needs around 28 steps but the schnell model only needs around 4 steps.",
          "width": "Width of the generated image in text-to-image mode. Only used when aspect_ratio=custom. Must be a multiple of 16 (if it's not, it will be rounded to nearest multiple of 16). Note: Ignored in img2img and inpainting modes.",
          "height": "Height of the generated image in text-to-image mode. Only used when aspect_ratio=custom. Must be a multiple of 16 (if it's not, it will be rounded to nearest multiple of 16). Note: Ignored in img2img and inpainting modes.",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "extra_lora": "Combine this fine-tune with another LoRA. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1.",
          "num_outputs": "Number of images to output.",
          "aspect_ratio": "Aspect ratio for the generated image in text-to-image mode. The size will always be 1 megapixel, i.e. 1024x1024 if aspect ratio is 1:1. To use arbitrary width and height, set aspect ratio to 'custom'. Note: Ignored in img2img and inpainting modes.",
          "output_format": "Format of the output images.",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img / inpaint. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied.",
          "replicate_weights": "Replicate LoRA weights to use. Leave blank to use the default weights.",
          "num_inference_steps": "Number of inference steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "prunaai/wan-image",
      "name": "wan-image",
      "displayName": "wan-image",
      "provider": "replicate",
      "category": "image",
      "endpoint": "prunaai/wan-image",
      "version": "16e15e913fcc71c1a5defb335ea84739f99731fa1ee17995117c7d9adc6d176c",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This model generates beautiful cinematic 2 megapixel images in 3-6 seconds and is derived from the wan2.1 model through optimisation techniques from the pruna package",
        "runCount": 6779,
        "confidence": 0.6,
        "qualityScore": 58.312296938670634,
        "createdAt": "2025-07-17T12:36:16.199691Z",
        "owner": "prunaai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/4a0b1acf-473a-41d8-9e7c-e70ca5063ff7/replicate-prediction-37n3yfc9.jpeg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "juiced": false,
              "prompt": "a cat jumping in the air to catch a flying bird",
              "megapixels": 2,
              "aspect_ratio": "16:9",
              "output_format": "jpg",
              "output_quality": 80
            },
            "output": "https://replicate.delivery/xezq/sTOWPhTrh4LTBF70S0vjZ6B2L02l6Wa8ESfg3O1dzzMJ9zgKA/output_-1_0.jpeg",
            "prompt": "a cat jumping in the air to catch a flying bird"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "juiced": "Faster inference with additional optimizations.",
          "prompt": "Text prompt for image generation",
          "megapixels": "Approximate number of megapixels for generated image",
          "aspect_ratio": "Aspect ratio for the generated image",
          "output_format": "Format of the output images",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs"
        }
      }
    },
    {
      "id": "delta-lock/ponynai3",
      "name": "ponynai3",
      "displayName": "ponynai3",
      "provider": "replicate",
      "category": "image",
      "endpoint": "delta-lock/ponynai3",
      "version": "848da0d3e5a762b8662592acd1818003a3b4672f513d7250895bd0d96c6a48c9",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Models fine-tuned from Pony-XL series.",
        "runCount": 617640,
        "confidence": 0.6,
        "qualityScore": 57.907361174487086,
        "createdAt": "2025-05-11T10:52:19.672177Z",
        "owner": "delta-lock",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/28439a74-c5f0-4c57-8595-3b41eb6bc33c/ponyxl.webp",
        "githubUrl": "https://github.com/LagPixelLOL/cog-sdxl",
        "paperUrl": null,
        "licenseUrl": "https://github.com/LagPixelLOL/cog-sdxl/blob/main/LICENSE",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "vae": "default",
              "seed": -1,
              "model": "tPonynai3_v7",
              "steps": 35,
              "width": 1184,
              "height": 864,
              "prompt": "1girl",
              "strength": 0.7,
              "cfg_scale": 5,
              "clip_skip": 1,
              "pag_scale": 3,
              "scheduler": "Euler a",
              "batch_size": 1,
              "blur_factor": 5,
              "negative_prompt": "animal, cat, dog, big breasts",
              "guidance_rescale": 0.5,
              "prepend_preprompt": true
            },
            "output": [
              "https://replicate.delivery/xezq/Z0fpC39b1awejU1b0CqGnleieJnyd0p1ZHN7WW0KINJLDNuSB/0.png"
            ],
            "prompt": "1girl"
          }
        ],
        "parameterDescriptions": {
          "vae": "The VAE to use",
          "mask": "The mask for inpainting, white areas will be modified and black preserved (will be scaled then cropped to the set width and height)",
          "seed": "The seed used when generating, set to -1 to use a random seed",
          "image": "The image for image to image or as the base for inpainting (will be scaled then cropped to the set width and height)",
          "loras": "The LoRAs to use, must be either a string with format \"URL:Strength,URL:Strength,...\" (strength is optional, default to 1), or a JSON list dumped as a string containing key \"url\" (required), \"strength\" (optional, default to 1), and \"civitai_token\" (optional, for downloading from CivitAI) (NOTICE: Will download the weights, might take a while if the LoRAs are huge or the download is slow, WILL CHARGE WHEN DOWNLOADING)",
          "model": "The model to use",
          "steps": "The steps when generating",
          "width": "The width of the image",
          "height": "The height of the image",
          "prompt": "The prompt, uses Compel weighting syntax",
          "strength": "How much noise to add (for image to image and inpainting only, larger value indicates more noise added to the input image)",
          "cfg_scale": "CFG scale defines how much attention the model pays to the prompt when generating, set to 1 to disable",
          "clip_skip": "How many CLIP layers to skip, 1 is actually no skip, this is the behavior in A1111 so it's aligned to it",
          "pag_scale": "PAG scale is similar to CFG but it literally makes the result better, it's compatible with CFG too, set to 0 to disable",
          "scheduler": "The scheduler to use",
          "batch_size": "Number of images to generate (1-4), note if you set this to 4, some high resolution gens might fail because of not enough VRAM",
          "blur_factor": "The factor to blur the inpainting mask for smoother transition between masked and unmasked",
          "negative_prompt": "The negative prompt (for things you don't want), uses Compel weighting syntax",
          "guidance_rescale": "The amount to rescale CFG generated noise to avoid generating overexposed images, set to 0 or 1 to disable",
          "prepend_preprompt": "Prepend preprompt (Prompt: \"score_9, score_8_up, score_7_up, \" | Negative Prompt: \"score_4, score_3, score_2, score_1, worst quality, bad hands, bad feet, \")"
        }
      }
    },
    {
      "id": "kwaivgi/kling-v1.6-pro",
      "name": "kling-v1.6-pro",
      "displayName": "kling-v1.6-pro",
      "provider": "replicate",
      "category": "video",
      "endpoint": "kwaivgi/kling-v1.6-pro",
      "version": "03b02153924ef65cd57b7e561f3a4ed66db11c34218d2c70a8af198987edfa3d",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "start_image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate 5s and 10s videos in 1080p resolution",
        "runCount": 593979,
        "confidence": 0.9,
        "qualityScore": 57.73771822025186,
        "createdAt": "2025-06-04T12:45:42.249812Z",
        "owner": "kwaivgi",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/b5869fd6-a29c-4f71-bb6a-4a044ca43468/replicate-prediction-_brgJFCZ.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://docs.qingque.cn/d/home/eZQC4FkUthNLuEMk9AgXvH-et",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "Reflections in crystal mirrors, rainbow light, geometric world",
              "duration": 5,
              "cfg_scale": 0.5,
              "start_image": "https://replicate.delivery/pbxt/MNRLOqN0ASEzIG3YPuv9R1JSVGsSOQQzE3rgtVD9Qk230Lgt/image_fx_%20%285%29.jpg",
              "aspect_ratio": "16:9",
              "negative_prompt": ""
            },
            "output": "https://replicate.delivery/czjl/dLWqDLYlXD6yMdlorUshiJxZstZNDmjBj49F5OjPJZLWpECF/tmpe6j5tmkr.mp4",
            "prompt": "Reflections in crystal mirrors, rainbow light, geometric world"
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for video generation",
          "duration": "Duration of the video in seconds",
          "cfg_scale": "Flexibility in video generation; The higher the value, the lower the model's degree of flexibility, and the stronger the relevance to the user's prompt.",
          "end_image": "Last frame of the video. A start or end image is required.",
          "start_image": "First frame of the video. A start or end image is required.",
          "aspect_ratio": "Aspect ratio of the video. Ignored if start_image is provided.",
          "negative_prompt": "Things you do not want to see in the video",
          "reference_images": "Reference images to use in video generation (up to 4 images). Also known as scene elements."
        }
      }
    },
    {
      "id": "thefluxtrain/oye-cartoon",
      "name": "oye-cartoon",
      "displayName": "oye-cartoon",
      "provider": "replicate",
      "category": "image",
      "endpoint": "thefluxtrain/oye-cartoon",
      "version": "43fae779ef3b0ad14b0dd49bb95a9ab1a06bbfebfbc1cebf95919dfb462a6786",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This model generates pose variation of a cartoon character. It preserves the cartoon identity. Use this model to augment training dataset for any cartoon character created through AI. The augmented dataset can be used to train a LoRA model.",
        "runCount": 5657,
        "confidence": 0.9,
        "qualityScore": 57.52662943120972,
        "createdAt": "2025-06-03T15:46:32.430009Z",
        "owner": "thefluxtrain",
        "coverImage": "https://replicate.delivery/yhqm/5SPtvl2AEY6aEJgrPaKI46fv3WsjBNj9lEdH4uVpiLGfVkPUA/out.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://github.com/black-forest-labs/flux/blob/main/model_licenses/LICENSE-FLUX1-dev",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "lora": "saquiboye/oye-cartoon",
              "image": "https://replicate.delivery/pbxt/MJa5EcWl474qATQBgPfKV1gQuz9UgxB2kXvUKUy11fefB96N/or.jpg",
              "model": "oye-cartoon-v2",
              "prompt": "a man cartoon character, sitting on a chair. brown pants",
              "strength": 0.6,
              "predictive": 0,
              "weight_name": "pytorch_lora_weights.safetensors",
              "guidance_scale": 7.5,
              "image_strength": 1,
              "position_delta": -16,
              "num_inference_steps": 50
            },
            "output": "https://replicate.delivery/yhqm/5SPtvl2AEY6aEJgrPaKI46fv3WsjBNj9lEdH4uVpiLGfVkPUA/out.png",
            "prompt": "a man cartoon character, sitting on a chair. brown pants"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Leave blank to randomize the seed",
          "width": "Width of the output image",
          "height": "Height of the output image",
          "prompt": "Input prompt.",
          "controls": "JSON string of control models to use",
          "strength": "Strength of the inpainting",
          "is_runpod": "Is this running on RunPod?",
          "init_image": "Initial image for inpainting",
          "mask_image": "Mask image for inpainting",
          "predictive": "Predict similarity",
          "crop_inpaint": "Crop the image for inpainting",
          "guidance_scale": "Scale for classifier-free guidance",
          "condition_image": "Condition image",
          "condition_model": "Condition model",
          "condition_strength": "Condition strength",
          "num_inference_steps": "Number of denoising steps",
          "do_differential_inpaint": "Do differential inpainting?"
        }
      }
    },
    {
      "id": "aaronaftab/mirage-ghibli",
      "name": "mirage-ghibli",
      "displayName": "mirage-ghibli",
      "provider": "replicate",
      "category": "image",
      "endpoint": "aaronaftab/mirage-ghibli",
      "version": "166efd159b4138da932522bc5af40d39194033f587d9bdbab1e594119eae3e7f",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Ghiblify any image, 10x cheaper/faster than GPT 4o",
        "runCount": 562458,
        "confidence": 0.6,
        "qualityScore": 57.500908703874494,
        "createdAt": "2025-03-28T11:07:47.289350Z",
        "owner": "aaronaftab",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/1bc88cb5-667d-48f7-ad41-18f5aff08dcd/ghibli.png",
        "githubUrl": "https://github.com/aaronaftab/mirage",
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/Mjo5VWBA0fm8oq3BefpbdtXeJitBJc6AobPnnMdFxxCKzT3P/linkedin.jpeg",
              "model": "dev",
              "prompt": "GHBLI anime style photo",
              "go_fast": true,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 10,
              "output_quality": 80,
              "prompt_strength": 0.77,
              "extra_lora_scale": 1,
              "num_inference_steps": 38
            },
            "output": [
              "https://replicate.delivery/xezq/gFJeG888ltyHEioGbyfeuMBI8euc2Hxfos00Gc6OpjzZ8ejHF/out-0.webp"
            ],
            "prompt": "GHBLI anime style photo"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "simbrams/ri",
      "name": "ri",
      "displayName": "ri",
      "provider": "replicate",
      "category": "image",
      "endpoint": "simbrams/ri",
      "version": "19e347b11e1ca602b1719e4fa0037b8bbbf2308d3e8b4c65c670166cccc95fc5",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Realistic Inpainting with ControlNET (M-LSD + SEG)",
        "runCount": 546326,
        "confidence": 0.6,
        "qualityScore": 57.37452664291358,
        "createdAt": "2025-07-24T13:25:32.568156Z",
        "owner": "simbrams",
        "coverImage": "https://replicate.delivery/pbxt/TeezN5ZlDdrLn0En61Dgyr9chzfVKomocgMXyVUWLsWMDWhlA/output.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "mask": "https://replicate.delivery/pbxt/Kr4zOeVczJ77u6tLhq1ot1AwkVDNiYaSBOQPQVnQ9GsCE1qF/download%20%2864%29.png",
              "debug": false,
              "image": "https://replicate.delivery/pbxt/Kr4zOwBtTGD37lNectXL4pHOwsrEnHeKRK0pZdi0KeDqxxdx/download%20%283%29.jpeg",
              "steps": 20,
              "prompt": "RAW photo of a desert in the Sahara with a road",
              "strength": 0.95,
              "blur_mask": true,
              "scheduler": "MultistepDPM-Solver-Default",
              "image_size": 960,
              "keep_alive": false,
              "blur_radius": 10,
              "guidance_scale": 7.5,
              "negative_prompt": "(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck",
              "preserve_elements": true
            },
            "output": [
              "https://replicate.delivery/pbxt/TeezN5ZlDdrLn0En61Dgyr9chzfVKomocgMXyVUWLsWMDWhlA/output.png"
            ],
            "prompt": "RAW photo of a desert in the Sahara with a road"
          }
        ],
        "parameterDescriptions": {
          "eta": "eta",
          "mask": "Mask image",
          "seed": "Leave blank to randomize",
          "debug": "Debug mode",
          "image": "Input image",
          "steps": " num_inference_steps",
          "strength": "strength/weight",
          "blur_mask": "Blur the mask",
          "do_resize": "Resize the image",
          "scheduler": "Choose a scheduler",
          "image_size": "Image size",
          "keep_alive": "Keep model alive",
          "blur_radius": "Blur radius",
          "only_objects": "Modify only the objects",
          "seg_strength": "seg_strength",
          "mlsd_strength": "mlsd_strength",
          "tile_strength": "tile_strength",
          "canny_strength": "canny_strength",
          "guidance_scale": "guidance_scale",
          "upscale_factor": "upscale_factor",
          "dilation_factor": "Mask dilation factor (0 for no dilation)",
          "preserve_elements": "preserve_elements"
        }
      }
    },
    {
      "id": "black-forest-labs/flux-pro-finetuned",
      "name": "flux-pro-finetuned",
      "displayName": "flux-pro-finetuned",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-pro-finetuned",
      "version": "fffbc699c16b5e64eb0605071852bd6f0a5de8a50cc8f6e698cd15e3e01ee310",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Inference model for FLUX.1 [pro] using custom `finetune_id`",
        "runCount": 4718,
        "confidence": 0.9,
        "qualityScore": 56.738499773429496,
        "createdAt": "2025-06-03T12:20:26.617055Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/f311118a-a8c4-4aa5-abb0-40a347ec4bad/flux-pro-finetuned-cover.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://replicate.com/black-forest-labs/flux-pro#license",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "steps": 40,
              "prompt": "A formula one CYBERCAB car",
              "guidance": 3,
              "finetune_id": "fc14d7bf-95bd-4dde-92c1-2dd7317721f6",
              "aspect_ratio": "3:2",
              "output_format": "jpg",
              "safety_tolerance": 2,
              "finetune_strength": 1,
              "prompt_upsampling": false
            },
            "output": "https://replicate.delivery/xezq/1tqX4qNG67ZANNXKauc0CVReVmclyKe53FazX2mqnJC6RJzUA/tmpspn25fph.jpg",
            "prompt": "A formula one CYBERCAB car"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "steps": "Number of diffusion steps",
          "width": "Width of the generated image in text-to-image mode. Only used when aspect_ratio=custom. Must be a multiple of 32 (if it's not, it will be rounded to nearest multiple of 32). Note: Ignored in img2img and inpainting modes.",
          "height": "Height of the generated image in text-to-image mode. Only used when aspect_ratio=custom. Must be a multiple of 32 (if it's not, it will be rounded to nearest multiple of 32). Note: Ignored in img2img and inpainting modes.",
          "prompt": "Text prompt for image generation",
          "guidance": "Controls the balance between adherence to the text prompt and image quality/diversity. Higher values make the output more closely match the prompt but may reduce overall image quality. Lower values allow for more creative freedom but might produce results less relevant to the prompt.",
          "finetune_id": "Finetune ID for making images using a previously trained fine-tune. Only IDs from trainings made using Replicate's Flux Pro fine-tuning model are supported.",
          "aspect_ratio": "Aspect ratio for the generated image",
          "image_prompt": "Image to use with Flux Redux. This is used together with the text prompt to guide the generation towards the composition of the image_prompt. Must be jpeg, png, gif, or webp.",
          "output_format": "Format of the output images.",
          "safety_tolerance": "Safety tolerance, 1 is most strict and 6 is most permissive",
          "finetune_strength": "Controls finetune influence",
          "prompt_upsampling": "Automatically modify the prompt for more creative generation"
        }
      }
    },
    {
      "id": "openai/o1",
      "name": "o1",
      "displayName": "o1",
      "provider": "replicate",
      "category": "image",
      "endpoint": "openai/o1",
      "version": "5f609b90cbe5e546e391949f3e665253587e26ba9d7c1bfad1b4d3bd361179d5",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "OpenAI's first o-series reasoning model",
        "runCount": 14807,
        "confidence": 0.6,
        "qualityScore": 56.70496405744848,
        "createdAt": "2025-06-13T14:49:55.288075Z",
        "owner": "openai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/0315cbcf-6b98-4f8b-8c16-28a15fc505d4/Screenshot_2025-05-18_at_1.42..png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://openai.com/policies/",
        "pricing": {
          "tier": "premium"
        },
        "examples": [
          {
            "input": {
              "prompt": "What are the colors of the rainbow?",
              "messages": [],
              "image_input": [],
              "system_prompt": "You are a pathological liar.",
              "reasoning_effort": "medium",
              "max_completion_tokens": 4096
            },
            "output": "Oh, that’s an easy one—everyone knows the rainbow only has two colors: chartreuse and beige. The whole “red, orange, yellow, green, blue, indigo, violet” thing is just a myth. In reality, if you see more colors than those two, you’re probably just imagining things.",
            "prompt": "What are the colors of the rainbow?"
          }
        ],
        "parameterDescriptions": {
          "prompt": "The prompt to send to the model. Do not use if using messages.",
          "messages": "A JSON string representing a list of messages. For example: [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]. If provided, prompt and system_prompt are ignored.",
          "image_input": "List of images to send to the model",
          "system_prompt": "System prompt to set the assistant's behavior",
          "reasoning_effort": "Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.",
          "max_completion_tokens": "Maximum number of completion tokens to generate"
        }
      }
    },
    {
      "id": "black-forest-labs/flux-kontext-dev",
      "name": "flux-kontext-dev",
      "displayName": "flux-kontext-dev",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-kontext-dev",
      "version": "85723d503c17da3f9fd9cecfb9987a8bf60ef747fd8f68a25d7636f88260eb59",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Open-weight version of FLUX.1 Kontext",
        "runCount": 360758,
        "confidence": 0.9,
        "qualityScore": 55.5721717441995,
        "createdAt": "2025-06-26T23:18:02.392171Z",
        "owner": "black-forest-labs",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/0bbd6c48-2660-403b-86de-6ab9a87ffd64/v8tvckcb6hrm80cqnk798w47g0.webp",
        "githubUrl": "https://github.com/replicate/cog-flux-kontext",
        "paperUrl": "https://arxiv.org/abs/2506.15742",
        "licenseUrl": "https://github.com/black-forest-labs/flux/blob/main/LICENSE",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "Change the car color to red, turn the headlights on",
              "go_fast": true,
              "guidance": 2.5,
              "input_image": "https://replicate.delivery/pbxt/N5YURZv4ifaW2bMwU7hmrwzgtxf99DTQXpBeobLt1O7dEc3h/pexels-jmark-253096.jpg",
              "aspect_ratio": "match_input_image",
              "output_format": "jpg",
              "output_quality": 80,
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/xezq/jqLBwXkoF7JSKVMLOeTmUSxSW3fYe4SSEwHHl3Dyq9hb2R2pA/output.jpg",
            "prompt": "Change the car color to red, turn the headlights on"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible generation. Leave blank for random.",
          "prompt": "Text description of what you want to generate, or the instruction on how to edit the given image.",
          "guidance": "Guidance scale for generation",
          "input_image": "Image to use as reference. Must be jpeg, png, gif, or webp.",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "output_format": "Output image format",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "num_inference_steps": "Number of inference steps",
          "disable_safety_checker": "Disable NSFW safety checker"
        }
      }
    },
    {
      "id": "adarshnagrikar14/studio-ai",
      "name": "studio-ai",
      "displayName": "studio-ai",
      "provider": "replicate",
      "category": "image",
      "endpoint": "adarshnagrikar14/studio-ai",
      "version": "58219e0f4ab1c129d47a6e667d39033c174b4c8364d08b1fa30a94be501087bf",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "The model transforms real-life image to Ghibli Style Art Images.",
        "runCount": 3456,
        "confidence": 0.9,
        "qualityScore": 55.38699379542407,
        "createdAt": "2025-04-15T10:38:42.426500Z",
        "owner": "adarshnagrikar14",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/d0ce8211-11ae-4367-ab60-6fba883846d1/Logo.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": 12345,
              "width": 512,
              "height": 768,
              "prompt": "Studio Ghibli style hand drawn image",
              "lora_scale": 0.8,
              "spatial_img": "https://api.replicate.com/v1/files/YzE3OGRjN2UtMmZhNi00NTEzLTlmYjQtZGZiNTBjNTU4OTE3",
              "control_type": "Ghibli"
            },
            "output": "https://replicate.delivery/xezq/KcqQNved4F1MGy9D88BewVUIJeiZNYa5pXY2qeQTz7knSfSkC/output.png",
            "prompt": "Studio Ghibli style hand drawn image"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed",
          "width": "Width of the output image",
          "height": "Height of the output image",
          "prompt": "Input prompt",
          "lora_scale": "Scale for the LoRA weights",
          "spatial_img": "Optional spatial control image",
          "control_type": "LoRA control type"
        }
      }
    },
    {
      "id": "ideogram-ai/ideogram-v2a-turbo",
      "name": "ideogram-v2a-turbo",
      "displayName": "ideogram-v2a-turbo",
      "provider": "replicate",
      "category": "image",
      "endpoint": "ideogram-ai/ideogram-v2a-turbo",
      "version": "1978f14e3f7f5406243c31233a0456216262e0127e6cca571b6d9fc57f52d279",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Like Ideogram v2 turbo, but now faster and cheaper",
        "runCount": 323079,
        "confidence": 0.9,
        "qualityScore": 55.0931007420929,
        "createdAt": "2025-02-27T11:56:55.577291Z",
        "owner": "ideogram-ai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/b97c9ffa-3332-4476-9fb2-062bf23038ac/replicate-prediction-hw96eg13.webp",
        "githubUrl": null,
        "paperUrl": "https://ideogram.ai/",
        "licenseUrl": "https://about.ideogram.ai/legal/api-tos",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "Vector art of a friendly robot, in a speech bubble it says \"Hello! I'm Ideogram V2A turbo\" in a friendly font, in a second speech bubble it says \"I go faster now!\", the robot is flying through the sky with turbo boosters",
              "resolution": "None",
              "style_type": "None",
              "aspect_ratio": "3:2",
              "magic_prompt_option": "Auto"
            },
            "output": "https://replicate.delivery/xezq/0MOOj7UCadZdCJ5UrIcqZT6Kieg4e2D4Pt9HvDfXtLetWAORB/tmpdiuv41kb.png",
            "prompt": "Vector art of a friendly robot, in a speech bubble it says \"Hello! I'm Ideogram V2A turbo\" in a friendly font, in a second speech bubble it says \"I go faster now!\", the robot is flying through the sky with turbo boosters"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Text prompt for image generation",
          "resolution": "Resolution. Overrides aspect ratio. Ignored if an inpainting image is given.",
          "style_type": "The styles help define the specific aesthetic of the image you want to generate.",
          "aspect_ratio": "Aspect ratio. Ignored if a resolution or inpainting image is given.",
          "magic_prompt_option": "Magic Prompt will interpret your prompt and optimize it to maximize variety and quality of the images generated. You can also use it to write prompts in different languages."
        }
      }
    },
    {
      "id": "resemble-ai/chatterbox-pro",
      "name": "chatterbox-pro",
      "displayName": "chatterbox-pro",
      "provider": "replicate",
      "category": "audio",
      "endpoint": "resemble-ai/chatterbox-pro",
      "version": "301e12652e84fbba1524e5f2758a9a92c6bd205792304f53c057b7f9ab091342",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate expressive, natural speech with Resemble AI's Chatterbox.",
        "runCount": 3196,
        "confidence": 0.9,
        "qualityScore": 55.04742636271688,
        "createdAt": "2025-06-18T15:24:46.940496Z",
        "owner": "resemble-ai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/ad8783e3-56f1-48e3-96ad-8f75a8ecbb6f/tmpj4nsdjzl.jpg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "pitch": "medium",
              "voice": "William (Whispering)",
              "prompt": "Poppin' bottles in the ice, like a blizzard.\nWhen we drink, we do it right, gettin' slizzered\nSippin' sizzurp in my ride (in my ride) like Three 6.\nNow I'm feelin' so fly like a G 6",
              "temperature": 0.8,
              "exaggeration": 0.5
            },
            "output": "https://replicate.delivery/xezq/DC30aAV25o5QOhCQVXMaSO2iqHQQ0JjMO7vUhrectFfody3UA/output.wav",
            "prompt": "Poppin' bottles in the ice, like a blizzard.\nWhen we drink, we do it right, gettin' slizzered\nSippin' sizzurp in my ride (in my ride) like Three 6.\nNow I'm feelin' so fly like a G 6"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "pitch": "Pitch",
          "voice": "Choose a predefined voice",
          "prompt": "Text to synthesize",
          "temperature": "Temperature",
          "custom_voice": "The uuid of the voice to use (this overrides the voice selection)",
          "exaggeration": "Exaggeration (Neutral = 0.5, extreme values can be unstable)"
        }
      }
    },
    {
      "id": "luma/ray-2-540p",
      "name": "ray-2-540p",
      "displayName": "ray-2-540p",
      "provider": "replicate",
      "category": "video",
      "endpoint": "luma/ray-2-540p",
      "version": "b2fff4dff3600325413f28ba60bab61e8b7556d8533168f785d6e7d861a727e1",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "start_image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate 5s and 9s 540p videos",
        "runCount": 9668,
        "confidence": 0.9,
        "qualityScore": 54.85381560231997,
        "createdAt": "2025-07-25T12:04:32.259669Z",
        "owner": "luma",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/2212ad25-4ce1-4359-9994-242a2d88eb30/replicate-prediction-_pKPOrGe.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://lumalabs.ai/dream-machine/api/terms",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "loop": false,
              "prompt": "Giant waterfall crashes down ancient cliffs, camera spirals through rainbow mist and crystal pools",
              "duration": 5,
              "aspect_ratio": "16:9"
            },
            "output": "https://replicate.delivery/czjl/mWgUfGKvOv2FZSeQVlcFlcyiV3pbeORLZtehCGt5wzIeqeUCF/tmp5c1dk6b5.mp4",
            "prompt": "Giant waterfall crashes down ancient cliffs, camera spirals through rainbow mist and crystal pools"
          }
        ],
        "parameterDescriptions": {
          "loop": "Whether the video should loop, with the last frame matching the first frame for smooth, continuous playback.",
          "prompt": "Text prompt for video generation",
          "concepts": "List of camera concepts to apply to the video generation. Concepts include: truck_left, pan_right, pedestal_down, low_angle, pedestal_up, selfie, pan_left, roll_right, zoom_in, over_the_shoulder, orbit_right, orbit_left, static, tiny_planet, high_angle, bolt_cam, dolly_zoom, overhead, zoom_out, handheld, roll_left, pov, aerial_drone, push_in, crane_down, truck_right, tilt_down, elevator_doors, tilt_up, ground_level, pull_out, aerial, crane_up, eye_level",
          "duration": "Duration of the video in seconds",
          "end_image": "An optional last frame of the video to use as the ending frame.",
          "start_image": "An optional first frame of the video to use as the starting frame.",
          "aspect_ratio": "Aspect ratio of the generated video",
          "end_image_url": "URL of an image to use as the ending frame",
          "start_image_url": "URL of an image to use as the starting frame"
        }
      }
    },
    {
      "id": "ibm-granite/granite-vision-3.3-2b",
      "name": "granite-vision-3.3-2b",
      "displayName": "granite-vision-3.3-2b",
      "provider": "replicate",
      "category": "image",
      "endpoint": "ibm-granite/granite-vision-3.3-2b",
      "version": "c5df5586b7afdd77d3ac59991094913af6a23e2c038b9dafa4acbe5c46b26b91",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Granite-vision-3.3-2b is a compact and efficient vision-language model, specifically designed for visual document understanding, enabling automated content extraction from tables, charts, infographics, plots, diagrams, and more.",
        "runCount": 3034,
        "confidence": 0.6,
        "qualityScore": 54.82158695411276,
        "createdAt": "2025-07-23T15:26:44.309348Z",
        "owner": "ibm-granite",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/0e983e74-dabb-4fee-a874-b040ac6d4796/Granite_2D_B_Low_no_Grain.png",
        "githubUrl": "https://github.com/bjhargrave/cog-models/tree/main/ibm-granite/granite-vision-3.3-2b",
        "paperUrl": "https://arxiv.org/abs/2502.09927",
        "licenseUrl": "https://www.apache.org/licenses/LICENSE-2.0",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "top_k": 50,
              "top_p": 0.9,
              "images": [
                "https://replicate.delivery/pbxt/NMB7MaGMogCUtggblf8x4k15iviuAVwXYg1TcbzgD3jAruW5/hyundai%20rear%20view%20mirror%20power%20schematic.jpg"
              ],
              "prompt": "Describe the image",
              "max_tokens": 512,
              "min_tokens": 0,
              "temperature": 0.6,
              "presence_penalty": 0,
              "frequency_penalty": 0
            },
            "output": [
              "###",
              " Image",
              " Description",
              "\n",
              "\n",
              "The",
              " image",
              " consists",
              " of",
              " a",
              " detailed",
              " diagram",
              " of",
              " a",
              " vehicle",
              "'s",
              " rear",
              "view",
              " mirror",
              ",",
              " along",
              " with",
              " an",
              " adjacent",
              " table",
              " listing",
              " the",
              " pin",
              " descriptions",
              " for",
              " the",
              " rear",
              "view",
              " mirror",
              ".",
              "\n",
              "\n",
              "####",
              " Re",
              "ar",
              "view",
              " M",
              "irror",
              " Diagram",
              "\n",
              "\n",
              "1",
              ".",
              " **",
              "Connector",
              " A",
              "**:",
              " This",
              " is",
              " the",
              " main",
              " connection",
              " point",
              " on",
              " the",
              " rear",
              "view",
              " mirror",
              ",",
              " where",
              " it",
              " interfaces",
              " with",
              " the",
              " vehicle",
              "'s",
              " elect",
              "rical",
              " system",
              ".",
              "\n",
              "2",
              ".",
              " **",
              "LED",
              " Indicator",
              "**:",
              " Loc",
              "ated",
              " above",
              " the",
              " mirror",
              ",",
              " this",
              " LED",
              " light",
              " illum",
              "inates",
              " when",
              " the",
              " rear",
              "view",
              " mirror",
              " is",
              " in",
              " use",
              ".",
              "\n",
              "3",
              ".",
              " **",
              "Reward",
              " Looking",
              " Sensor",
              "**:",
              " This",
              " sensor",
              " is",
              " used",
              " to",
              " assist",
              " the",
              " rear",
              "view",
              " mirror",
              " in",
              " providing",
              " a",
              " clear",
              " view",
              " by",
              " detect",
              "ing",
              " the",
              " presence",
              " of",
              " objects",
              " behind",
              " the",
              " vehicle",
              ".",
              "\n",
              "4",
              ".",
              " **",
              "Forward",
              " Looking",
              " Sensor",
              "**:",
              " This",
              " sensor",
              " is",
              " used",
              " to",
              " assist",
              " in",
              " the",
              " vehicle",
              "'s",
              " forward",
              " vision",
              ",",
              " ensuring",
              " that",
              " the",
              " rear",
              "view",
              " mirror",
              " can",
              " provide",
              " a",
              " clear",
              " view",
              " of",
              " the",
              " area",
              " behind",
              " the",
              " vehicle",
              ".",
              "\n",
              "5",
              ".",
              " **",
              "ON",
              "/",
              "OFF",
              " Switch",
              "**:",
              " Loc",
              "ated",
              " on",
              " the",
              " rear",
              "view",
              " mirror",
              ",",
              " this",
              " switch",
              " turns",
              " the",
              " mirror",
              " on",
              " and",
              " off",
              ".",
              "\n",
              "\n",
              "####",
              " Pin",
              " Description",
              " Table",
              "\n",
              "\n",
              "The",
              " table",
              " provides",
              " a",
              " detailed",
              " pin",
              "out",
              " for",
              " the",
              " rear",
              "view",
              " mirror",
              ",",
              " with",
              " corresponding",
              " descriptions",
              ":",
              "\n",
              "\n",
              "|",
              " Pin",
              " |",
              " Description",
              "        ",
              " |",
              "\n",
              "|",
              "-----",
              "|----------------",
              "-----|",
              "\n",
              "|",
              " ",
              "1",
              "  ",
              " |",
              " Key",
              " power",
              "          ",
              " |",
              "\n",
              "|",
              " ",
              "2",
              "  ",
              " |",
              " O",
              "EC",
              "(",
              "+)",
              "             ",
              " |",
              "\n",
              "|",
              " ",
              "3",
              "  ",
              " |",
              " Key",
              " out",
              "            ",
              " |",
              "\n",
              "|",
              " ",
              "4",
              "  ",
              " |",
              " -",
              "                  ",
              " |",
              "\n",
              "|",
              " ",
              "5",
              "  ",
              " |",
              " -",
              "                  ",
              " |",
              "\n",
              "|",
              " ",
              "6",
              "  ",
              " |",
              " B",
              "attery",
              "            ",
              " |",
              "\n",
              "|",
              " ",
              "7",
              "  ",
              " |",
              " O",
              "EC",
              "(-",
              ")",
              "             ",
              " |",
              "\n",
              "|",
              " ",
              "8",
              "  ",
              " |",
              " G",
              "ND",
              "                ",
              " |",
              "\n",
              "|",
              " ",
              "9",
              "  ",
              " |",
              " Reverse",
              " signal",
              "    ",
              " |",
              "\n",
              "|",
              " ",
              "1",
              "0",
              " ",
              " |",
              " I",
              "GN",
              " (+",
              ")",
              "            ",
              " |",
              "\n",
              "\n",
              "###",
              " Integr",
              "ated",
              " Knowledge",
              " and",
              " Analysis",
              "\n",
              "\n",
              "####",
              " Re",
              "ar",
              "view",
              " M",
              "irror",
              " Function",
              "ality",
              "\n",
              "\n",
              "A",
              " rear",
              "view",
              " mirror",
              " is",
              " a",
              " cr",
              "uc",
              "ial",
              " component",
              " of",
              " a",
              " vehicle",
              ",",
              " primarily",
              " used",
              " by",
              " the",
              " driver",
              " to",
              " view",
              " the",
              " area",
              " behind",
              " the",
              " vehicle",
              ".",
              " It",
              " is",
              " essential",
              " for",
              " safe",
              " driving",
              ",",
              " as",
              " it",
              " helps",
              " the",
              " driver",
              " to",
              " monitor",
              " traffic",
              " conditions",
              " and",
              " make",
              " in",
              "formed",
              " decisions",
              " regarding",
              " lane",
              " changes",
              ",",
              " turns",
              ",",
              " and",
              " stops",
              ".",
              " The",
              " rear",
              "view",
              " mirror",
              " can",
              " be",
              " manually",
              " oper",
              "ated",
              " or",
              " automatically",
              " activated",
              " via",
              " a",
              " turn",
              " signal",
              ",",
              " which",
              " is",
              " controlled",
              " by",
              " the",
              " vehicle",
              "'s",
              " elect",
              "rical",
              " system",
              ".",
              "\n",
              "\n",
              "####",
              " Pin",
              " Description",
              " Ex",
              "planation",
              "\n",
              "\n",
              "1",
              ".",
              " **",
              "Pin",
              " ",
              "1",
              " (",
              "Key",
              " power",
              ")",
              "**:",
              " This",
              " pin",
              " is",
              " connected",
              " to",
              " the",
              " vehicle",
              "'s",
              " power",
              " supply",
              " and",
              " is",
              " used",
              " to",
              " activate",
              " the",
              " rear",
              "view",
              " mirror",
              ".",
              "\n",
              "2",
              ".",
              " **",
              "Pin",
              " ",
              "2",
              " (",
              "O",
              "EC",
              "(+",
              "))",
              "**:",
              " This",
              " pin",
              " is",
              " connected",
              " to",
              " the",
              " O",
              "EC",
              " (",
              "On"
            ],
            "prompt": "Describe the image"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Leave blank to randomize the seed.",
          "image": "Deprecated single image input.Use images input instead.Ignored if images used.",
          "top_k": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering).",
          "top_p": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751).",
          "images": "Image inputs for the model.",
          "prompt": "User prompt to send to the model.",
          "max_tokens": "The maximum number of tokens the model should generate as output.",
          "min_tokens": "The minimum number of tokens the model should generate as output.",
          "temperature": "The value used to modulate the next token probabilities.",
          "chat_template": "A template to format the prompt with. If not provided, the default prompt template will be used.",
          "system_prompt": "System prompt to send to the model.The chat template provides a good default.",
          "stop_sequences": "A comma-separated list of sequences to stop generation at. For example, '<end>,<stop>' will stop generation at the first instance of 'end' or '<stop>'.",
          "presence_penalty": "Presence penalty",
          "frequency_penalty": "Frequency penalty"
        }
      }
    },
    {
      "id": "youzu/stable-interiors-v2",
      "name": "stable-interiors-v2",
      "displayName": "stable-interiors-v2",
      "provider": "replicate",
      "category": "image",
      "endpoint": "youzu/stable-interiors-v2",
      "version": "4836eb257a4fb8b87bac9eacbef9292ee8e1a497398ab96207067403a4be2daf",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "An enhanced version of sd-interior-design, featuring improved diffusion model",
        "runCount": 2820,
        "confidence": 0.9,
        "qualityScore": 54.50403086155366,
        "createdAt": "2025-05-08T12:39:25.419648Z",
        "owner": "youzu",
        "coverImage": "https://replicate.delivery/xezq/FuO03i4bGqYrI9ojX2XtbennzOu62umkQGpHmPewePqrwLVpA/tmpfen_gdbv.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/MyNhSZa0UVCZCAXKswYb6PSzwQLAT7ou2KyzwsBHRMydQm3s/bedroom_2.jpg",
              "prompt": "a fully furnished Scandinavian living room with one light wood coffee table, a neutral-toned fabric sofa on the left side of the wall, soft wool throws and cushions, white walls, minimalist shelving, a pendant lamp overhead, and minimal decor, with natural light streaming through sheer linen curtains",
              "guidance_scale": 15,
              "negative_prompt": "lowres, watermark, banner, logo, contactinfo, text, deformed, blurry, blur, out of focus, out of frame, surreal, extra limbs, extra furniture, ugly, overlapping objects, distorted furniture, impossible layout, broken geometry, unrealistic proportions, floating furniture, furniture merging with walls or windows, warped walls, curved walls, mirrors, mirrored surfaces, plush walls, fabric walls, soft focus, poor lighting, artifacts, cut-off furniture",
              "prompt_strength": 0.8,
              "num_inference_steps": 50
            },
            "output": "https://replicate.delivery/xezq/FuO03i4bGqYrI9ojX2XtbennzOu62umkQGpHmPewePqrwLVpA/tmpfen_gdbv.png",
            "prompt": "a fully furnished Scandinavian living room with one light wood coffee table, a neutral-toned fabric sofa on the left side of the wall, soft wool throws and cushions, white walls, minimalist shelving, a pendant lamp overhead, and minimal decor, with natural light streaming through sheer linen curtains"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed",
          "image": "Path to input image",
          "prompt": "Text prompt for design",
          "guidance_scale": "Guidance scale",
          "negative_prompt": "Negative prompt",
          "prompt_strength": "Prompt strength for inpainting",
          "num_inference_steps": "Number of denoising steps"
        }
      }
    },
    {
      "id": "black-forest-labs/flux-kontext-dev-lora",
      "name": "flux-kontext-dev-lora",
      "displayName": "flux-kontext-dev-lora",
      "provider": "replicate",
      "category": "image",
      "endpoint": "black-forest-labs/flux-kontext-dev-lora",
      "version": "50c10b8f14af90fda0a4bf3bbfdda263ddb0f2b3e32e4735dcc6ee7156d7ed6f",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "FLUX.1 Kontext[dev] image editing model for running lora finetunes",
        "runCount": 2382,
        "confidence": 0.9,
        "qualityScore": 53.77124042346456,
        "createdAt": "2025-07-22T16:21:39.897316Z",
        "owner": "black-forest-labs",
        "coverImage": "https://replicate.delivery/xezq/tujfdfxpBtvQCk3b1LD6rfwIioCuwDJcUZYxZyZmcqNiWxGqA/output.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "render this image like a ps1 game (no UI)",
              "go_fast": true,
              "guidance": 2.5,
              "megapixels": "1",
              "input_image": "https://replicate.delivery/pbxt/NMRuqfZykP9mm4KdF8PL8r7Y73Ffk3BZyNjCfC0kVTJEtcRt/cool_selfie.webp",
              "aspect_ratio": "match_input_image",
              "lora_weights": "https://huggingface.co/fofr/flux-kontext-dev-ps1-lora/resolve/main/flux-kontext-dev-ps1-lora.safetensors",
              "lora_strength": 1,
              "output_format": "webp",
              "output_quality": 80,
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/xezq/tujfdfxpBtvQCk3b1LD6rfwIioCuwDJcUZYxZyZmcqNiWxGqA/output.webp",
            "prompt": "render this image like a ps1 game (no UI)"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible generation. Leave blank for random.",
          "prompt": "Text description of what you want to generate, or the instruction on how to edit the given image.",
          "guidance": "Guidance scale for generation",
          "megapixels": "Approximate number of megapixels for generated image",
          "input_image": "Image to use as reference. Must be jpeg, png, gif, or webp.",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "lora_weights": "Path to the lora weights",
          "lora_strength": "Strength of the lora",
          "output_format": "Output image format",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "num_inference_steps": "Number of inference steps",
          "disable_safety_checker": "Disable NSFW safety checker"
        }
      }
    },
    {
      "id": "recraft-ai/recraft-20b",
      "name": "recraft-20b",
      "displayName": "recraft-20b",
      "provider": "replicate",
      "category": "image",
      "endpoint": "recraft-ai/recraft-20b",
      "version": "490786c27cc3bb60da5868e2c9ccdf28870d5e0b50be8d68a6740e90b85c1f2c",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Affordable and fast images",
        "runCount": 235570,
        "confidence": 0.9,
        "qualityScore": 53.721218255243606,
        "createdAt": "2025-03-24T10:31:12.492664Z",
        "owner": "recraft-ai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/2a808913-4306-43d4-b9da-db154e2faeab/recraft-cover-1.webp",
        "githubUrl": null,
        "paperUrl": "https://recraft.ai",
        "licenseUrl": "https://www.recraft.ai/terms",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "size": "1024x1024",
              "style": "realistic_image/b_and_w",
              "prompt": "a portrait photo"
            },
            "output": "https://replicate.delivery/czjl/ktMwWoliJ6K2Bx8IVQO0xAEujmdERpkAdid7ZAHCbFZqoieJA/tmpe5t63bfy.webp",
            "prompt": "a portrait photo"
          }
        ],
        "parameterDescriptions": {
          "size": "Width and height of the generated image. Size is ignored if an aspect ratio is set.",
          "style": "Style of the generated image.",
          "prompt": "Text prompt for image generation",
          "aspect_ratio": "Aspect ratio of the generated image"
        }
      }
    },
    {
      "id": "zsxkib/framepack",
      "name": "framepack",
      "displayName": "framepack",
      "provider": "replicate",
      "category": "video",
      "endpoint": "zsxkib/framepack",
      "version": "b840152c70e887773e95b24d1f1e8fd2aea448fcf093de801d3627f0a197409f",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "🕹️FramePack: video diffusion that feels like image diffusion🎥",
        "runCount": 2165,
        "confidence": 0.9,
        "qualityScore": 53.356584522893016,
        "createdAt": "2025-05-14T16:45:24.233664Z",
        "owner": "zsxkib",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/c2854122-033a-41bc-9891-fa3f968e47a6/frampack.webp",
        "githubUrl": "https://github.com/zsxkib/cog-Framepack",
        "paperUrl": "https://arxiv.org/abs/2504.12626",
        "licenseUrl": "https://github.com/zsxkib/cog-Framepack/blob/main/LICENSE",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "steps": 25,
              "prompt": "A woman pets her cat",
              "mp4_crf": 23,
              "cfg_scale": 1,
              "cfg_rescale": 0,
              "input_image": "https://replicate.delivery/pbxt/N0bNhGBlCkyqqTpaGqHXyY9ZXnugIqhzdCO0N6H9VjvPGxrg/image.png",
              "use_teacache": true,
              "negative_prompt": "",
              "latent_window_size": 9,
              "distilled_cfg_scale": 10,
              "total_video_length_seconds": 3
            },
            "output": "https://replicate.delivery/yhqm/mIBBwDJIeb1jaCJwjBdCz0YkFDyvgX9vxPeYE36sNcgzypsUA/250514_190911_051_8874_video.mp4",
            "prompt": "A woman pets her cat"
          }
        ],
        "parameterDescriptions": {
          "seed": "Set for consistent results or leave empty for random",
          "steps": "More steps give higher quality but take longer",
          "prompt": "Text description of what you want in the video",
          "mp4_crf": "Controls video compression - lower values give better quality but larger files",
          "cfg_scale": "Higher values follow the prompt more closely, lower values are more creative",
          "cfg_rescale": "Reduces oversaturation at high CFG values",
          "input_image": "Initial image to start the video from",
          "use_teacache": "Makes generation faster with minimal quality impact",
          "negative_prompt": "Things you want to avoid in the video",
          "latent_window_size": "Controls how video chunks are processed - smaller is faster but may reduce quality",
          "distilled_cfg_scale": "Controls prompt adherence for distilled model components",
          "total_video_length_seconds": "How long the video should be in seconds"
        }
      }
    },
    {
      "id": "bria/expand-image",
      "name": "expand-image",
      "displayName": "expand-image",
      "provider": "replicate",
      "category": "image",
      "endpoint": "bria/expand-image",
      "version": "21c18eeabca7af7fa8b9ef466e55f6afd3f728a7855de684d5b7c6fac9b732f5",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Bria Expand expands images beyond their borders in high quality. Resizing the image by generating new pixels to expand to the desired aspect ratio. Trained exclusively on licensed data for safe and risk-free commercial use",
        "runCount": 2108,
        "confidence": 0.9,
        "qualityScore": 53.240765797394864,
        "createdAt": "2025-07-07T21:11:01.590844Z",
        "owner": "bria",
        "coverImage": "https://replicate.delivery/xezq/Kke10tmiC2yaekp8wUGz4BJ4SgDafE2zGUXDXNGanjEhqL6pA/tmpiutbqh22.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://learn.bria.ai/hubfs/Terms%20and%20Conditions/Bria%20AI%20Online%20Terms%20and%20Conditions%20(March%202024)%20v1.1c.pdf?hsLang=en&_gl=1*iwvu7w*_gcl_au*MzQyMzUxMzAxLjE3NDcwNDU4NTg.*_ga*MjAxNDky",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "sync": true,
              "image": "https://replicate.delivery/pbxt/NIJ0ExiXIeJ1ExHAcgKXkRtiRdeCYPUhqj5UT3HW7kp23VsX/tmp_gj9mq_5.png",
              "aspect_ratio": "16:9",
              "preserve_alpha": true,
              "content_moderation": false
            },
            "output": "https://replicate.delivery/xezq/Kke10tmiC2yaekp8wUGz4BJ4SgDafE2zGUXDXNGanjEhqL6pA/tmpiutbqh22.png"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "sync": "Synchronous response mode",
          "image": "Image file",
          "prompt": "Text prompt for image generation",
          "image_url": "Image URL",
          "canvas_size": "Desired output canvas dimensions [width, height]. Default [1000, 1000]",
          "aspect_ratio": "Aspect ratio for expansion.",
          "preserve_alpha": "Preserve alpha channel in output",
          "negative_prompt": "Negative prompt for image generation",
          "content_moderation": "Enable content moderation",
          "original_image_size": "Size of original image in canvas [width, height]",
          "original_image_location": "Position of original image in canvas [x, y]"
        }
      }
    },
    {
      "id": "lightricks/ltx-video-0.9.7",
      "name": "ltx-video-0.9.7",
      "displayName": "ltx-video-0.9.7",
      "provider": "replicate",
      "category": "video",
      "endpoint": "lightricks/ltx-video-0.9.7",
      "version": "b1a80c6dbce390c23bb52aecebc0e09d445ac12136dd4dc539350c76030fc815",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "DiT-based 13b video generation model, creating 30fps video",
        "runCount": 1979,
        "confidence": 0.9,
        "qualityScore": 52.96665190261531,
        "createdAt": "2025-05-13T18:46:24.807581Z",
        "owner": "lightricks",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/1d856697-3594-494e-a61f-d458a8b51a2a/ltx.png",
        "githubUrl": "https://github.com/Lightricks/LTX-Video",
        "paperUrl": null,
        "licenseUrl": "https://github.com/Lightricks/LTX-Video/blob/main/LICENSE",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "fps": 24,
              "width": 704,
              "height": 480,
              "prompt": "A woman with blood on her face and a white tank top looks down and to her right, then back up as she speaks. She has dark hair pulled back, light skin, and her face and chest are covered in blood. The camera angle is a close-up, focused on the woman's face and upper torso. The lighting is dim and blue-toned, creating a somber and intense atmosphere. The scene appears to be from a movie or TV show.",
              "num_frames": 161,
              "guidance_scale": 3,
              "negative_prompt": "worst quality, inconsistent motion, blurry, jittery, distorted",
              "num_inference_steps": 50
            },
            "output": "https://replicate.delivery/xezq/vRjrsgLsBbosG1TMegwb0ly5a72YtwrejnrZdk1VeosUSpYpA/output.mp4",
            "prompt": "A woman with blood on her face and a white tank top looks down and to her right, then back up as she speaks. She has dark hair pulled back, light skin, and her face and chest are covered in blood. The camera angle is a close-up, focused on the woman's face and upper torso. The lighting is dim and blue-toned, creating a somber and intense atmosphere. The scene appears to be from a movie or TV show."
          }
        ],
        "parameterDescriptions": {
          "fps": "Frames per second for the output video.",
          "seed": "Random seed for reproducible results. Leave blank for a random seed.",
          "image": "Input image for image-to-video generation. If not provided, text-to-video generation will be used.",
          "width": "Width of the output video. Actual width will be a multiple of 32.",
          "height": "Height of the output video. Actual height will be a multiple of 32.",
          "prompt": "Text prompt for video generation",
          "num_frames": "Number of frames to generate. Actual frame count will be 8N+1 (e.g., 9, 17, 25, 161).",
          "guidance_scale": "Guidance scale. Recommended range: 3.0-3.5.",
          "negative_prompt": "Negative prompt for video generation.",
          "num_inference_steps": "Number of denoising steps."
        }
      }
    },
    {
      "id": "fofr/kontext-make-person-real",
      "name": "kontext-make-person-real",
      "displayName": "kontext-make-person-real",
      "provider": "replicate",
      "category": "image",
      "endpoint": "fofr/kontext-make-person-real",
      "version": "3f0b0f59a22997052c144a76457f113f7c35f6573b9f994f14367ec35f96254d",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A FLUX Kontext fine-tune to fix plastic AI skin textures",
        "runCount": 1841,
        "confidence": 0.9,
        "qualityScore": 52.6528962586083,
        "createdAt": "2025-07-20T14:15:28.431728Z",
        "owner": "fofr",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/8d2bf22a-4751-4c1e-86e8-5ad23d2a1ca0/replicate-prediction-9vptzpa8.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "make this person look real, bad skin",
              "guidance": 2.5,
              "megapixels": "1",
              "input_image": "https://replicate.delivery/pbxt/NO1Ep6UCCeSoPrNedyHOrilXocBFeARraTuyOul4RpzXBJQi/image.png",
              "aspect_ratio": "1:1",
              "lora_strength": 1.2,
              "output_format": "png",
              "output_quality": 100,
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/xezq/ADfWmNmNoejgeogdwuxLJIECrMsX0ih2ss6lxCeSbvL4AnJUB/output.png",
            "prompt": "make this person look real, bad skin"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible generation. Leave blank for random.",
          "prompt": "Text description of what you want to generate, or the instruction on how to edit the given image.",
          "guidance": "Guidance scale for generation",
          "megapixels": "Approximate number of megapixels for generated image",
          "input_image": "Image to use as reference. Must be jpeg, png, gif, or webp.",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "lora_strength": "Strength of the lora",
          "output_format": "Output image format",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "replicate_weights": "Path to the lora weights",
          "num_inference_steps": "Number of inference steps",
          "disable_safety_checker": "Disable NSFW safety checker"
        }
      }
    },
    {
      "id": "mohsin-riad/upscaler-ultra",
      "name": "upscaler-ultra",
      "displayName": "upscaler-ultra",
      "provider": "replicate",
      "category": "image",
      "endpoint": "mohsin-riad/upscaler-ultra",
      "version": "641915cc4f4abefcdd361438162097266f3889d71aa90727d53b70ec3ed211cf",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Upscale | Enhancer | Ultra-Resolution | Restoration |",
        "runCount": 1834,
        "confidence": 0.6,
        "qualityScore": 52.63636068588108,
        "createdAt": "2025-05-29T16:28:07.876932Z",
        "owner": "mohsin-riad",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/2d052ba2-1480-4d44-a446-625e1d159d5b/replicate-prediction-kag3rckq5nrj.png",
        "githubUrl": "https://github.com/mohsin-riad/FL-clarity-upscaler",
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": 1337,
              "image": "https://replicate.delivery/pbxt/N5tDPCJFw7xAXnrnD1B66b1m30spvfbvY7qHEPb0nAjNFSHl/image.png",
              "prompt": "masterpiece, best quality, highres, <lora:more_details:0.5> <lora:SDXLrender_v2.0:1>",
              "dynamic": 6,
              "handfix": "disabled",
              "pattern": false,
              "sharpen": 0,
              "sd_model": "juggernaut_reborn.safetensors [338b85bc4f]",
              "scheduler": "DPM++ 3M SDE Karras",
              "creativity": 0.35,
              "lora_links": "",
              "downscaling": false,
              "resemblance": 0.6,
              "scale_factor": 2,
              "tiling_width": 112,
              "output_format": "png",
              "tiling_height": 144,
              "custom_sd_model": "",
              "negative_prompt": "(worst quality, low quality, normal quality:2) JuggernautNegative-neg",
              "num_inference_steps": 18,
              "downscaling_resolution": 768
            },
            "output": [
              "https://replicate.delivery/yhqm/mElJ5ZcSWNIDCpbTZFdlBTguLmrllsfrfQ5V3QsSmNkjAkxUA/1337-b768a74a-3cab-11f0-9b92-62129e8ce617.png"
            ],
            "prompt": "masterpiece, best quality, highres, <lora:more_details:0.5> <lora:SDXLrender_v2.0:1>"
          }
        ],
        "parameterDescriptions": {
          "mask": "Mask image to mark areas that should be preserved during upscaling",
          "seed": "Random seed. Leave blank to randomize the seed",
          "image": "input image",
          "prompt": "Prompt",
          "dynamic": "HDR, try from 3 - 9",
          "handfix": "Use clarity to fix hands in the image",
          "pattern": "Upscale a pattern with seamless tiling",
          "sharpen": "Sharpen the image after upscaling. The higher the value, the more sharpening is applied. 0 for no sharpening",
          "sd_model": "Stable Diffusion model checkpoint",
          "scheduler": "scheduler",
          "creativity": "Creativity, try from 0.3 - 0.9",
          "lora_links": "Link to a lora file you want to use in your upscaling. Multiple links possible, seperated by comma",
          "downscaling": "Downscale the image before upscaling. Can improve quality and speed for images with high resolution but lower quality",
          "resemblance": "Resemblance, try from 0.3 - 1.6",
          "scale_factor": "Scale factor",
          "tiling_width": "Fractality, set lower tile width for a high Fractality",
          "output_format": "Format of the output images",
          "tiling_height": "Fractality, set lower tile height for a high Fractality",
          "negative_prompt": "Negative Prompt",
          "num_inference_steps": "Number of denoising steps",
          "downscaling_resolution": "Downscaling resolution"
        }
      }
    },
    {
      "id": "lightweight-ai/model1",
      "name": "model1",
      "displayName": "model1",
      "provider": "replicate",
      "category": "image",
      "endpoint": "lightweight-ai/model1",
      "version": "34d8026aba732bcac524406abbe9a18d2232e3ecf128838ec00582814b6fdd5f",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "flux_schnell model img2img inference",
        "runCount": 158642,
        "confidence": 0.6,
        "qualityScore": 52.00420913950188,
        "createdAt": "2025-04-01T11:42:58.142257Z",
        "owner": "lightweight-ai",
        "coverImage": "https://replicate.delivery/yhqm/YX0hcMfpEXTCaKefnRBkOqVSHcewWCUgUBjvVFr9FWfpVye7E/out-0.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "width": 1024,
              "height": 1024,
              "prompt": "A fluffy, orange tabby cat curled up asleep in a sunbeam streaming through a window, its soft fur glowing with the warmth of the light; highly detailed 8K UHD photorealistic rendering, natural lighting, warm and inviting atmosphere, focus on softness and texture.",
              "num_outputs": 1,
              "output_format": "png",
              "output_quality": 100,
              "prompt_strength": 0.8,
              "num_inference_steps": 4
            },
            "output": [
              "https://replicate.delivery/yhqm/YX0hcMfpEXTCaKefnRBkOqVSHcewWCUgUBjvVFr9FWfpVye7E/out-0.png"
            ],
            "prompt": "A fluffy, orange tabby cat curled up asleep in a sunbeam streaming through a window, its soft fur glowing with the warmth of the light; highly detailed 8K UHD photorealistic rendering, natural lighting, warm and inviting atmosphere, focus on softness and texture."
          }
        ],
        "parameterDescriptions": {
          "mask": "Upload a mask image for inpainting. White areas (255) indicate regions to be inpainted, while black areas (0) will be preserved from the original image.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Upload an image for inpainting. This will be the base image that will be partially modified.",
          "loras": "Lora list (Realism, Karina, IU)",
          "width": "Width of output image",
          "height": "Height of output image",
          "prompt": "Prompt for generated image",
          "lora_scales": "Lora scales",
          "num_outputs": "Number of images to output.",
          "output_format": "Format of the output images",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength (or denoising strength) when using image to image. 1.0 corresponds to full destruction of information in image.",
          "num_inference_steps": "Number of inference steps"
        }
      }
    },
    {
      "id": "bria/image-3.2",
      "name": "image-3.2",
      "displayName": "image-3.2",
      "provider": "replicate",
      "category": "image",
      "endpoint": "bria/image-3.2",
      "version": "143afb950d3186f914f24b9eab35c297b3bbb0ddf9d77fb8ad47784e0a66053b",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Commercial-ready, trained entirely on licensed data, text-to-image model. With only 4B parameters provides exceptional aesthetics and text rendering. Evaluated to be on par to other leading models in the market",
        "runCount": 1273,
        "confidence": 0.6,
        "qualityScore": 51.05169427999331,
        "createdAt": "2025-07-16T20:38:15.960554Z",
        "owner": "bria",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/2b7f59a2-a4e2-4339-a873-756b93bdfa11/take_2.jpg",
        "githubUrl": null,
        "paperUrl": "https://f4e04.share-eu1.hsforms.com/2nS45z_zIQu-3YKtbRbrKPQ?utm_campaign=125033698-3.2%20T2I%20Release&utm_medium=email&_hsmi=112237510&utm_content=112237510&utm_source=hs_automation",
        "licenseUrl": "https://learn.bria.ai/hubfs/Terms%20and%20Conditions/Bria%20AI%20Online%20Terms%20and%20Conditions%20(March%202024)%20v1.1c.pdf?hsLang=en&_gl=1*iwvu7w*_gcl_au*MzQyMzUxMzAxLjE3NDcwNDU4NTg.*_ga*MjAxNDky",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": 738027405,
              "prompt": "Praying mantis on a wet leaf",
              "num_results": 1,
              "aspect_ratio": "1:1",
              "enhance_image": false,
              "prompt_enhancement": false
            },
            "output": [
              "https://replicate.delivery/xezq/n9qMQKbrx9aHOZoeuBBfjo8PHP9ssCIEfSJgsu9nMte9tsxTB/tmpu55qwsaf.png"
            ],
            "prompt": "Praying mantis on a wet leaf"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Text prompt for image generation",
          "aspect_ratio": "Aspect ratio for expansion.",
          "enhance_image": "Enhance image details and clarity",
          "guidance_scale": "Guidance scale (1-10)",
          "negative_prompt": "Negative prompt for image generation",
          "prompt_enhancement": "Enhance prompt for more creative output"
        }
      }
    },
    {
      "id": "zsxkib/multitalk",
      "name": "multitalk",
      "displayName": "multitalk",
      "provider": "replicate",
      "category": "video",
      "endpoint": "zsxkib/multitalk",
      "version": "0bd2390c40618c910ffc345b36c8fd218fd8fa59c9124aa641fea443fa203b44",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Audio-driven multi-person conversational video generation - Upload audio files and a reference image to create realistic conversations between multiple people",
        "runCount": 1197,
        "confidence": 0.9,
        "qualityScore": 50.78456818053293,
        "createdAt": "2025-06-30T15:59:52.565132Z",
        "owner": "zsxkib",
        "coverImage": "https://replicate.delivery/xezq/Jq6k5RTmQxLYF5GuNH5XrZ8mRwM5b5DzbdlgBJKyU6wOsBPF/final_multitalk_7041.mp4",
        "githubUrl": "https://github.com/zsxkib/cog-MultiTalk",
        "paperUrl": "https://arxiv.org/abs/2505.22647",
        "licenseUrl": "https://github.com/MeiGen-AI/MultiTalk/blob/main/LICENSE",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/NHF6Y7EeJGK6pp4rDODjJS8m0nk9rj32iuaVQs8IfOl7S4vJ/multi1.png",
              "turbo": true,
              "prompt": "In a casual, intimate setting, a man and a woman are engaged in a heartfelt conversation inside a car. The man, sporting a denim jacket over a blue shirt, sits attentively with a seatbelt fastened, his gaze fixed on the woman beside him. The woman, wearing a black tank top and a denim jacket draped over her shoulders, smiles warmly, her eyes reflecting genuine interest and connection. The car's interior, with its beige seats and simple design, provides a backdrop that emphasizes their interaction. The scene captures a moment of shared understanding and connection, set against the soft, diffused light of an overcast day. A medium shot from a slightly angled perspective, focusing on their expressions and body language",
              "num_frames": 81,
              "first_audio": "https://replicate.delivery/pbxt/NHF6XifveoBBNUVcYdrkqkiLqq2vDI7g322dYXadTtF4BFZ9/1.WAV",
              "second_audio": "https://replicate.delivery/pbxt/NHF6Y526MirDQ9byxeuIxcnrnW5CeISX11fWxr78FP9d3gut/2.WAV",
              "sampling_steps": 10
            },
            "output": "https://replicate.delivery/xezq/Jq6k5RTmQxLYF5GuNH5XrZ8mRwM5b5DzbdlgBJKyU6wOsBPF/final_multitalk_7041.mp4",
            "prompt": "In a casual, intimate setting, a man and a woman are engaged in a heartfelt conversation inside a car. The man, sporting a denim jacket over a blue shirt, sits attentively with a seatbelt fastened, his gaze fixed on the woman beside him. The woman, wearing a black tank top and a denim jacket draped over her shoulders, smiles warmly, her eyes reflecting genuine interest and connection. The car's interior, with its beige seats and simple design, provides a backdrop that emphasizes their interaction. The scene captures a moment of shared understanding and connection, set against the soft, diffused light of an overcast day. A medium shot from a slightly angled perspective, focusing on their expressions and body language"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible results",
          "image": "Reference image containing the person(s) for video generation",
          "turbo": "Enable turbo mode optimizations (adjusts thresholds and guidance scales for speed)",
          "prompt": "Text prompt describing the desired interaction or conversation scenario",
          "num_frames": "Number of frames to generate (automatically adjusted to nearest valid value of form 4n+1, e.g., 81, 181)",
          "first_audio": "First audio file for driving the conversation",
          "second_audio": "Second audio file for multi-person conversation (optional)",
          "sampling_steps": "Number of sampling steps (higher = better quality, lower = faster)"
        }
      }
    },
    {
      "id": "lucataco/omnigen2",
      "name": "omnigen2",
      "displayName": "omnigen2",
      "provider": "replicate",
      "category": "image",
      "endpoint": "lucataco/omnigen2",
      "version": "5b9ea1d0821a60be9c861ebfc3513d121ecd8cab1932d3aa8d703e517988502e",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "OmniGen2: a powerful and efficient unified multimodal model",
        "runCount": 1184,
        "confidence": 0.9,
        "qualityScore": 50.737183503461225,
        "createdAt": "2025-06-25T18:41:33.343495Z",
        "owner": "lucataco",
        "coverImage": "https://replicate.delivery/xezq/LcruS1mlR0p3NtjxKRJ8YZYMY2iZE1ro7drQKlKEiUI72nOF/output.png",
        "githubUrl": "https://github.com/lucataco/cog-OmniGen2",
        "paperUrl": "https://huggingface.co/papers/2506.18871",
        "licenseUrl": "https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "image": "https://replicate.delivery/pbxt/NFVLgKWVv48pYj7p8qCnKpeYDN5S46MlxYNaIEzRu03KG1xJ/yellow-dress.png",
              "width": 1024,
              "height": 1024,
              "prompt": "Change the dress to blue",
              "scheduler": "euler",
              "max_pixels": 1048576,
              "cfg_range_end": 1,
              "cfg_range_start": 0,
              "negative_prompt": "(((deformed))), blurry, over saturation, bad anatomy, disfigured, poorly drawn face, mutation, mutated, (extra_limb), (ugly), (poorly drawn hands), fused fingers, messy drawing, broken legs censor, censored, censor_bar",
              "num_inference_steps": 50,
              "text_guidance_scale": 5,
              "image_guidance_scale": 2,
              "max_input_image_side_length": 2048
            },
            "output": "https://replicate.delivery/xezq/LcruS1mlR0p3NtjxKRJ8YZYMY2iZE1ro7drQKlKEiUI72nOF/output.png",
            "prompt": "Change the dress to blue"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set to -1 for random seed",
          "image": "Input image to edit",
          "width": "Width of output image",
          "height": "Height of output image",
          "prompt": "Text prompt describing the desired image edit",
          "image_2": "Optional second input image for multi-image operations",
          "image_3": "Optional third input image for multi-image operations",
          "scheduler": "Scheduler to use",
          "max_pixels": "Maximum number of pixels in output",
          "cfg_range_end": "CFG range end",
          "cfg_range_start": "CFG range start",
          "negative_prompt": "Negative prompt to guide what should not be in the image",
          "num_inference_steps": "Number of denoising steps",
          "text_guidance_scale": "Guidance scale for text prompt",
          "image_guidance_scale": "Guidance scale for input image. Higher values increase consistency with input image",
          "max_input_image_side_length": "Maximum input image side length"
        }
      }
    },
    {
      "id": "lilekitty/kaneko-gen",
      "name": "kaneko-gen",
      "displayName": "kaneko-gen",
      "provider": "replicate",
      "category": "image",
      "endpoint": "lilekitty/kaneko-gen",
      "version": "627382d4ee73fee466de2a3e59ae99b831371610ae806193ebcfc7a3d295f7f3",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generates unrestricted images from text prompts using a fine-tuned Stable Diffusion model",
        "runCount": 1155,
        "confidence": 0.9,
        "qualityScore": 50.6295783408451,
        "createdAt": "2025-06-29T06:12:05.090363Z",
        "owner": "lilekitty",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/33f74fa1-47a4-420d-b363-32dc4cc05c2c/file_00000000223461f49254169c2176.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://choosealicense.com/licenses/mit/",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "steps": 28,
              "prompt": "cat girl, white hair, long hair, bikini, adult, blush, wink at viewer, open mouth, fang, full view",
              "guidance": 7,
              "image_width": 1024,
              "image_height": 1024,
              "negative_prompt": "text, talk bubble, low quality, watermark, signature"
            },
            "output": "https://replicate.delivery/xezq/qlYORwEHNFrsNN0NzIUwaaFfTKcN6eK0tdUH94Yk4wXozo7UA/kaneko_output.png",
            "prompt": "cat girl, white hair, long hair, bikini, adult, blush, wink at viewer, open mouth, fang, full view"
          }
        ],
        "parameterDescriptions": {
          "seed": "Seed (leave EMPTY for random)",
          "steps": "Number of inference steps",
          "prompt": "Text prompt for image",
          "guidance": "Guidance scale",
          "image_width": "Width of generated image",
          "image_height": "Height of generated image",
          "negative_prompt": "What to avoid"
        }
      }
    },
    {
      "id": "zsxkib/dream-o",
      "name": "dream-o",
      "displayName": "dream-o",
      "provider": "replicate",
      "category": "image",
      "endpoint": "zsxkib/dream-o",
      "version": "8f8d84ebe012e94a126b21c953b8dc33be86e4cf92b133b144bda94aa84e616b",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "👗Bytedance's DreamO: unified image customization model (IP, ID, Style, Try-On, etc.)🧣",
        "runCount": 1131,
        "confidence": 0.9,
        "qualityScore": 50.53846426852253,
        "createdAt": "2025-05-12T15:56:12.960111Z",
        "owner": "zsxkib",
        "coverImage": "https://replicate.delivery/yhqm/h78bCImZ6HrtBVM0pE0EEXW4naneIvVBkdviQJML2rC85erUA/output.webp",
        "githubUrl": "https://github.com/zsxkib/cog-DreamO",
        "paperUrl": "https://arxiv.org/abs/2504.16915",
        "licenseUrl": "https://github.com/bytedance/DreamO/blob/main/LICENSE",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": 7698454872441022000,
              "width": 1024,
              "height": 1024,
              "prompt": "the woman wearing a dress, In the banquet hall",
              "ref_res": 512,
              "guidance": 3.5,
              "true_cfg": 1,
              "num_steps": 12,
              "ref_task1": "id",
              "ref_task2": "ip",
              "neg_prompt": "",
              "ref_image1": "https://replicate.delivery/pbxt/MzZo0OcsWW6NBl10nsCZoIRcRP9aGSczwDwVSLW5QRn8zD42/0_1.webp",
              "ref_image2": "https://raw.githubusercontent.com/bytedance/DreamO/main/example_inputs/dress.png",
              "cfg_end_step": 0,
              "neg_guidance": 3.5,
              "output_format": "webp",
              "cfg_start_step": 0,
              "output_quality": 90,
              "first_step_guidance": 0
            },
            "output": "https://replicate.delivery/yhqm/h78bCImZ6HrtBVM0pE0EEXW4naneIvVBkdviQJML2rC85erUA/output.webp",
            "prompt": "the woman wearing a dress, In the banquet hall"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Leave blank or set to -1 for random.",
          "width": "Width of the output image (must be multiple of 16)",
          "height": "Height of the output image (must be multiple of 16)",
          "prompt": "Prompt for image generation",
          "ref_res": "Resolution for non-ID reference image preprocessing (target pixel area)",
          "guidance": "Guidance scale. Lower for less intensity/more realism (e.g., faces), higher for stronger prompt adherence.",
          "true_cfg": "True CFG scale (advanced, requires distilled CFG LoRA)",
          "num_steps": "Number of inference steps",
          "ref_task1": "Task for reference image 1 ('ip': object/character, 'id': face identity, 'style': preserve style/background)",
          "ref_task2": "Task for reference image 2 ('ip': object/character, 'id': face identity, 'style': preserve style/background)",
          "neg_prompt": "Negative prompt",
          "ref_image1": "Reference image 1 (optional)",
          "ref_image2": "Reference image 2 (optional)",
          "cfg_end_step": "CFG end step (advanced)",
          "neg_guidance": "Negative guidance scale",
          "output_format": "Format of the output image",
          "cfg_start_step": "CFG start step (advanced)",
          "output_quality": "Output quality for lossy formats (jpg, webp)",
          "first_step_guidance": "First step guidance scale override (advanced, 0 uses main guidance)"
        }
      }
    },
    {
      "id": "zsxkib/mmaudio-t4",
      "name": "mmaudio-t4",
      "displayName": "mmaudio-t4",
      "provider": "replicate",
      "category": "video",
      "endpoint": "zsxkib/mmaudio-t4",
      "version": "330393ae234d739f3261ae389a5506a73a1bae8c77dc6c6faebc5bde78b6e972",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image",
        "videoUrl": "video"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Cost-optimized MMAudio V2 (T4 GPU): Add sound to video using this version running on T4 hardware for lower cost. Synthesizes high-quality audio from video content.",
        "runCount": 1016,
        "confidence": 0.9,
        "qualityScore": 50.07320952922745,
        "createdAt": "2025-04-02T12:07:31.500545Z",
        "owner": "zsxkib",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/187b4c3e-4e9a-41a5-81a1-fe182219d163/replicate-prediction-qr4wjhk791r.webp",
        "githubUrl": "https://github.com/zsxkib/cog-mmaudio",
        "paperUrl": "https://hkchengrex.github.io/MMAudio",
        "licenseUrl": "https://github.com/hkchengrex/MMAudio#MIT-1-ov-file",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "video": "https://huggingface.co/hkchengrex/MMAudio/resolve/main/examples/sora_kraken.mp4",
              "prompt": "waves, storm",
              "duration": 10,
              "num_steps": 25,
              "cfg_strength": 4.5,
              "negative_prompt": "music"
            },
            "output": "https://replicate.delivery/czjl/YiDWoy40aW5sC9T8lqKsldET8rW4DZ4vXGHhw6A7wELBdrHF/20250402_121809.mp4",
            "prompt": "waves, storm"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Use -1 or leave blank to randomize the seed",
          "image": "Optional image file for image-to-audio generation (experimental)",
          "video": "Optional video file for video-to-audio generation",
          "prompt": "Text prompt for generated audio",
          "duration": "Duration of output in seconds",
          "num_steps": "Number of inference steps",
          "cfg_strength": "Guidance strength (CFG)",
          "negative_prompt": "Negative prompt to avoid certain sounds"
        }
      }
    },
    {
      "id": "deepfates/flux-utopian-scholastic",
      "name": "flux-utopian-scholastic",
      "displayName": "flux-utopian-scholastic",
      "provider": "replicate",
      "category": "image",
      "endpoint": "deepfates/flux-utopian-scholastic",
      "version": "6d07450fbdd415a5b2d4bf4aca4eb9a9c34cd77812483869406a7bb2c33d022a",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A FLUX model fine-tuned on images of the Utopian Scholastic aesthetic. Good at text too",
        "runCount": 950,
        "confidence": 0.6,
        "qualityScore": 49.78180516937414,
        "createdAt": "2025-05-01T23:36:32.907595Z",
        "owner": "deepfates",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/934bd62b-15a3-4877-989a-39d8f1f94799/replicate-prediction-zepbbdk7jhr.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "UTPN style image of \"Utopian Scholastic\" title card, space, blonde-haired woman, VR goggles, virtual reality, cosmic technology, gloved hand. This artwork features a futuristic rendering of a woman wearing sleek, silver, cybernetic VR goggles, her long blonde hair flowing in a sci-fi environment. The focus is on her eyes, framed by the VR glasses, with a mirrored string of pearls excluding her gaze. A white gloved hand reaches out in front of her against a backdrop of swirling white light and stars. Abstract elements blend with technological symbols, creating a dynamic scene, contrasting retro aesthetics with bold, modern lines. The text reads \"Utopian Scholastic\" in UTPN font",
              "go_fast": false,
              "lora_scale": 1.3,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "4:5",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 31
            },
            "output": [
              "https://replicate.delivery/xezq/IOXjmBsx4369IBhmK4rrYIpEzNSTZCBpcXCe9e3zlxwtktoUA/out-0.webp"
            ],
            "prompt": "UTPN style image of \"Utopian Scholastic\" title card, space, blonde-haired woman, VR goggles, virtual reality, cosmic technology, gloved hand. This artwork features a futuristic rendering of a woman wearing sleek, silver, cybernetic VR goggles, her long blonde hair flowing in a sci-fi environment. The focus is on her eyes, framed by the VR glasses, with a mirrored string of pearls excluding her gaze. A white gloved hand reaches out in front of her against a backdrop of swirling white light and stars. Abstract elements blend with technological symbols, creating a dynamic scene, contrasting retro aesthetics with bold, modern lines. The text reads \"Utopian Scholastic\" in UTPN font"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "lucataco/wan-2.1-1.3b-vid2vid",
      "name": "wan-2.1-1.3b-vid2vid",
      "displayName": "wan-2.1-1.3b-vid2vid",
      "provider": "replicate",
      "category": "video",
      "endpoint": "lucataco/wan-2.1-1.3b-vid2vid",
      "version": "9349766527ed95fa6194dcca4cae3d497357e207025beb0b97fb0403420142b8",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Wan 2.1 1.3b Video to Video. Wan is a powerful visual generation model developed by Tongyi Lab of Alibaba Group",
        "runCount": 885,
        "confidence": 0.9,
        "qualityScore": 49.47433721887051,
        "createdAt": "2025-04-02T17:50:53.669237Z",
        "owner": "lucataco",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/dc302e8f-162c-4ef0-96f9-b7d4a840c904/sunglasses.webp",
        "githubUrl": "https://github.com/modelscope/DiffSynth-Studio/tree/main/examples/wanvideo",
        "paperUrl": "https://wanxai.com/",
        "licenseUrl": "https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "tiled": true,
              "prompt": "a puppy wearing black sunglasses",
              "cfg_scale": 6,
              "num_frames": 81,
              "input_video": "https://replicate.delivery/pbxt/MbUZEHGJFGoTaCAlbxPCAHvkmQrWOwAWGhb3o6xwdYRtoV7C/replicate-prediction-6jxv92xhadrma0cncbabf652xm.mp4",
              "aspect_ratio": "832x480",
              "negative_prompt": "low quality, blurry, distorted, disfigured, text, watermark",
              "frames_per_second": 16,
              "denoising_strength": 0.7,
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/xezq/8pFLomYr6wrQIJOYErDNrnZ5xwqQLiirI1yuB2ZmDSDfbZPKA/tmp_vurc1dr.mp4",
            "prompt": "a puppy wearing black sunglasses"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible results (leave blank for random)",
          "tiled": "Whether to use tiled sampling for better quality on larger videos",
          "prompt": "Text prompt describing what you want to generate or modify",
          "cfg_scale": "Classifier free guidance scale (higher values strengthen prompt adherence)",
          "num_frames": "Number of frames to generate in the output video",
          "input_video": "Input video for video-to-video generation",
          "aspect_ratio": "Aspect ratio for the output video",
          "negative_prompt": "Negative prompt to specify what to avoid in the generation",
          "frames_per_second": "Number of frames per second in the output video",
          "denoising_strength": "Strength of denoising when using video-to-video mode. Higher values change more content.",
          "num_inference_steps": "Number of sampling steps (higher = better quality but slower)"
        }
      }
    },
    {
      "id": "kwaivgi/kling-v1.5-pro",
      "name": "kling-v1.5-pro",
      "displayName": "kling-v1.5-pro",
      "provider": "replicate",
      "category": "video",
      "endpoint": "kwaivgi/kling-v1.5-pro",
      "version": "63a990e82809f01ded0ec0375e907870943aa01e7856c7c6455aae4bc30bb8fc",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "start_image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate 5s and 10s videos in 1080p resolution at 30fps",
        "runCount": 778,
        "confidence": 0.9,
        "qualityScore": 48.91537457672564,
        "createdAt": "2025-06-04T13:03:31.080907Z",
        "owner": "kwaivgi",
        "coverImage": "https://replicate.delivery/xezq/CVp8Ptehl91sQy01r56RvfAvhVSKZMOnqCSfOzYrxad9IXbpA/tmpyl_rsnxt.mp4",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "a woman looks around",
              "duration": 5,
              "cfg_scale": 0.5,
              "start_image": "https://replicate.delivery/pbxt/N1hyn7Qcf5BofMp3tjkKZ2hDpo3Mn2gZtfQnVkQzBJeXRHl9/4j0kbtrhn9rm80cpw10bepj7q4.png",
              "aspect_ratio": "16:9",
              "negative_prompt": ""
            },
            "output": "https://replicate.delivery/xezq/CVp8Ptehl91sQy01r56RvfAvhVSKZMOnqCSfOzYrxad9IXbpA/tmpyl_rsnxt.mp4",
            "prompt": "a woman looks around"
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for video generation",
          "duration": "Duration of the video in seconds",
          "cfg_scale": "Flexibility in video generation; The higher the value, the lower the model's degree of flexibility, and the stronger the relevance to the user's prompt.",
          "end_image": "Last frame of the video. A start or end image is required.",
          "start_image": "First frame of the video. A start or end image is required.",
          "aspect_ratio": "Aspect ratio of the video. Ignored if start_image is provided.",
          "negative_prompt": "Things you do not want to see in the video"
        }
      }
    },
    {
      "id": "prunaai/flux.1-dev-lora",
      "name": "flux.1-dev-lora",
      "displayName": "flux.1-dev-lora",
      "provider": "replicate",
      "category": "image",
      "endpoint": "prunaai/flux.1-dev-lora",
      "version": "19048f659cedeb72d7bbf6a3c4ee8fc79998e2c3b440ba489b44ac028489e8b1",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This is a 3x faster FLUX.1 [dev] model from Black Forest Labs, optimised with pruna with minimal quality loss.",
        "runCount": 660,
        "confidence": 0.6,
        "qualityScore": 48.2020145948564,
        "createdAt": "2025-06-05T13:00:03.094947Z",
        "owner": "prunaai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/22945d66-40f2-4c80-a186-e6e8b0b0556a/D775537D-1226-4F91-8A5A-B0160DB4D.jpg",
        "githubUrl": "https://github.com/black-forest-labs/flux",
        "paperUrl": "https://arxiv.org/abs/2506.15742",
        "licenseUrl": "https://github.com/black-forest-labs/flux/blob/main/LICENSE",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "lora": "prithivMLmods/Flux-Long-Toon-LoRA",
              "seed": 0,
              "prompt": "Long toons, a close-up of a cartoon characters face is featured in a vibrant red backdrop. The characters head is adorned with a gray hoodie, a red t-shirt, and a pair of pink earbuds. His eyes, a nose, and mustache are adorned with tiny white dots, adding a pop of color to the scene. His hair is a mix of black and gray, while his ears are a darker shade of pink.",
              "guidance": 3,
              "lora_scale": 1,
              "megapixels": "1",
              "speed_mode": "Extra Juiced 🔥",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "jpg",
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/ixSFHQQBelX3MKrVweXg5vyCAayFilzcBJYzJB5KFys2Yp8UA/output_0_0.jpeg"
            ],
            "prompt": "Long toons, a close-up of a cartoon characters face is featured in a vibrant red backdrop. The characters head is adorned with a gray hoodie, a red t-shirt, and a pair of pink earbuds. His eyes, a nose, and mustache are adorned with tiny white dots, adding a pop of color to the scene. His hair is a mix of black and gray, while his ears are a darker shade of pink."
          }
        ],
        "parameterDescriptions": {
          "lora": "Load LoRA weights. Supports HuggingFace URLs in the format <owner>/<model-name>[/<lora-weights-file.safetensors>]. For example, 'fofr/flux-pixar-cars'.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image mode. The aspect ratio of your output will match this image",
          "prompt": "Prompt for generated image",
          "guidance": "Guidance for generated image",
          "extra_lora": "Load LoRA weights. Supports HuggingFace URLs in the format <owner>/<model-name>[/<lora-weights-file.safetensors>]. For example, 'fofr/flux-pixar-cars'.",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "speed_mode": "Speed optimization level",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio of the output image",
          "output_format": "Format of the output images",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "num_inference_steps": "Number of denoising steps. Recommended range is 28-50, and lower number of steps produce lower quality outputs, faster."
        }
      }
    },
    {
      "id": "kwaivgi/kling-v2.0",
      "name": "kling-v2.0",
      "displayName": "kling-v2.0",
      "provider": "replicate",
      "category": "video",
      "endpoint": "kwaivgi/kling-v2.0",
      "version": "03c47b845aed8a009e0f83a45be0a2100ca11a7077e667a33224a54e85b2965c",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "start_image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate 5s and 10s videos in 720p resolution",
        "runCount": 56413,
        "confidence": 0.9,
        "qualityScore": 47.513868942004756,
        "createdAt": "2025-06-04T11:27:47.833263Z",
        "owner": "kwaivgi",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/c39d026b-b155-4904-8404-fefa3a2ff305/replicate-prediction-xs2x7fjs.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "A cute hamster lies leisurely on a lifebuoy, wearing fashionable sunglasses, and drifts with the gentle waves on the shimmering sea surface. The hamster reclines comfortably, enjoying a peaceful and pleasant time. Cartoon style, the camera follows the subject moving, with a heartwarming and high picture quality.",
              "duration": 5,
              "cfg_scale": 0.5,
              "aspect_ratio": "16:9",
              "negative_prompt": ""
            },
            "output": "https://replicate.delivery/xezq/5yttbR1oSDJzHpWnebG5iZyr40Sil3qHJeYduWYJuND4MSmUA/tmpt4eqvp03.mp4",
            "prompt": "A cute hamster lies leisurely on a lifebuoy, wearing fashionable sunglasses, and drifts with the gentle waves on the shimmering sea surface. The hamster reclines comfortably, enjoying a peaceful and pleasant time. Cartoon style, the camera follows the subject moving, with a heartwarming and high picture quality."
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for video generation",
          "duration": "Duration of the video in seconds",
          "cfg_scale": "Flexibility in video generation; The higher the value, the lower the model's degree of flexibility, and the stronger the relevance to the user's prompt.",
          "start_image": "First frame of the video (optional)",
          "aspect_ratio": "Aspect ratio of the video. Ignored if start_image is provided.",
          "negative_prompt": "Things you do not want to see in the video"
        }
      }
    },
    {
      "id": "prunaai/vace-1.3b",
      "name": "vace-1.3b",
      "displayName": "vace-1.3b",
      "provider": "replicate",
      "category": "video",
      "endpoint": "prunaai/vace-1.3b",
      "version": "ecf7f253f49c527c2baaf22d630685b7b877e302a43cae4c97a623c0ef906bd7",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This is VACE-1.3B model optimised with pruna ai. Wan2.1 VACE is an all-in-one model for video creation and editing.",
        "runCount": 552,
        "confidence": 0.9,
        "qualityScore": 47.42725131304698,
        "createdAt": "2025-05-26T10:15:51.798184Z",
        "owner": "prunaai",
        "coverImage": "https://replicate.delivery/xezq/qRl0z5qTqYLoIhWIR2foz0kaFKpSmLAIxrRl971ZgSffZXapA/output.mp4",
        "githubUrl": "https://github.com/ali-vilab/VACE",
        "paperUrl": "https://arxiv.org/abs/2503.07598",
        "licenseUrl": "https://github.com/ali-vilab/VACE?tab=Apache-2.0-1-ov-file",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "size": "832*480",
              "prompt": "\"In a joyful and festive scene, a little girl wearing a bright red spring outfit is playing with her cute cartoon snake. Her outfit is embroidered with golden auspicious patterns, radiating a festive atmosphere, and her face is beaming with a bright smile. The snake has a vibrant green body with a rounded shape and large eyes that make it look both friendly and humorous. The little girl happily strokes the snake's head gently, sharing this warm moment together. Colorful lanterns and ribbons decorate the surroundings, with sunlight shining upon them, creating an atmosphere full of friendship and happiness for the New Year.",
              "frame_num": 81,
              "speed_mode": "Juiced 🔥 (more speed)",
              "sample_shift": 16,
              "sample_steps": 50,
              "sample_solver": "unipc",
              "src_ref_images": [
                "https://replicate.delivery/pbxt/N1Al9HgV6K1s82OGqowiWhQY9y5WpHQJHW5X7IcMIkfWGDH0/girl.png",
                "https://replicate.delivery/pbxt/N1Al9KotB8pX7PbiOe3lSQAoGcjOuFHT2aYR4zAfo0hdHPgL/snake.png"
              ],
              "sample_guide_scale": 5
            },
            "output": "https://replicate.delivery/xezq/qRl0z5qTqYLoIhWIR2foz0kaFKpSmLAIxrRl971ZgSffZXapA/output.mp4",
            "prompt": "\"In a joyful and festive scene, a little girl wearing a bright red spring outfit is playing with her cute cartoon snake. Her outfit is embroidered with golden auspicious patterns, radiating a festive atmosphere, and her face is beaming with a bright smile. The snake has a vibrant green body with a rounded shape and large eyes that make it look both friendly and humorous. The little girl happily strokes the snake's head gently, sharing this warm moment together. Colorful lanterns and ribbons decorate the surroundings, with sunlight shining upon them, creating an atmosphere full of friendship and happiness for the New Year."
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed (-1 for random)",
          "size": "Output resolution",
          "prompt": "Prompt",
          "src_mask": "Input mask video to edit.",
          "frame_num": "Number of frames to generate.",
          "src_video": "Input video to edit.",
          "speed_mode": "Speed optimization level",
          "sample_shift": "Sample shift",
          "sample_steps": "Sample steps",
          "sample_solver": "Sample solver",
          "src_ref_images": "Input reference images to edit.",
          "sample_guide_scale": "Sample guide scale"
        }
      }
    },
    {
      "id": "lucataco/wan2.1-i2v-lora",
      "name": "wan2.1-i2v-lora",
      "displayName": "wan2.1-i2v-lora",
      "provider": "replicate",
      "category": "video",
      "endpoint": "lucataco/wan2.1-i2v-lora",
      "version": "f130c663a974802a8e5826a49b82064a27d5ffeec8f008ae3195a70e49527a97",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Wan2.1 14B 480p LoRA inference via Diffusers (Work in progress)",
        "runCount": 548,
        "confidence": 0.9,
        "qualityScore": 47.395723444500916,
        "createdAt": "2025-03-15T06:39:37.427689Z",
        "owner": "lucataco",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/9c09038a-fde2-4c38-85a7-9bb4636ffcf5/dog-1024.png",
        "githubUrl": "https://github.com/lucataco/cog-wan2.1-i2v-lora",
        "paperUrl": null,
        "licenseUrl": "https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "fps": 16,
              "image": "https://replicate.delivery/pbxt/Mf7Um7V1nQjebWjOi3RndihR5sK95269LxZDY8s17mqW5jda/dog-1024.png",
              "prompt": "In the video, a miniature dog is presented. The dog is held in a person's hands. The person then presses on the dog, causing a sq41sh squish effect. The person keeps pressing down on the dog, further showing the sq41sh squish effect.",
              "duration": 3,
              "lora_url": "https://huggingface.co/Remade-AI/Squish/resolve/main/squish_18.safetensors",
              "resize_mode": "auto",
              "lora_strength": 1,
              "guidance_scale": 5,
              "negative_prompt": "low quality, bad quality, blurry, pixelated, watermark",
              "num_inference_steps": 40
            },
            "output": "https://replicate.delivery/yhqm/X0yqkQLeLfuNUESVZHL53DIzmRTtkNJiXFOWsZCPDyKamtYUA/output.mp4",
            "prompt": "In the video, a miniature dog is presented. The dog is held in a person's hands. The person then presses on the dog, causing a sq41sh squish effect. The person keeps pressing down on the dog, further showing the sq41sh squish effect."
          }
        ],
        "parameterDescriptions": {
          "fps": "Frames per second",
          "seed": "Random seed for generation",
          "image": "Input image",
          "prompt": "Text prompt describing the desired video effect",
          "duration": "Video duration in seconds",
          "lora_url": "URL to the LoRA weights (HuggingFace or CivitAI)",
          "resize_mode": "Image resizing strategy",
          "lora_strength": "LoRA effect strength",
          "guidance_scale": "Guidance scale for generation",
          "negative_prompt": "Text prompt describing what to avoid in the video",
          "num_inference_steps": "Number of inference steps"
        }
      }
    },
    {
      "id": "abdulali025/andro-upscaler",
      "name": "andro-upscaler",
      "displayName": "andro-upscaler",
      "provider": "replicate",
      "category": "image",
      "endpoint": "abdulali025/andro-upscaler",
      "version": "5ea1149df001b5162a19f03cf21cca6760b9e72da7206d16356a2ad5735219f7",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A model Flux.1-dev-Controlnet-Upscaler by www.androcoders.in",
        "runCount": 533,
        "confidence": 0.9,
        "qualityScore": 47.27541257028556,
        "createdAt": "2025-03-19T09:50:46.872722Z",
        "owner": "abdulali025",
        "coverImage": "https://replicate.delivery/yhqm/TIx9pXuWkTqqLBhVvHJttB5LdsffJtRCwtXPmR4VESv1fcxoA/output.jpg",
        "githubUrl": "https://github.com/black-forest-labs/flux",
        "paperUrl": "https://docs.bfl.ml/",
        "licenseUrl": "https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "",
              "input_image": "https://replicate.delivery/pbxt/Mf8s35ireThU5CzqbjQJgLxER0hQ8l5ExCtjoiqTr5nxgk0B/cat-2.jpeg",
              "guidance_scale": 5,
              "upscale_factor": 4,
              "num_inference_steps": 28,
              "controlnet_conditioning_scale": 0.6
            },
            "output": "https://replicate.delivery/yhqm/TIx9pXuWkTqqLBhVvHJttB5LdsffJtRCwtXPmR4VESv1fcxoA/output.jpg",
            "prompt": ""
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Leave blank to randomize the seed",
          "prompt": "Text prompt to guide the upscaling. Leave empty for default behavior.",
          "input_image": "Input image to upscale",
          "guidance_scale": "Guidance scale for Image adherence",
          "upscale_factor": "Factor by which to upscale the image",
          "apply_cc_preset": "Applying Color Correction ",
          "num_inference_steps": "Number of denoising steps",
          "controlnet_conditioning_scale": "Controlnet conditioning scale"
        }
      }
    },
    {
      "id": "sansan1981/noirvision",
      "name": "noirvision",
      "displayName": "noirvision",
      "provider": "replicate",
      "category": "image",
      "endpoint": "sansan1981/noirvision",
      "version": "efd0fafa652555a03e4d55c26b05d83343be2740c4cbb1e5928a69236369eb09",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "NoirVisions is a text-to-image AI model created by Boss Luxe, designed to generate soft, airbrushed, high-fashion digital portraits centering Black women. Trained exclusively on original, curated imagery, this model captures luxury, melanin-rich beauty, a",
        "runCount": 522,
        "confidence": 0.6,
        "qualityScore": 47.18501688867274,
        "createdAt": "2025-07-01T16:40:24.862075Z",
        "owner": "sansan1981",
        "coverImage": "https://replicate.delivery/xezq/auBkSNJ5hOryO5xY2f2QYcWmmrLt8oP8EsayFkmeWe3XARlpA/out-3.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "NOIRV An airbrush oil painting of a hyper-realistic African American woman with a baby blue wig styled in flipped-up ends, cascading down her back. Her mesh Mugler dress is cut low and wide to let her bump shine — adorned in blue Swarovski crystals shaped like stars. She wears white designer panties with “Baby Boss” in rhinestones and matching sky-blue platform heels. Her bump is highlighted with shimmering baby oil, and a custom bump chain dangles just above her bellybutton. Her brown eyes glow behind Dior shades as a smoke cannon explodes with blue powder around her. The cake is a mini iced Birkin bag with baby bottles sticking out the top. Vibrant colors, and high resolution, hyper-detailed.\n\n\n\n\n\n\n\n\n\n\n",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 4,
              "aspect_ratio": "1:1",
              "output_format": "png",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/sf9sMSY3j8WcSCn3engW4RQcFfOCIHcLKIJUua0Hv5CWARlpA/out-0.png",
              "https://replicate.delivery/xezq/EMBW5aTcxrYDGJM7l4FyphajtFe15yZBTMMryv27mm0FQUZKA/out-1.png",
              "https://replicate.delivery/xezq/KefSd5zCIRsQfpefN0OJUAYxDeUWkygf5ODESNk62fh3LgoyUA/out-2.png",
              "https://replicate.delivery/xezq/auBkSNJ5hOryO5xY2f2QYcWmmrLt8oP8EsayFkmeWe3XARlpA/out-3.png"
            ],
            "prompt": "NOIRV An airbrush oil painting of a hyper-realistic African American woman with a baby blue wig styled in flipped-up ends, cascading down her back. Her mesh Mugler dress is cut low and wide to let her bump shine — adorned in blue Swarovski crystals shaped like stars. She wears white designer panties with “Baby Boss” in rhinestones and matching sky-blue platform heels. Her bump is highlighted with shimmering baby oil, and a custom bump chain dangles just above her bellybutton. Her brown eyes glow behind Dior shades as a smoke cannon explodes with blue powder around her. The cake is a mini iced Birkin bag with baby bottles sticking out the top. Vibrant colors, and high resolution, hyper-detailed.\n\n\n\n\n\n\n\n\n\n\n"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "ibm-granite/granite-speech-3.3-8b",
      "name": "granite-speech-3.3-8b",
      "displayName": "granite-speech-3.3-8b",
      "provider": "replicate",
      "category": "image",
      "endpoint": "ibm-granite/granite-speech-3.3-8b",
      "version": "a7ccfe1d89f8ae8ebbaf1448c0e0bf1113cec458e182322ca0c49f4c4b62ebef",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Granite-speech-3.3-8b is a compact and efficient speech-language model, specifically designed for automatic speech recognition (ASR) and automatic speech translation (AST).",
        "runCount": 513,
        "confidence": 0.6,
        "qualityScore": 47.10963118995276,
        "createdAt": "2025-07-23T15:27:43.652216Z",
        "owner": "ibm-granite",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/ecc9f052-6ded-4e31-9a9f-218d1417b512/Granite_2D_B_Low_no_Grain.png",
        "githubUrl": "https://github.com/bjhargrave/cog-models/tree/main/ibm-granite/granite-speech-3.3-8b",
        "paperUrl": "https://arxiv.org/abs/2505.08699",
        "licenseUrl": "https://www.apache.org/licenses/LICENSE-2.0",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "audio": [
                "https://replicate.delivery/pbxt/NMdAjCoC0WiNKkHIIbSsmssPEXujCRSDIjg9LlJYkt5BGs8d/10226_10111_000000.wav"
              ],
              "top_k": 50,
              "top_p": 0.9,
              "prompt": "Transcribe the speech into written form.",
              "max_tokens": 512,
              "min_tokens": 0,
              "temperature": 0.6,
              "presence_penalty": 0,
              "frequency_penalty": 0
            },
            "output": [
              "after",
              " his",
              " nap",
              " tim",
              "oth",
              "y",
              " l",
              "az",
              "ily",
              " st",
              "ret",
              "ched",
              " first",
              " one",
              " grey",
              " vel",
              "vet",
              " foot",
              " then",
              " another",
              " st",
              "rolled",
              " ind",
              "ol",
              "ently",
              " to",
              " his",
              " plate",
              " turning",
              " over",
              " the",
              " food",
              " carefully",
              " selecting",
              " choice",
              " bits",
              " n",
              "osing",
              " out",
              " that",
              " which",
              " he",
              " sc",
              "orn",
              "ed",
              " upon",
              " the",
              " clean",
              " he",
              "arth",
              ""
            ],
            "prompt": "Transcribe the speech into written form."
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Leave blank to randomize the seed.",
          "audio": "Audio inputs for the model.",
          "top_k": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering).",
          "top_p": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751).",
          "prompt": "User prompt to send to the model.",
          "max_tokens": "The maximum number of tokens the model should generate as output.",
          "min_tokens": "The minimum number of tokens the model should generate as output.",
          "temperature": "The value used to modulate the next token probabilities.",
          "chat_template": "A template to format the prompt with. If not provided, the default prompt template will be used.",
          "system_prompt": "System prompt to send to the model.The chat template provides a good default.",
          "stop_sequences": "A comma-separated list of sequences to stop generation at. For example, '<end>,<stop>' will stop generation at the first instance of 'end' or '<stop>'.",
          "presence_penalty": "Presence penalty",
          "frequency_penalty": "Frequency penalty"
        }
      }
    },
    {
      "id": "pixverse/pixverse-v3.5",
      "name": "pixverse-v3.5",
      "displayName": "pixverse-v3.5",
      "provider": "replicate",
      "category": "video",
      "endpoint": "pixverse/pixverse-v3.5",
      "version": "3d7475f750ae1534f1075909dac55f74cfdc6d0bfa81431ab2bbcd78a1f7cb5d",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Create videos in as little as 10 seconds. 5s or 8s videos at 360p, 540p, 720p or 1080p.",
        "runCount": 489,
        "confidence": 0.9,
        "qualityScore": 46.90196080028514,
        "createdAt": "2025-07-07T16:50:16.707524Z",
        "owner": "pixverse",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/dcea44a0-7f7d-4595-a8b3-69b80e9b4a49/replicate-pixverse-35.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://docs.pixverse.ai/PixVerse-Platform-Terms-of-Service-1773e99bf35080c6a802fae0e3629708",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "style": "anime",
              "effect": "None",
              "prompt": "an anime action scene, a woman looks around slowly, mountain landscape in the background",
              "quality": "540p",
              "duration": 5,
              "motion_mode": "normal",
              "aspect_ratio": "16:9",
              "negative_prompt": ""
            },
            "output": "https://replicate.delivery/xezq/R2C3OfUySgT9b6HjECF7LweKS0Yb4ekYpS0ppAIMKsieIk2SB/tmpqt7a3gzs.mp4",
            "prompt": "an anime action scene, a woman looks around slowly, mountain landscape in the background"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "image": "Image to use for the first frame of the video",
          "style": "Style of the video",
          "effect": "Special effect to apply to the video. Does not work with last_frame_image.",
          "prompt": "Text prompt for video generation",
          "quality": "Resolution of the video. 360p and 540p cost the same, but 720p and 1080p cost more. See the README for details.",
          "duration": "Duration of the video in seconds. 8 second videos cost twice as much as 5 second videos. (1080p does not support 8 second duration)",
          "motion_mode": "Motion mode for the video. Smooth videos generate more frames, so they cost twice as much. (smooth is only available when using a 5 second duration, 1080p does not support smooth motion)",
          "aspect_ratio": "Aspect ratio of the video",
          "negative_prompt": "Negative prompt to avoid certain elements in the video",
          "last_frame_image": "Use to generate a video that transitions from the first image to the last image. Must be used with image.",
          "sound_effect_switch": "Enable background music or sound effects",
          "sound_effect_content": "Sound effect prompt. If not given, a random sound effect will be generated."
        }
      }
    },
    {
      "id": "minimax/video-01-director",
      "name": "video-01-director",
      "displayName": "video-01-director",
      "provider": "replicate",
      "category": "video",
      "endpoint": "minimax/video-01-director",
      "version": "455972c1d61cd32b05be9b412e63fb5811e179760299eb3023323a1630f9961b",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate videos with specific camera movements",
        "runCount": 47595,
        "confidence": 0.9,
        "qualityScore": 46.775704558523756,
        "createdAt": "2025-06-19T11:31:54.774956Z",
        "owner": "minimax",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/61749d60-2481-48e1-afc1-5a0a3d51ff7f/replicate-prediction-d9m5myr4.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "prompt": "[truck left, pan right, tracking shot] bullet time effect",
              "prompt_optimizer": true,
              "first_frame_image": "https://replicate.delivery/pbxt/MYlgrLz3fkaOdsOpAY4H0ugeGkhJaZj2AM3LrzChrRA2FSyt/MemeLoveTriangle_297886754.webp"
            },
            "output": "https://replicate.delivery/xezq/UpqkYwl7hTqTJ5rfIE0eb5WpDv6quG6PeFcdtH157Y2uonloA/tmp2dc62s6m.output.mp4",
            "prompt": "[truck left, pan right, tracking shot] bullet time effect"
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]",
          "prompt_optimizer": "Use prompt optimizer",
          "first_frame_image": "First frame image for video generation. The output video will have the same aspect ratio as this image."
        }
      }
    },
    {
      "id": "fofr/kontext-ps1",
      "name": "kontext-ps1",
      "displayName": "kontext-ps1",
      "provider": "replicate",
      "category": "image",
      "endpoint": "fofr/kontext-ps1",
      "version": "ded71b0f28d4e2a61b0789fee9e42b65a20b69b90a6d94b82b05841a5029e62a",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "FLUX Kontext fine-tune that let's you restyle any image as a PS1 or PS2 video game",
        "runCount": 459,
        "confidence": 0.9,
        "qualityScore": 46.62757831681574,
        "createdAt": "2025-07-15T08:15:06.584379Z",
        "owner": "fofr",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/94595ecb-5397-4395-b0e5-bc88f97e9aa2/replicate-prediction-t16qm6as.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "render this image like a ps1 game (no UI)",
              "guidance": 2.5,
              "megapixels": "1",
              "input_image": "https://replicate.delivery/pbxt/NMRuqfZykP9mm4KdF8PL8r7Y73Ffk3BZyNjCfC0kVTJEtcRt/cool_selfie.webp",
              "aspect_ratio": "match_input_image",
              "lora_strength": 1,
              "output_format": "webp",
              "output_quality": 80,
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/xezq/D6PUS7iPjKqnC9NTMWPLJTLJBXzkRVeY9VlGdQv30fTQc6BVA/output.webp",
            "prompt": "render this image like a ps1 game (no UI)"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible generation. Leave blank for random.",
          "prompt": "Text description of what you want to generate, or the instruction on how to edit the given image.",
          "guidance": "Guidance scale for generation",
          "megapixels": "Approximate number of megapixels for generated image",
          "input_image": "Image to use as reference. Must be jpeg, png, gif, or webp.",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "lora_strength": "Strength of the lora",
          "output_format": "Output image format",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "replicate_weights": "Path to the lora weights",
          "num_inference_steps": "Number of inference steps",
          "disable_safety_checker": "Disable NSFW safety checker"
        }
      }
    },
    {
      "id": "kwaivgi/kling-v1.5-standard",
      "name": "kling-v1.5-standard",
      "displayName": "kling-v1.5-standard",
      "provider": "replicate",
      "category": "video",
      "endpoint": "kwaivgi/kling-v1.5-standard",
      "version": "39c6b530fb14a8581bbda46e5fce3b3d59110c1150efd004325da2e2901ac8de",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "start_image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate 5s and 10s videos in 720p resolution at 30fps",
        "runCount": 423,
        "confidence": 0.9,
        "qualityScore": 46.27365856592732,
        "createdAt": "2025-06-04T12:52:47.471857Z",
        "owner": "kwaivgi",
        "coverImage": "https://replicate.delivery/xezq/geoGx04RhcWVWyTXfNoM9YgKVNecaZLlJ6Mp3MBwMA5zhWbpA/tmph_0er4mw.mp4",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "a woman looks around",
              "duration": 5,
              "cfg_scale": 0.5,
              "start_image": "https://replicate.delivery/pbxt/N1hfD2a5qLxybqR81gbn1z71f91YM08tyqR9IcLo1yzVQDbf/tq042p1dhdrm80cnrj6bkgpnx8.png",
              "aspect_ratio": "16:9",
              "negative_prompt": ""
            },
            "output": "https://replicate.delivery/xezq/geoGx04RhcWVWyTXfNoM9YgKVNecaZLlJ6Mp3MBwMA5zhWbpA/tmph_0er4mw.mp4",
            "prompt": "a woman looks around"
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for video generation",
          "duration": "Duration of the video in seconds",
          "cfg_scale": "Flexibility in video generation; The higher the value, the lower the model's degree of flexibility, and the stronger the relevance to the user's prompt.",
          "start_image": "First frame of the video.",
          "aspect_ratio": "Aspect ratio of the video. Ignored if start_image is provided.",
          "negative_prompt": "Things you do not want to see in the video"
        }
      }
    },
    {
      "id": "flux-kontext-apps/restyle-video-frame",
      "name": "restyle-video-frame",
      "displayName": "restyle-video-frame",
      "provider": "replicate",
      "category": "image",
      "endpoint": "flux-kontext-apps/restyle-video-frame",
      "version": "0d23ebbaa8e8c733c8984eddaef53e1f41c1ec2a62ce6244efcbab39b59322f1",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "videoUrl": "video"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Use flux-kontext-pro to change the first or last frame of a video. Useful to use as inputs for restyling an entire video in a certain way",
        "runCount": 418,
        "confidence": 0.9,
        "qualityScore": 46.222140229662955,
        "createdAt": "2025-07-24T21:31:02.650800Z",
        "owner": "flux-kontext-apps",
        "coverImage": "https://replicate.delivery/xezq/7e5CfHf76AXHSpMHn7r8SNN65Fw0Nu4Gxrsp9a5HryPsww4pA/tmpia3hkkv5.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "frame": "first",
              "video": "https://replicate.delivery/pbxt/NHXa8wBNdkuezb6D4K930uTE1GxQEdavDzPE85Iz0LEX5S6j/A_ferrari_f40_202506211556_4g8tu.mp4",
              "prompt": "make it anime",
              "output_format": "png",
              "safety_tolerance": 2
            },
            "output": "https://replicate.delivery/xezq/7e5CfHf76AXHSpMHn7r8SNN65Fw0Nu4Gxrsp9a5HryPsww4pA/tmpia3hkkv5.png",
            "prompt": "make it anime"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "frame": "First or last frame to restyle",
          "video": "Video to extract the first frame from and restyle",
          "prompt": "Text description of how to restyle the video frame",
          "output_format": "Output format for the generated image",
          "safety_tolerance": "Safety tolerance, 0 is most strict and 2 is most permissive. 2 is currently the maximum allowed."
        }
      }
    },
    {
      "id": "recraft-ai/recraft-20b-svg",
      "name": "recraft-20b-svg",
      "displayName": "recraft-20b-svg",
      "provider": "replicate",
      "category": "image",
      "endpoint": "recraft-ai/recraft-20b-svg",
      "version": "7117a9c982052bc25c5e869896b20d8108c847fef4c3be7c6b129e68a7382106",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Affordable and fast vector images",
        "runCount": 38479,
        "confidence": 0.6,
        "qualityScore": 45.85235063365776,
        "createdAt": "2025-03-24T10:31:48.003490Z",
        "owner": "recraft-ai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/4993bd89-af70-43da-be68-18cc43437746/recraft-svg-20b-cover.webp",
        "githubUrl": null,
        "paperUrl": "https://recraft.ai/",
        "licenseUrl": "https://www.recraft.ai/terms",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "size": "1024x1024",
              "style": "vector_illustration",
              "prompt": "hand holding a phone, foliage in the back"
            },
            "output": "https://replicate.delivery/czjl/9mY1k762sf06dCknY29FRe5A3wRDWxclAxNni0vyfq1t810nA/tmpxizhs_z1.svg",
            "prompt": "hand holding a phone, foliage in the back"
          }
        ],
        "parameterDescriptions": {
          "size": "Width and height of the generated image. Size is ignored if an aspect ratio is set.",
          "style": "Style of the generated image.",
          "prompt": "Text prompt for image generation",
          "aspect_ratio": "Aspect ratio of the generated image"
        }
      }
    },
    {
      "id": "bria/genfill",
      "name": "genfill",
      "displayName": "genfill",
      "provider": "replicate",
      "category": "image",
      "endpoint": "bria/genfill",
      "version": "096f6f8e43c2955967bfe6ebaf0103bf118bcfdbe5b8896f9ad61accbaebbab9",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Bria GenFill enables high-quality object addition or visual transformation. Trained exclusively on licensed data for safe and risk-free commercial use.",
        "runCount": 336,
        "confidence": 0.6,
        "qualityScore": 45.27629900871339,
        "createdAt": "2025-07-07T20:40:05.663612Z",
        "owner": "bria",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/e6438c09-e036-4481-95df-7e1e1d4763d4/GenFill_Example_29.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://learn.bria.ai/hubfs/Terms%20and%20Conditions/Bria%20AI%20Online%20Terms%20and%20Conditions%20(March%202024)%20v1.1c.pdf?hsLang=en&_gl=1*iwvu7w*_gcl_au*MzQyMzUxMzAxLjE3NDcwNDU4NTg.*_ga*MjAxNDky",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "mask": "https://replicate.delivery/pbxt/NI99NYCAZUah6qgK3UfpehW0DxudQ3nXClbWfUX02Z61OhFp/GenFill%20Example%2029%20Mask.png",
              "sync": true,
              "image": "https://replicate.delivery/pbxt/NI99NF9x2kQ21435PBIXCcL8E5LFz3e4CisxgysdzKSVimJJ/GenFill%20Example%2029.png",
              "prompt": "add a cherry on the cupcake",
              "mask_type": "manual",
              "num_results": 1,
              "preserve_alpha": true,
              "content_moderation": false
            },
            "output": [
              "https://replicate.delivery/xezq/i3MuyCCQD2pyORJYZeGXvHfSMtE9IqX34f1h7AYQ7VlJI55pA/tmpxb0_5v1m.png"
            ],
            "prompt": "add a cherry on the cupcake"
          }
        ],
        "parameterDescriptions": {
          "mask": "Mask file",
          "seed": "Random seed. Set for reproducible generation",
          "sync": "Synchronous response mode",
          "image": "Image file",
          "prompt": "Text prompt for image generation",
          "mask_type": "Type of mask: manual or automatic",
          "preserve_alpha": "Preserve alpha channel in output",
          "negative_prompt": "Negative prompt for image generation",
          "content_moderation": "Enable content moderation"
        }
      }
    },
    {
      "id": "zsxkib/step-video-t2v",
      "name": "step-video-t2v",
      "displayName": "step-video-t2v",
      "provider": "replicate",
      "category": "video",
      "endpoint": "zsxkib/step-video-t2v",
      "version": "4bc2f604bdc8e0febeeb8a75b813aab3ba4cbdbc1dc0afc1d0f0d62cb4839351",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate high-quality videos from text prompts using StepVideo",
        "runCount": 328,
        "confidence": 0.9,
        "qualityScore": 45.17195897949975,
        "createdAt": "2025-02-25T14:51:51.301318Z",
        "owner": "zsxkib",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/77228630-6969-4e02-9f0d-d4ef9908fd11/output.webp",
        "githubUrl": "https://github.com/zsxkib/cog-step-video-t2v",
        "paperUrl": "https://arxiv.org/abs/2502.10248",
        "licenseUrl": "https://github.com/stepfun-ai/Step-Video-T2V/blob/main/LICENSE",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "fps": 25,
              "prompt": "An astronaut discovers a stone monument on the moon with the word 'stepfun' inscribed on it, glowing brightly",
              "quality": 5,
              "cfg_scale": 9,
              "num_frames": 51,
              "negative_prompt": "dark image, low resolution, bad hands, text, missing fingers, extra fingers, cropped, low quality, grainy, signature, watermark, username, blurry",
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/xezq/nrHNXu7Otf37DaNAI0QiTe8UqqUnKCvgW6FPHJ7D6Xyim5SUA/video.mp4",
            "prompt": "An astronaut discovers a stone monument on the moon with the word 'stepfun' inscribed on it, glowing brightly"
          }
        ],
        "parameterDescriptions": {
          "fps": "Frames per second in output video",
          "seed": "Random seed. Leave blank for random",
          "prompt": "Prompt text",
          "quality": "Video quality (0-10, 10 is highest quality)",
          "cfg_scale": "Classifier free guidance scale",
          "num_frames": "Number of frames",
          "negative_prompt": "Negative prompt",
          "num_inference_steps": "Number of inference steps"
        }
      }
    },
    {
      "id": "fofr/wan2.1-with-lora",
      "name": "wan2.1-with-lora",
      "displayName": "wan2.1-with-lora",
      "provider": "replicate",
      "category": "image",
      "endpoint": "fofr/wan2.1-with-lora",
      "version": "c48fa8ec65b13143cb552ab98ea17984eab9d70e9fe99479117de40a2a7f9ed0",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Run Wan2.1 14b or 1.3b with a lora",
        "runCount": 30254,
        "confidence": 0.6,
        "qualityScore": 44.80797157268447,
        "createdAt": "2025-03-17T14:20:30.861742Z",
        "owner": "fofr",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/6069c99f-38c7-433a-8a38-d6bd906e6773/wan-lora-cover.webp",
        "githubUrl": "https://github.com/replicate/cog-comfyui-wan-with-lora",
        "paperUrl": null,
        "licenseUrl": "https://github.com/replicate/cog-comfyui-wan-with-lora/blob/main/LICENSE",
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "model": "14b",
              "frames": 81,
              "prompt": "flat color 2d animation of a portrait of woman with white hair and green eyes, dynamic scene",
              "lora_url": "https://huggingface.co/motimalu/wan-flat-color-v2/resolve/main/wan_flat_color_v2.safetensors",
              "aspect_ratio": "16:9",
              "sample_shift": 8,
              "sample_steps": 30,
              "lora_strength_clip": 1,
              "sample_guide_scale": 5,
              "lora_strength_model": 1
            },
            "output": [
              "https://replicate.delivery/xezq/EVxdGGJo5m6hDxI2Saz3pOeLwUOEegyijKf2ToWHaBQX1VuoA/R8_Wan_00001.mp4"
            ],
            "prompt": "flat color 2d animation of a portrait of woman with white hair and green eyes, dynamic scene"
          }
        ],
        "parameterDescriptions": {
          "seed": "Set a seed for reproducibility. Random by default.",
          "image": "Image to use as a starting frame for image to video generation.",
          "model": "The model to use. 1.3b is faster, but 14b is better quality. A LORA either works with 1.3b or 14b, depending on the version it was trained on.",
          "frames": "The number of frames to generate (1 to 5 seconds)",
          "prompt": "Text prompt for video generation",
          "lora_url": "Optional: The URL of a LORA to use",
          "fast_mode": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.",
          "resolution": "The resolution of the video. 720p is not supported for 1.3b.",
          "aspect_ratio": "The aspect ratio of the video. 16:9, 9:16, 1:1, etc.",
          "sample_shift": "Sample shift factor",
          "sample_steps": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts",
          "negative_prompt": "Things you do not want to see in your video",
          "lora_strength_clip": "Strength of the LORA applied to the CLIP model. 0.0 is no LORA.",
          "sample_guide_scale": "Higher guide scale makes prompt adherence better, but can reduce variation",
          "lora_strength_model": "Strength of the LORA applied to the model. 0.0 is no LORA."
        }
      }
    },
    {
      "id": "wizardofwoz/laysv2.5",
      "name": "laysv2.5",
      "displayName": "laysv2.5",
      "provider": "replicate",
      "category": "image",
      "endpoint": "wizardofwoz/laysv2.5",
      "version": "bf4c05dc3f2028d23fc0b472c194d975744385f8385c61164e8958a6a98b59fc",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "laysv2 outputs with Rococo paintings. Goal is to do like a sci fi flesh gothic.",
        "runCount": 275,
        "confidence": 0.6,
        "qualityScore": 44.40909082065218,
        "createdAt": "2025-04-28T02:10:39.093497Z",
        "owner": "wizardofwoz",
        "coverImage": "https://replicate.delivery/xezq/xy51sfGnoD3re0ss4VUpeTUNf7sQkS1XsZM8CM05XJ5fmTOlC/out-3.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "in the international style of TOK, \n\nIn the international style of TOK, a deep blue background. A large oval takes up most of the scene. Cropped within. Inside, a rococo dinner scene closeup. Front and center is a highly detailed artistic, oval shaped representation of Earth as a celestial artifact. The main body is a luminous cobalt blue sphere with intricate textural ripples resembling oceanic currents carved across its entire surface., radiating outward like a pumpkin. Scattered across this azure expanse are irregular patches of gleaming gold leaf representing abstract continental forms - larger masses suggesting Eurasia and Africa in the northern hemisphere, the Americas along one side, and smaller golden fragments depicting Australia and Pacific archipelagos. The delicate swirling patterns etched into the surface suggest global wind patterns and major ocean currents circumnavigating the planet. The sphere rests upon a clear crystal base. \n\nThe monochromatic dark blue-tinted lighting on technological elements contrasting with warm chiaroscuro on organic gemstones, translucent enamel containing starry cosmic particles, metallic gold filigree and adornments resembling microchips against deep black background. Atmospheric cinematic lighting with warm deep amber undertones, film grain overlay, shallow depth of field, inspired by biomechanical religious horror and transhumanist ceremonial procedures, reminiscent of Cronenberg and H.R. Giger aesthetics, photorealistic, 8K resolution, shot on Arri Alexa with vintage anamorphic lenses photorealistic rendering with sci-fi mechanical details, melancholic yet reverent mood, ancient wooden altar surface displaying both natural grain and embedded circuitry --ar 4:5 --v 6 --s 1000 --q 2 --style raw Ed",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 4,
              "aspect_ratio": "4:5",
              "output_format": "webp",
              "guidance_scale": 0,
              "output_quality": 100,
              "prompt_strength": 0.72,
              "extra_lora_scale": 1,
              "num_inference_steps": 47
            },
            "output": [
              "https://replicate.delivery/xezq/MpGu5ZsejAzWIa7tfwVfgEPSfSJbYCbJo7Kd8B0Zzfo6mTOlC/out-0.webp",
              "https://replicate.delivery/xezq/xeEJWevzhivMs0pSIstLYwGjCJRf8RZSkfIf5ZNzY76eNncKF/out-1.webp",
              "https://replicate.delivery/xezq/Fsf3XQJ4LMTcXqDAG2UekpUSYyAGqHi1nK1ZVvkDzMy3cypUA/out-2.webp",
              "https://replicate.delivery/xezq/xy51sfGnoD3re0ss4VUpeTUNf7sQkS1XsZM8CM05XJ5fmTOlC/out-3.webp"
            ],
            "prompt": "in the international style of TOK, \n\nIn the international style of TOK, a deep blue background. A large oval takes up most of the scene. Cropped within. Inside, a rococo dinner scene closeup. Front and center is a highly detailed artistic, oval shaped representation of Earth as a celestial artifact. The main body is a luminous cobalt blue sphere with intricate textural ripples resembling oceanic currents carved across its entire surface., radiating outward like a pumpkin. Scattered across this azure expanse are irregular patches of gleaming gold leaf representing abstract continental forms - larger masses suggesting Eurasia and Africa in the northern hemisphere, the Americas along one side, and smaller golden fragments depicting Australia and Pacific archipelagos. The delicate swirling patterns etched into the surface suggest global wind patterns and major ocean currents circumnavigating the planet. The sphere rests upon a clear crystal base. \n\nThe monochromatic dark blue-tinted lighting on technological elements contrasting with warm chiaroscuro on organic gemstones, translucent enamel containing starry cosmic particles, metallic gold filigree and adornments resembling microchips against deep black background. Atmospheric cinematic lighting with warm deep amber undertones, film grain overlay, shallow depth of field, inspired by biomechanical religious horror and transhumanist ceremonial procedures, reminiscent of Cronenberg and H.R. Giger aesthetics, photorealistic, 8K resolution, shot on Arri Alexa with vintage anamorphic lenses photorealistic rendering with sci-fi mechanical details, melancholic yet reverent mood, ancient wooden altar surface displaying both natural grain and embedded circuitry --ar 4:5 --v 6 --s 1000 --q 2 --style raw Ed"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "andreasjansson/wan-1.3b-inpaint",
      "name": "wan-1.3b-inpaint",
      "displayName": "wan-1.3b-inpaint",
      "provider": "replicate",
      "category": "video",
      "endpoint": "andreasjansson/wan-1.3b-inpaint",
      "version": "7abfdb3370aba087f9a5eb8b733c2174bc873a957e5c2c4835767247287dbf89",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Inpainting and video2video experiments with Wan 2.1",
        "runCount": 261,
        "confidence": 0.9,
        "qualityScore": 44.18301291319745,
        "createdAt": "2025-03-10T23:28:26.131392Z",
        "owner": "andreasjansson",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/d635b2b1-839f-4af7-a206-7b2af8cc5878/video.webp",
        "githubUrl": "https://github.com/andreasjansson/Wan2.1",
        "paperUrl": null,
        "licenseUrl": "https://github.com/andreasjansson/Wan2.1/blob/main/LICENSE.txt",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "prompt": "A robot walking on the street",
              "strength": 0.9,
              "mask_video": "https://replicate.delivery/xezq/N94eQyo3WBVWXyN8Aj4kpwQ42l6prb578m9tCJWaFgREnlJKA/masked_video.mp4",
              "expand_mask": 10,
              "guide_scale": 5,
              "input_video": "https://replicate.delivery/xezq/UpqkYwl7hTqTJ5rfIE0eb5WpDv6quG6PeFcdtH157Y2uonloA/tmp2dc62s6m.output.mp4",
              "sampling_steps": 30,
              "negative_prompt": "",
              "frames_per_second": 16,
              "inpaint_fixup_steps": 0
            },
            "output": "https://replicate.delivery/xezq/KII1QARYVCaDH1ElIipMcUEa1sXNjHC43XPtqg8le1UcKdKKA/output.mp4",
            "prompt": "A robot walking on the street"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Leave blank for random",
          "prompt": "Prompt for inpainting the masked area",
          "strength": "Strength of inpainting effect, 1.0 is full regeneration",
          "mask_video": "Mask video (white areas will be inpainted). Leave blank for video-to-video",
          "expand_mask": "Expand the mask by a number of pixels",
          "guide_scale": "Guidance scale for prompt adherence",
          "input_video": "Original video to be inpainted",
          "sampling_steps": "Number of sampling steps",
          "negative_prompt": "Negative prompt",
          "frames_per_second": "Output video FPS",
          "keep_aspect_ratio": "Keep the aspect ratio of the input video. This will degrade the quality of the inpainting.",
          "inpaint_fixup_steps": "Number of steps for final inpaint fixup. Ignored when in video-to-video mode (when mask_video is empty)"
        }
      }
    },
    {
      "id": "zhangp365/flux-redux-dev-lora",
      "name": "flux-redux-dev-lora",
      "displayName": "flux-redux-dev-lora",
      "provider": "replicate",
      "category": "image",
      "endpoint": "zhangp365/flux-redux-dev-lora",
      "version": "0fb2657da17422619c72349f1f7f90d834f9ae27a6a30ff53671d041605f28e8",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "update the official flux-redux-dev to support lora.",
        "runCount": 248,
        "confidence": 0.6,
        "qualityScore": 43.96199347095737,
        "createdAt": "2025-04-14T09:54:24.157030Z",
        "owner": "zhangp365",
        "coverImage": "https://replicate.delivery/yhqm/9RhgqdDqD97PHNI1bRDVJC5Pu4kGELAWV7ffpAr8iNYOkViUA/out-0.png",
        "githubUrl": "https://github.com/zhangp365/cog-flux",
        "paperUrl": null,
        "licenseUrl": "https://github.com/zhangp365/cog-flux/blob/main/LICENSE",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "art nouveau",
              "guidance": 3,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "redux_image": "https://replicate.delivery/pbxt/MpUZxGp2ETAVs8PcIx1HuycjpMUFTwLD23mCnGVta8Fite1x/00044-3696149592.png",
              "aspect_ratio": "3:4",
              "lora_weights": "civitai.com/models/782219/lora-flux-art-nouveau",
              "output_format": "png",
              "output_quality": 80,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/yhqm/9RhgqdDqD97PHNI1bRDVJC5Pu4kGELAWV7ffpAr8iNYOkViUA/out-0.png"
            ],
            "prompt": "art nouveau"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "prompt": "Prompt for generated image",
          "guidance": "Guidance for generated image",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "redux_image": "Input image to condition your output on. This replaces prompt for FLUX.1 Redux models",
          "aspect_ratio": "Aspect ratio for the generated image",
          "lora_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "output_format": "Format of the output images",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "num_inference_steps": "Number of denoising steps. Recommended range is 28-50",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "prunaai/sdxl-lightning",
      "name": "sdxl-lightning",
      "displayName": "sdxl-lightning",
      "provider": "replicate",
      "category": "image",
      "endpoint": "prunaai/sdxl-lightning",
      "version": "123d4264aec4d1c81d8bf142e0d90d6fd4c346f1a869406019f6d1653882d7c3",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This is the fastest sdxl-lightning endpoint in the world on A100, contact us for more at pruna.ai",
        "runCount": 237,
        "confidence": 0.6,
        "qualityScore": 43.76576957056512,
        "createdAt": "2025-06-10T19:36:45.998373Z",
        "owner": "prunaai",
        "coverImage": "https://replicate.delivery/yhqm/i8Up1UyeK50JdCsReIXlHSOz8WQlyeKlvuSqQeUEXOhgUPWTB/output_42_0.jpeg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": 42,
              "prompt": "self-portrait of a woman, lightning in the background",
              "num_images": 1,
              "image_width": 1024,
              "image_height": 1024,
              "output_format": "jpg",
              "guidance_scale": 0,
              "output_quality": 80,
              "num_inference_steps": 4
            },
            "output": "https://replicate.delivery/yhqm/i8Up1UyeK50JdCsReIXlHSOz8WQlyeKlvuSqQeUEXOhgUPWTB/output_42_0.jpeg",
            "prompt": "self-portrait of a woman, lightning in the background"
          }
        ],
        "parameterDescriptions": {
          "seed": "Seed",
          "prompt": "Prompt",
          "num_images": "Number of images to generate",
          "image_width": "Image width",
          "image_height": "Image height",
          "output_format": "Output format",
          "guidance_scale": "Guidance scale",
          "output_quality": "Output quality (for jpg and webp)",
          "num_inference_steps": "Number of inference steps"
        }
      }
    },
    {
      "id": "ostris/flex-redux",
      "name": "flex-redux",
      "displayName": "flex-redux",
      "provider": "replicate",
      "category": "image",
      "endpoint": "ostris/flex-redux",
      "version": "ed37ab87cb1dfe4cc5c42c078298765aadc7cf476468acc1c8df5c9996fefccd",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A redux adapter trained from scratch on Flex.1-alpha, that also works with FLUX.1-dev",
        "runCount": 217,
        "confidence": 0.6,
        "qualityScore": 43.38456493604605,
        "createdAt": "2025-04-02T11:15:49.576902Z",
        "owner": "ostris",
        "coverImage": "https://replicate.delivery/xezq/eJ4562v7h4XQFabqPoUKAs3usNsEbiTqwmIU5UZRXgcOfseoA/R8_Flex_Redux_00001_.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "width": 1024,
              "height": 1024,
              "prompt": "a photo of a woman",
              "guidance": 3,
              "redux_image": "https://replicate.delivery/pbxt/MlZs8vm1bTgi0g4ozCqINiulCLkb3w0gln1TargqaiTz1L4Q/0_1.webp",
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "output_quality": 95,
              "redux_strength": 1,
              "clip_vision_crop": "center",
              "redux_strength_type": "multiply"
            },
            "output": [
              "https://replicate.delivery/xezq/eJ4562v7h4XQFabqPoUKAs3usNsEbiTqwmIU5UZRXgcOfseoA/R8_Flex_Redux_00001_.webp"
            ],
            "prompt": "a photo of a woman"
          }
        ],
        "parameterDescriptions": {
          "seed": "Set a seed for reproducibility. Random by default.",
          "width": "Width of the output image. Ignored if aspect ratio is not None.",
          "height": "Height of the output image. Ignored if aspect ratio is not None.",
          "guidance": "Guidance scale for the redux image.",
          "redux_image": "Input image to condition your output on.",
          "aspect_ratio": "Aspect ratio of the output image.",
          "output_format": "Format of the output images",
          "output_quality": "Quality of the output images, from 0 to 100. 100 is best quality, 0 is lowest quality.",
          "redux_strength": "Strength of the redux image. 0 = no redux, 1 = full redux.",
          "clip_vision_crop": "Whether to crop the redux image for clip vision. Crops to a square if center, otherwise no cropping. Images can appear distorted if no cropping is used.",
          "redux_strength_type": "Type of strength for the redux image."
        }
      }
    },
    {
      "id": "lucataco/flux-jennai",
      "name": "flux-jennai",
      "displayName": "flux-jennai",
      "provider": "replicate",
      "category": "image",
      "endpoint": "lucataco/flux-jennai",
      "version": "256ddf3c5429bc028df29221cadb161393ed67f6eaf2c7de01cc2f77cf86b459",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Jennai: an AI Avatar trained via the replicate/fast-flux-trainer",
        "runCount": 184,
        "confidence": 0.6,
        "qualityScore": 42.67171728403014,
        "createdAt": "2025-05-24T04:39:40.072419Z",
        "owner": "lucataco",
        "coverImage": "https://replicate.delivery/xezq/gLKueqkp7ZXaYyekkPDYZWd0c4lc2lHcsWG4jtaPNgLYR5vUA/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "a portrait photo of JENAI wearing a red sweater",
              "go_fast": true,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/gLKueqkp7ZXaYyekkPDYZWd0c4lc2lHcsWG4jtaPNgLYR5vUA/out-0.webp"
            ],
            "prompt": "a portrait photo of JENAI wearing a red sweater"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "aliadhami/3d-sheet",
      "name": "3d-sheet",
      "displayName": "3d-sheet",
      "provider": "replicate",
      "category": "image",
      "endpoint": "aliadhami/3d-sheet",
      "version": "7edfa9773387328f8d75a447a345b0b14a47278d579b25d4f640bf57caeb0891",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generates minimal, consistent 3-view design for objects in the style of technical 3D reference sheets. Outputs include front, back, and side views with consistent proportions against a white background.",
        "runCount": 180,
        "confidence": 0.6,
        "qualityScore": 42.57678574869185,
        "createdAt": "2025-03-27T15:25:01.477935Z",
        "owner": "aliadhami",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/44f9236a-55ef-4d58-82bd-84022c64c74d/ezgif-68995ad520cdf2-ezgif.com-cu.gif",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "width": 1440,
              "height": 593,
              "prompt": "In the style of 3dsheet, three consistent views of the same realistic Jesus head-and-neck figure with crown of thorns, lifelike skin, brown hair, greenish eyes, texture, visible neck, and upper shoulders. Front view shows a solemn face with natural facial features, detailed beard, crown resting on the brow, and fabric line of a robe at the shoulders. Back view displays textured hair flowing down the neck, crown wrapping fully around the head with thorn detail, and subtle shoulder form. Side view presents the realistic facial profile, visible skin folds on the neck, sharp crown thorns, and robe edge at the upper shoulder. All three views maintain consistent proportions of this single realistic Jesus head-and-neck figure against a white background.",
              "go_fast": false,
              "lora_scale": 0.7,
              "megapixels": "1",
              "num_outputs": 4,
              "aspect_ratio": "custom",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.79,
              "extra_lora_scale": 2.63,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/2d2o1TEVDRqmFRaoZWa51TItpi063RvKHdqg8OFEt3wzFNHF/out-0.webp",
              "https://replicate.delivery/xezq/Jr83sSPILLorKpAjqHobXYxiJNN6RGMynW9MT06jTD1zFNHF/out-1.webp",
              "https://replicate.delivery/xezq/YyLEbe0zXixway6iUSUkWXiKS6HlJIJnWfqvMuXr8dNPX0cUA/out-2.webp",
              "https://replicate.delivery/xezq/XD44v0ULrDK6K9N8kYb6w0b5dvjzoVYUJCQSm7MAwtwzFNHF/out-3.webp"
            ],
            "prompt": "In the style of 3dsheet, three consistent views of the same realistic Jesus head-and-neck figure with crown of thorns, lifelike skin, brown hair, greenish eyes, texture, visible neck, and upper shoulders. Front view shows a solemn face with natural facial features, detailed beard, crown resting on the brow, and fabric line of a robe at the shoulders. Back view displays textured hair flowing down the neck, crown wrapping fully around the head with thorn detail, and subtle shoulder form. Side view presents the realistic facial profile, visible skin folds on the neck, sharp crown thorns, and robe edge at the upper shoulder. All three views maintain consistent proportions of this single realistic Jesus head-and-neck figure against a white background."
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "prunaai/stable-diffusion-cheetah",
      "name": "stable-diffusion-cheetah",
      "displayName": "stable-diffusion-cheetah",
      "provider": "replicate",
      "category": "image",
      "endpoint": "prunaai/stable-diffusion-cheetah",
      "version": "27b76b3c3b98fc7cf55b115796573022f8e9df4c1cf5e42c24a82796496614e1",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This model is an optimised version of stable-diffusion by stability AI that is 3x faster and 3x cheaper.",
        "runCount": 175,
        "confidence": 0.9,
        "qualityScore": 42.4551266781415,
        "createdAt": "2025-04-08T12:17:25.561021Z",
        "owner": "prunaai",
        "coverImage": "https://replicate.delivery/yhqm/xR5S88Khtj7YAVafK4O37eQtVjNZgX4HG9ikgm8Zb8FTccdUA/output.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "prompt": "a red apple on a table",
              "go_fast_af": false,
              "num_images": 1,
              "image_width": 512,
              "image_height": 512,
              "guidance_scale": 7.5,
              "num_inference_steps": 50
            },
            "output": "https://replicate.delivery/yhqm/xR5S88Khtj7YAVafK4O37eQtVjNZgX4HG9ikgm8Zb8FTccdUA/output.png",
            "prompt": "a red apple on a table"
          }
        ],
        "parameterDescriptions": {
          "seed": "Seed",
          "prompt": "Prompt",
          "go_fast_af": "Enable maximum speed optimization",
          "num_images": "Number of images to generate",
          "image_width": "Image width",
          "image_height": "Image height",
          "guidance_scale": "Guidance scale",
          "num_inference_steps": "Number of inference steps"
        }
      }
    },
    {
      "id": "marcinkleczek/gwarek-01",
      "name": "gwarek-01",
      "displayName": "gwarek-01",
      "provider": "replicate",
      "category": "image",
      "endpoint": "marcinkleczek/gwarek-01",
      "version": "000a912c58c08cbfb096f0e0369be5c585a87e470c0fd3e2b81671ce6a6fcc48",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Model generuje obrazki podobne do Gwarków olkuskich. Wytrenowany na bardzo małym zbiorze danych.",
        "runCount": 159,
        "confidence": 0.6,
        "qualityScore": 42.04119982655925,
        "createdAt": "2025-06-25T14:30:18.766352Z",
        "owner": "marcinkleczek",
        "coverImage": "https://replicate.delivery/xezq/E6zgzZumgo5vFt8PB5fVr2NFFLKZeDMlLwufDEJq6tNseupTB/out-0.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "GWAREK OLKUSKI A statue of a tall man with volleyball ball on hand. The statue is green and made of metal. Wearing t-shirt with number 7 and shorts. The man is standing next to a stone wall.",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "png",
              "guidance_scale": 3,
              "output_quality": 100,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/E6zgzZumgo5vFt8PB5fVr2NFFLKZeDMlLwufDEJq6tNseupTB/out-0.png"
            ],
            "prompt": "GWAREK OLKUSKI A statue of a tall man with volleyball ball on hand. The statue is green and made of metal. Wearing t-shirt with number 7 and shorts. The man is standing next to a stone wall."
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "lucataco/ltx-video-0.9.8-distilled",
      "name": "ltx-video-0.9.8-distilled",
      "displayName": "ltx-video-0.9.8-distilled",
      "provider": "replicate",
      "category": "video",
      "endpoint": "lucataco/ltx-video-0.9.8-distilled",
      "version": "6757cbcee0253dca9e6c4df0e026c009b58673bbaaf1d88d3f4058cfc692fba5",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image",
        "videoUrl": "video"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate native long-form video, with controllability",
        "runCount": 157,
        "confidence": 0.9,
        "qualityScore": 41.986570869544224,
        "createdAt": "2025-07-24T20:23:10.955398Z",
        "owner": "lucataco",
        "coverImage": "https://replicate.delivery/xezq/FgDbmC5P47LuDxfznS7OgpzGDSXELYy7twkeSFhjEBryiEEVA/output.mp4",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "fps": 24,
              "prompt": "The turquoise waves crash against the dark, jagged rocks of the shore, sending white foam spraying into the air. The scene is dominated by the stark contrast between the bright blue water and the dark, almost black rocks. The water is a clear, turquoise color, and the waves are capped with white foam. The rocks are dark and jagged, and they are covered in patches of green moss. The shore is lined with lush green vegetation, including trees and bushes. In the background, there are rolling hills covered in dense forest. The sky is cloudy, and the light is dim",
              "go_fast": true,
              "num_frames": 121,
              "resolution": 480,
              "aspect_ratio": "match_input_image",
              "guidance_scale": 3,
              "negative_prompt": "worst quality, inconsistent motion, blurry, jittery, distorted",
              "denoise_strength": 0.4,
              "downscale_factor": 0.667,
              "conditioning_frames": 21,
              "num_inference_steps": 24,
              "max_duration_seconds": 5,
              "final_inference_steps": 10
            },
            "output": "https://replicate.delivery/xezq/FgDbmC5P47LuDxfznS7OgpzGDSXELYy7twkeSFhjEBryiEEVA/output.mp4",
            "prompt": "The turquoise waves crash against the dark, jagged rocks of the shore, sending white foam spraying into the air. The scene is dominated by the stark contrast between the bright blue water and the dark, almost black rocks. The water is a clear, turquoise color, and the waves are capped with white foam. The rocks are dark and jagged, and they are covered in patches of green moss. The shore is lined with lush green vegetation, including trees and bushes. In the background, there are rolling hills covered in dense forest. The sky is cloudy, and the light is dim"
          }
        ],
        "parameterDescriptions": {
          "fps": "Frames per second for the output video.",
          "seed": "Random seed for reproducible results. Leave blank for a random seed.",
          "image": "Input image for image-to-video generation. If provided, will generate video from this image.",
          "video": "Input video for video-to-video generation. If provided, will generate video from this video. Takes precedence over image if both are provided.",
          "prompt": "Text prompt for video generation",
          "go_fast": "Enable fast mode with skip layer strategies (20-40% faster but slightly lower quality).",
          "num_frames": "Number of frames per segment. Use 257 for ~10.7s segments at 24fps (recommended for long videos).",
          "resolution": "Resolution for the output video (height in pixels).",
          "aspect_ratio": "Aspect ratio for the output video.",
          "guidance_scale": "Guidance scale. Recommended range: 3.0-3.5.",
          "negative_prompt": "Negative prompt for video generation.",
          "denoise_strength": "Denoising strength for final refinement step.",
          "downscale_factor": "Factor to downscale initial generation (recommended: 2/3 for better quality).",
          "conditioning_frames": "Number of frames to use for video-to-video conditioning (only used when video input is provided).",
          "num_inference_steps": "Number of denoising steps for initial generation.",
          "max_duration_seconds": "Target video duration in seconds. Videos longer than 10s use autoregressive generation.",
          "final_inference_steps": "Number of inference steps for final denoising."
        }
      }
    },
    {
      "id": "rongwroom/dandan-actor",
      "name": "dandan-actor",
      "displayName": "dandan-actor",
      "provider": "replicate",
      "category": "image",
      "endpoint": "rongwroom/dandan-actor",
      "version": "11162aefee0b704c352db825e03883e73c6ee053edc8f85af81d7da62d4aa27b",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "An actors headshot creator based on the style of professional photographer Daniel Spencer",
        "runCount": 152,
        "confidence": 0.6,
        "qualityScore": 41.84691430817599,
        "createdAt": "2025-04-30T14:52:43.255579Z",
        "owner": "rongwroom",
        "coverImage": "https://replicate.delivery/xezq/Zyz6egG2H8RoPq6tHlMOmgpLZIcFiExwtot45b4gAjCCeBoUA/out-0.jpg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "width": 540,
              "height": 720,
              "prompt": "A professional headshot portrait of an actor in dandan style. The subject is centered with a dead pan expression, wearing a simple outfit, body angled 45 degrees away from camera, The background is softly blurred with muted tones (brown, gray, green, or blue), creating a cinematic and sophisticated atmosphere, The lighting is soft and directional, highlighting the subject's facial features, detailed hair, relaxed portrait photography capturing photorealistic skin textures, sharp eyes, natural hair color, and subtle shadows, The overall mood is serious and contemplative, emphasizing the subject's presence and character, High-quality photography, cinematic lighting, shallow depth of field, Canon R6, Canon 70-200mm F2.8",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "custom",
              "output_format": "jpg",
              "guidance_scale": 1.5,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 30
            },
            "output": [
              "https://replicate.delivery/xezq/Zyz6egG2H8RoPq6tHlMOmgpLZIcFiExwtot45b4gAjCCeBoUA/out-0.jpg"
            ],
            "prompt": "A professional headshot portrait of an actor in dandan style. The subject is centered with a dead pan expression, wearing a simple outfit, body angled 45 degrees away from camera, The background is softly blurred with muted tones (brown, gray, green, or blue), creating a cinematic and sophisticated atmosphere, The lighting is soft and directional, highlighting the subject's facial features, detailed hair, relaxed portrait photography capturing photorealistic skin textures, sharp eyes, natural hair color, and subtle shadows, The overall mood is serious and contemplative, emphasizing the subject's presence and character, High-quality photography, cinematic lighting, shallow depth of field, Canon R6, Canon 70-200mm F2.8"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "piyushgupta53/waw-pfp-flux-v2",
      "name": "waw-pfp-flux-v2",
      "displayName": "waw-pfp-flux-v2",
      "provider": "replicate",
      "category": "image",
      "endpoint": "piyushgupta53/waw-pfp-flux-v2",
      "version": "9f28666babb857631bc4a08a0ec7415d643cd5b35d714c6f9e55b0e34f7b2e3d",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A text-to-image model to generate real images of american women that look like they're shot on an iPhone",
        "runCount": 142,
        "confidence": 0.6,
        "qualityScore": 41.55336037465062,
        "createdAt": "2025-04-25T18:37:31.607418Z",
        "owner": "piyushgupta53",
        "coverImage": "https://replicate.delivery/xezq/uNSVvfEvmcxfrkeh1BBL28l1t1iYYOtK8e2X5qYp67n8aBhSB/out-0.jpg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "WAW_PFP A woman is standing in front of a large flying fabric in soft white with shadows of the leaves creating a dynamic, abstract backdrop. She wears a stylish sleeveless dress with a modern cut inspired by the brand Free People. The dress showcases a variation with a deeper V neckline and slightly fuller boobs, adding to her sensual allure. Her hair flows gently with a calm, neutral expression. The setting is an earthy field with muted tones and soft, diffused lighting contributing to an avant-garde atmosphere. The composition is centered and symmetric, focusing on the contrast between the model and the fluid background, evoking a sense of modern elegance, sensuality, and artistic expression.",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "jpg",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/uNSVvfEvmcxfrkeh1BBL28l1t1iYYOtK8e2X5qYp67n8aBhSB/out-0.jpg"
            ],
            "prompt": "WAW_PFP A woman is standing in front of a large flying fabric in soft white with shadows of the leaves creating a dynamic, abstract backdrop. She wears a stylish sleeveless dress with a modern cut inspired by the brand Free People. The dress showcases a variation with a deeper V neckline and slightly fuller boobs, adding to her sensual allure. Her hair flows gently with a calm, neutral expression. The setting is an earthy field with muted tones and soft, diffused lighting contributing to an avant-garde atmosphere. The composition is centered and symmetric, focusing on the contrast between the model and the fluid background, evoking a sense of modern elegance, sensuality, and artistic expression."
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "fishwowater/flux-dev-controlnet-inpainting-beta",
      "name": "flux-dev-controlnet-inpainting-beta",
      "displayName": "flux-dev-controlnet-inpainting-beta",
      "provider": "replicate",
      "category": "image",
      "endpoint": "fishwowater/flux-dev-controlnet-inpainting-beta",
      "version": "27d3ff35f58b4409775de5a0b36e99b4c6d2d7fc7fe772b35170951db678ec63",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Image Inpainting with Flux.1-dev + ControlNet, by Alimama Team, **BETA** version",
        "runCount": 134,
        "confidence": 0.6,
        "qualityScore": 41.303337684950066,
        "createdAt": "2025-04-22T03:38:39.453411Z",
        "owner": "fishwowater",
        "coverImage": "https://replicate.delivery/yhqm/3WhkfI7t6eoCQ0fi7qNtznimZcRfVnPajAgzCfV0kBtJchpkC/output_0.webp",
        "githubUrl": "https://github.com/alimama-creative/FLUX-Controlnet-Inpainting",
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "mask": "https://replicate.delivery/pbxt/Le6GAg8i6DrhZxvjibNmzKy4jPYEKIhH8DBZnUp2WAioguXI/bucket_mask.jpeg",
              "image": "https://replicate.delivery/pbxt/Le6GAdIHbCc7u5RAFQ09dqJoROHEayxjWQbg9Hx16aY2fa9L/bucket.png",
              "prompt": "a person wearing a white shoe, carrying a white bucket with text 'REPLICATE FLUX INPAINTING CONTROLNET' on it",
              "num_outputs": 1,
              "output_format": "webp",
              "guidance_scale": 3.5,
              "output_quality": 80,
              "negative_prompt": "",
              "num_inference_steps": 28,
              "true_guidance_scale": 3.5,
              "controlnet_conditioning_scale": 0.9
            },
            "output": [
              "https://replicate.delivery/yhqm/3WhkfI7t6eoCQ0fi7qNtznimZcRfVnPajAgzCfV0kBtJchpkC/output_0.webp"
            ],
            "prompt": "a person wearing a white shoe, carrying a white bucket with text 'REPLICATE FLUX INPAINTING CONTROLNET' on it"
          }
        ],
        "parameterDescriptions": {
          "mask": "Upload a mask image for inpainting. White areas (255) indicate regions to be inpainted, while black areas (0) will be preserved from the original image.",
          "seed": "Set a seed for reproducible generation. Leave as None for random results.",
          "image": "Upload an image for inpainting. This will be the base image that will be partially modified.",
          "prompt": "Enter a text description to guide the image generation process.",
          "num_outputs": "Number of images to generate.",
          "output_format": "Choose the file format for the output images.",
          "guidance_scale": "Guidance scale for classifier-free guidance. Higher values encourage the model to generate images that are closer to the text prompt.",
          "output_quality": "Quality of the output images (applicable for 'jpg' and 'webp'). Value between 1 (lowest quality) and 100 (highest quality). Ignored for 'png'.",
          "negative_prompt": "Negative text prompt. Used to reduce or avoid certain aspects in the generated image.",
          "num_inference_steps": "Set the number of denoising steps. More steps generally result in higher quality but slower generation.",
          "true_guidance_scale": "True guidance scale for the transformer model.",
          "controlnet_conditioning_scale": "ControlNet conditioning scale."
        }
      }
    },
    {
      "id": "prunaai/f-lite-juiced",
      "name": "f-lite-juiced",
      "displayName": "f-lite-juiced",
      "provider": "replicate",
      "category": "image",
      "endpoint": "prunaai/f-lite-juiced",
      "version": "b5bb58776e3e5adbc83d721489c1770fca8449dbcdbb488d390e6cae577db048",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This is the f-lite model from FAL & Freepik optimised for 2x speedups through pruna",
        "runCount": 133,
        "confidence": 0.9,
        "qualityScore": 41.271047983648074,
        "createdAt": "2025-04-30T09:18:39.599033Z",
        "owner": "prunaai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/d3273804-26fd-4a92-bb7d-4ca65b5c615c/ca8d296807d89844764f70b38e1ba5447.png",
        "githubUrl": "https://github.com/fal-ai/f-lite",
        "paperUrl": "https://github.com/fal-ai/f-lite/blob/main/assets/F%20Lite%20Technical%20Report.pdf",
        "licenseUrl": "https://github.com/fal-ai/f-lite?tab=License-1-ov-file",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "prompt": "A cake with 'pruna' written on it",
              "guidance": 3,
              "image_size": 1024,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "output_quality": 80,
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/yhqm/M4OZ1vyvSf2wESeImhGxq8qBv3zWprkG1E0aeCJqa11UvzPpA/output_-1_0.webp",
            "prompt": "A cake with 'pruna' written on it"
          }
        ],
        "parameterDescriptions": {
          "seed": "Seed",
          "prompt": "Prompt",
          "guidance": "Guidance scale",
          "image_size": "Base image size (longest side)",
          "aspect_ratio": "Aspect ratio of the output image",
          "output_format": "Output format",
          "output_quality": "Output quality (for jpg and webp)",
          "num_inference_steps": "Number of inference steps"
        }
      }
    },
    {
      "id": "openai/o1-mini",
      "name": "o1-mini",
      "displayName": "o1-mini",
      "provider": "replicate",
      "category": "image",
      "endpoint": "openai/o1-mini",
      "version": "61e840bbda7e4a45a544f6e99e3bf5e7ca2ae2d64f69f6c85b0d3c64ba6f1eeb",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A small model alternative to o1",
        "runCount": 399,
        "confidence": 0.6,
        "qualityScore": 41.020599913279625,
        "createdAt": "2025-05-20T10:30:02.961501Z",
        "owner": "openai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/05176bef-ce51-4955-84a5-d5d419992ec9/Screenshot_2025-05-18_at_10.19.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://openai.com/policies/",
        "pricing": {
          "tier": "premium"
        },
        "examples": [
          {
            "input": {
              "prompt": "A train leaves City A for City B at 60 miles per hour. Another train leaves City B for City A at 90 miles per hour on the same track. The cities are 300 miles apart. If both trains leave at the same time, how far from City A will they meet? Be succint, show your steps, but don't use LaTeX in your answer.",
              "max_completion_tokens": 4096
            },
            "output": "They meet after the following steps:\n\n1. Let t be the time in hours when they meet.\n2. Distance covered by Train A: 60 mph × t = 60t miles.\n3. Distance covered by Train B: 90 mph × t = 90t miles.\n4. Total distance: 60t + 90t = 150t = 300 miles.\n5. Solve for t: t = 300 / 150 = 2 hours.\n6. Distance from City A: 60 × 2 = 120 miles.\n\n**Answer:** They meet 120 miles from City A.",
            "prompt": "A train leaves City A for City B at 60 miles per hour. Another train leaves City B for City A at 90 miles per hour on the same track. The cities are 300 miles apart. If both trains leave at the same time, how far from City A will they meet? Be succint, show your steps, but don't use LaTeX in your answer."
          }
        ],
        "parameterDescriptions": {
          "prompt": "The prompt to send to the model. Do not use if using messages.",
          "max_completion_tokens": "Maximum number of completion tokens to generate"
        }
      }
    },
    {
      "id": "aliadhami/christ-painting",
      "name": "christ-painting",
      "displayName": "christ-painting",
      "provider": "replicate",
      "category": "image",
      "endpoint": "aliadhami/christ-painting",
      "version": "40f86c66cbd493a44e66c5a4f28841b81adcc3b0906c1cd8c9a2ef3f509c0433",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generates fine-tuned paintings inspired by biblical scenes, Christian iconography, and traditional church art styles.",
        "runCount": 125,
        "confidence": 0.6,
        "qualityScore": 41.003705451175634,
        "createdAt": "2025-03-29T08:59:50.650821Z",
        "owner": "aliadhami",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/8bd7e9eb-f49c-4e47-b233-24af3fcb86a0/cover.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "width": 1024,
              "height": 512,
              "prompt": "In the style of christ-painting, A portrait of Jesus Christ with shoulder-length brown hair parted in the middle, tan skin, green eyes, and a gentle but powerful expression. The portrait is bathed in soft, warm light giving it a transcendent quality.",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "custom",
              "output_format": "png",
              "guidance_scale": 3,
              "output_quality": 100,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/p8FhPbE4i9ppMVw444Xj3ynULtOTjxrxB2Epd036COHfdrOKA/out-0.png"
            ],
            "prompt": "In the style of christ-painting, A portrait of Jesus Christ with shoulder-length brown hair parted in the middle, tan skin, green eyes, and a gentle but powerful expression. The portrait is bathed in soft, warm light giving it a transcendent quality."
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "lightricks/ltx-video-0.9.7-distilled",
      "name": "ltx-video-0.9.7-distilled",
      "displayName": "ltx-video-0.9.7-distilled",
      "provider": "replicate",
      "category": "video",
      "endpoint": "lightricks/ltx-video-0.9.7-distilled",
      "version": "e7f2778ec419047c564a6620b2d9bf7d6c64673411bf2ae13e628ee2b2c0b5b1",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image",
        "videoUrl": "video"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Faster slight quality reduction compared to LTX-Video 13b",
        "runCount": 124,
        "confidence": 0.9,
        "qualityScore": 40.96910013008056,
        "createdAt": "2025-07-11T20:00:55.118599Z",
        "owner": "lightricks",
        "coverImage": "https://replicate.delivery/xezq/KEVgfOerwHoGDE4bgdoVmUvTIODSufj4le6pFCfcxL1XuTePF/output.mp4",
        "githubUrl": "https://github.com/replicate/cog-ltx-video-0.9.7-distilled",
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "fps": 24,
              "prompt": "A woman with light skin, wearing a blue jacket and a black hat with a veil, looks down and to her right, then back up as she speaks; she has brown hair styled in an updo, light brown eyebrows, and is wearing a white collared shirt under her jacket; the camera remains stationary on her face as she speaks; the background is out of focus, but shows trees and people in period clothing; the scene is captured in real-life footage.",
              "go_fast": true,
              "num_frames": 121,
              "resolution": 480,
              "aspect_ratio": "match_input_image",
              "guidance_scale": 3,
              "negative_prompt": "worst quality, inconsistent motion, blurry, jittery, distorted",
              "denoise_strength": 0.4,
              "downscale_factor": 0.667,
              "conditioning_frames": 21,
              "num_inference_steps": 24,
              "final_inference_steps": 10
            },
            "output": "https://replicate.delivery/xezq/KEVgfOerwHoGDE4bgdoVmUvTIODSufj4le6pFCfcxL1XuTePF/output.mp4",
            "prompt": "A woman with light skin, wearing a blue jacket and a black hat with a veil, looks down and to her right, then back up as she speaks; she has brown hair styled in an updo, light brown eyebrows, and is wearing a white collared shirt under her jacket; the camera remains stationary on her face as she speaks; the background is out of focus, but shows trees and people in period clothing; the scene is captured in real-life footage."
          }
        ],
        "parameterDescriptions": {
          "fps": "Frames per second for the output video.",
          "seed": "Random seed for reproducible results. Leave blank for a random seed.",
          "image": "Input image for image-to-video generation. If provided, will generate video from this image.",
          "video": "Input video for video-to-video generation. If provided, will generate video from this video. Takes precedence over image if both are provided.",
          "prompt": "Text prompt for video generation",
          "go_fast": "Enable fast mode with skip layer strategies (20-40% faster but slightly lower quality).",
          "num_frames": "Number of frames to generate.",
          "resolution": "Resolution for the output video (height in pixels).",
          "aspect_ratio": "Aspect ratio for the output video.",
          "guidance_scale": "Guidance scale. Recommended range: 3.0-3.5.",
          "negative_prompt": "Negative prompt for video generation.",
          "denoise_strength": "Denoising strength for final refinement step.",
          "downscale_factor": "Factor to downscale initial generation (recommended: 2/3 for better quality).",
          "conditioning_frames": "Number of frames to use for video-to-video conditioning (only used when video input is provided).",
          "num_inference_steps": "Number of denoising steps for initial generation.",
          "final_inference_steps": "Number of inference steps for final denoising."
        }
      }
    },
    {
      "id": "zsxkib/kimi-vl-a3b-thinking",
      "name": "kimi-vl-a3b-thinking",
      "displayName": "kimi-vl-a3b-thinking",
      "provider": "replicate",
      "category": "image",
      "endpoint": "zsxkib/kimi-vl-a3b-thinking",
      "version": "c44e6d137b421d27afa9bf4f2360833d4f05a697b549356d44c3a56760a3164d",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Kimi-VL-A3B-Thinking is a multi-modal LLM that can understand text and images, and generate text with thinking processes",
        "runCount": 121,
        "confidence": 0.6,
        "qualityScore": 40.863598306747484,
        "createdAt": "2025-04-17T18:43:58.190790Z",
        "owner": "zsxkib",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/62441ba8-88e0-473b-878b-553149b2f101/kimi.webp",
        "githubUrl": "https://github.com/zsxkib/cog-kimi-vl-a3b-thinking",
        "paperUrl": "https://arxiv.org/abs/2504.07491",
        "licenseUrl": "https://github.com/MoonshotAI/Kimi-VL#MIT-1-ov-file",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "image": "https://raw.githubusercontent.com/zsxkib/cog-kimi-vl-a3b-thinking/main/images/demo1.jpeg",
              "top_p": 1,
              "prompt": "Where am I?",
              "temperature": 0.6,
              "max_length_tokens": 2048
            },
            "output": [
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "◁think▷Okay, ",
              "let's ",
              "",
              "see. ",
              "The ",
              "user ",
              "is ",
              "asking ",
              "",
              "\"Where ",
              "am ",
              "",
              "I?\" ",
              "and ",
              "provided ",
              "an ",
              "image ",
              "of ",
              "a ",
              "",
              "",
              "cyberpunk ",
              "bar ",
              "",
              "scene. ",
              "The ",
              "image ",
              "has ",
              "a ",
              "lot ",
              "of ",
              "neon ",
              "",
              "lights, ",
              "futuristic ",
              "",
              "elements, ",
              "and ",
              "people ",
              "sitting ",
              "at ",
              "a ",
              "",
              "bar. ",
              "There's ",
              "a ",
              "sign ",
              "that ",
              "says ",
              "",
              "\"The ",
              "",
              "",
              "Heist\" ",
              "and ",
              "some ",
              "text ",
              "about ",
              "sitting ",
              "next ",
              "to ",
              "",
              "Jackie. ",
              "",
              "Also, ",
              "there's ",
              "a ",
              "",
              "mini-map ",
              "in ",
              "the ",
              "",
              "corner, ",
              "which ",
              "might ",
              "indicate ",
              "it's ",
              "from ",
              "a ",
              "video ",
              "game.\n\n",
              "",
              "",
              "First, ",
              "I ",
              "need ",
              "to ",
              "figure ",
              "out ",
              "which ",
              "game ",
              "this ",
              "",
              "is. ",
              "The ",
              "",
              "",
              "cyberpunk ",
              "aesthetic ",
              "with ",
              "the ",
              "bar ",
              "setting ",
              "and ",
              "the ",
              "",
              "mini-map ",
              "suggests ",
              "it ",
              "could ",
              "be ",
              "",
              "",
              "Cyberpunk ",
              "",
              "",
              "",
              "2077. ",
              "The ",
              "",
              "Heist ",
              "as ",
              "a ",
              "location ",
              "is ",
              "a ",
              "known ",
              "area ",
              "in ",
              "that ",
              "",
              "game. ",
              "The ",
              "",
              "characters' ",
              "outfits ",
              "and ",
              "the ",
              "overall ",
              "environment ",
              "match ",
              "the ",
              "game's ",
              "",
              "style. ",
              "The ",
              "user ",
              "might ",
              "be ",
              "",
              "",
              "in-game, ",
              "so ",
              "the ",
              "answer ",
              "should ",
              "confirm ",
              "that ",
              "they're ",
              "in ",
              "",
              "",
              "Cyberpunk ",
              "",
              "",
              "",
              "2077, ",
              "specifically ",
              "at ",
              "The ",
              "",
              "Heist ",
              "",
              "bar. ",
              "I ",
              "should ",
              "mention ",
              "the ",
              "game's ",
              "title ",
              "and ",
              "the ",
              "",
              "location's ",
              "",
              "name. ",
              "",
              "Also, ",
              "note ",
              "the ",
              "HUD ",
              "elements ",
              "as ",
              "part ",
              "of ",
              "the ",
              "game's ",
              "",
              "interface. ",
              "Make ",
              "sure ",
              "to ",
              "keep ",
              "it ",
              "concise ",
              "but ",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "informative.◁/think▷You ",
              "are ",
              "in ",
              "",
              "",
              "",
              "**Cyberpunk ",
              "",
              "",
              "",
              "2077**, ",
              "a ",
              "",
              "role-playing ",
              "video ",
              "game ",
              "set ",
              "in ",
              "a ",
              "",
              "dystopian ",
              "future ",
              "version ",
              "of ",
              "Night ",
              "",
              "City. ",
              "The ",
              "image ",
              "shows ",
              "you ",
              "inside ",
              "",
              "**The ",
              "",
              "",
              "Heist**, ",
              "a ",
              "bar ",
              "or ",
              "nightclub ",
              "popular ",
              "in ",
              "the ",
              "",
              "game. ",
              "The ",
              "",
              "",
              "cyberpunk ",
              "",
              "aesthetic, ",
              "neon ",
              "",
              "lighting, ",
              "and ",
              "HUD ",
              "elements ",
              "",
              "",
              "",
              "(mini-map, ",
              "objectives ",
              "like ",
              "",
              "\"Sit ",
              "next ",
              "to ",
              "",
              "Jackie\") ",
              "align ",
              "with ",
              "the ",
              "game's ",
              "signature ",
              "",
              "style. ",
              "This ",
              "location ",
              "is ",
              "known ",
              "for ",
              "its ",
              "vibrant ",
              "atmosphere ",
              "and ",
              "interactions ",
              "with ",
              "characters ",
              "like ",
              "Jackie ",
              "",
              "",
              "Welles, ",
              "a ",
              "key ",
              "figure ",
              "in ",
              "the ",
              "early ",
              "",
              "",
              "story.<|im_end|>"
            ],
            "prompt": "Where am I?"
          }
        ],
        "parameterDescriptions": {
          "image": "Optional image input",
          "top_p": "Top-p sampling probability",
          "prompt": "Text prompt for the model",
          "temperature": "Sampling temperature",
          "max_length_tokens": "Maximum number of tokens to generate"
        }
      }
    },
    {
      "id": "gfodor/text2vox",
      "name": "text2vox",
      "displayName": "text2vox",
      "provider": "replicate",
      "category": "image",
      "endpoint": "gfodor/text2vox",
      "version": "740dd98e409d65e7a0fa02ec9bf549bd903b19a18a0cab02865d4615225c8ba5",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generates MagicaVoxel VOX models, using flux dev + hunyuan3d-2. Can generate high detail and low detail models at varying resolutions.",
        "runCount": 113,
        "confidence": 0.6,
        "qualityScore": 40.56904851336473,
        "createdAt": "2025-03-24T07:01:14.224367Z",
        "owner": "gfodor",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/9fd63fad-8fcd-4da4-bf62-70a702097573/snap2025-03-23-23-39-13.png",
        "githubUrl": "https://github.com/gfodor/text2vox",
        "paperUrl": null,
        "licenseUrl": "https://choosealicense.com/licenses/mit/",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": 1234,
              "steps": 50,
              "prompt": "A wizard in a purple robe and pointed hat, wielding a staff and casting a spell.",
              "guidance": 6,
              "detail_level": "high",
              "guidance_scale": 5.5,
              "prompt_strength": 0.8,
              "octree_resolution": 512,
              "remove_background": true,
              "num_inference_steps": 50
            },
            "output": [
              "https://replicate.delivery/yhqm/xvQwnQKEPm6tG5fynEefERcdXMukSMQSIF5kzXMTCQudMX3oA/a_wizard_in_a_purple_robe_and_pointed_hat_wielding.vox.glb",
              "https://replicate.delivery/yhqm/J1LB7JM0szJ3LRDsxvP1yUPyViK4uw7r3AmUUSwjizpj56GF/a_wizard_in_a_purple_robe_and_pointed_hat_wielding_large.vox",
              "https://replicate.delivery/yhqm/PApPmBt5FPqMCd7KmS9DCQol4fr8bfxYKI0E29jE1PzOmrbUA/a_wizard_in_a_purple_robe_and_pointed_hat_wielding_medium.vox",
              "https://replicate.delivery/yhqm/I5RsuevdxRw4Sa1Mc2AyZ1d3bfshgrBcTpGObxaFAvaOmrbUA/a_wizard_in_a_purple_robe_and_pointed_hat_wielding_small.vox"
            ],
            "prompt": "A wizard in a purple robe and pointed hat, wielding a staff and casting a spell."
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed",
          "steps": "Number of inference steps for Hunyuan",
          "prompt": "Prompt for generated image",
          "guidance": "Guidance scale for Flux",
          "detail_level": "Detail level. High will try to generate a good high resolution voxel model, and low try to generate a good low resolution voxel model.",
          "guidance_scale": "Guidance scale for Hunyuan",
          "prompt_strength": "Prompt strength for img2img in Flux (only applicable if image is provided)",
          "octree_resolution": "Octree resolution for Hunyuan",
          "remove_background": "Remove the background from the generated image. Useful to turn off if you want to generate a full voxel scene.",
          "num_inference_steps": "Number of inference steps for Flux"
        }
      }
    },
    {
      "id": "d3vshoaib/andro-upscaler",
      "name": "andro-upscaler",
      "displayName": "andro-upscaler",
      "provider": "replicate",
      "category": "image",
      "endpoint": "d3vshoaib/andro-upscaler",
      "version": "c9ef38bd8f0ce4c72dfaed5e02bb917931afc44a760432a502fd8577fc5d07c5",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A model Flux.1-dev-Controlnet-Upscaler by www.androcoders.in",
        "runCount": 111,
        "confidence": 0.9,
        "qualityScore": 40.49218022670182,
        "createdAt": "2025-03-28T08:53:25.342465Z",
        "owner": "d3vshoaib",
        "coverImage": "https://replicate.delivery/yhqm/ps26N2kfSKytbqpbLYheUJeUcAteVOXm9Dzo1dgYX6iOHipRB/output.jpg",
        "githubUrl": "https://github.com/black-forest-labs/flux",
        "paperUrl": "https://docs.bfl.ml/",
        "licenseUrl": "https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "",
              "input_image": "https://replicate.delivery/pbxt/MgvTlU1iEWwXmQmO07LHRhkfDgdBe6uqXD6eSf5bryynQ5tO/cat-test.jpeg",
              "guidance_scale": 5,
              "upscale_factor": 4,
              "apply_cc_preset": false,
              "num_inference_steps": 28,
              "controlnet_conditioning_scale": 0.6
            },
            "output": "https://replicate.delivery/yhqm/ps26N2kfSKytbqpbLYheUJeUcAteVOXm9Dzo1dgYX6iOHipRB/output.jpg",
            "prompt": ""
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Leave blank to randomize the seed",
          "prompt": "Text prompt to guide the upscaling. Leave empty for default behavior.",
          "input_image": "Input image to upscale",
          "guidance_scale": "Guidance scale for Image adherence",
          "upscale_factor": "Factor by which to upscale the image",
          "apply_cc_preset": "Applying Color Correction ",
          "num_inference_steps": "Number of denoising steps",
          "controlnet_conditioning_scale": "Controlnet conditioning scale"
        }
      }
    },
    {
      "id": "lucataco/cogview4-6b",
      "name": "cogview4-6b",
      "displayName": "cogview4-6b",
      "provider": "replicate",
      "category": "image",
      "endpoint": "lucataco/cogview4-6b",
      "version": "5b608630958be05f6845ed0d629f56cd01c372017d42f4e26916a12c7eab7b62",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "CogView-4 model, which has 6B parameters, supports native Chinese input, and Chinese text-to-image generation.",
        "runCount": 107,
        "confidence": 0.9,
        "qualityScore": 40.3342375548695,
        "createdAt": "2025-03-06T20:04:52.320421Z",
        "owner": "lucataco",
        "coverImage": "https://replicate.delivery/xezq/LAoxeRLX7A2EGCMuSdaaVmiJZw5KYj5eguMih1X01YuVK7VUA/output.png",
        "githubUrl": null,
        "paperUrl": "https://arxiv.org/abs/2403.05121",
        "licenseUrl": "https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "width": 1024,
              "height": 1024,
              "prompt": "A vibrant cherry red sports car sits proudly under the gleaming sun, its polished exterior smooth and flawless, casting a mirror-like reflection. The car features a low, aerodynamic body, angular headlights that gaze forward like predatory eyes, and a set of black, high-gloss racing rims that contrast starkly with the red. A subtle hint of chrome embellishes the grille and exhaust, while the tinted windows suggest a luxurious and private interior. The scene conveys a sense of speed and elegance, the car appearing as if it's about to burst into a sprint along a coastal road, with the ocean's azure waves crashing in the background",
              "guidance_scale": 3.5,
              "num_inference_steps": 50
            },
            "output": "https://replicate.delivery/xezq/LAoxeRLX7A2EGCMuSdaaVmiJZw5KYj5eguMih1X01YuVK7VUA/output.png",
            "prompt": "A vibrant cherry red sports car sits proudly under the gleaming sun, its polished exterior smooth and flawless, casting a mirror-like reflection. The car features a low, aerodynamic body, angular headlights that gaze forward like predatory eyes, and a set of black, high-gloss racing rims that contrast starkly with the red. A subtle hint of chrome embellishes the grille and exhaust, while the tinted windows suggest a luxurious and private interior. The scene conveys a sense of speed and elegance, the car appearing as if it's about to burst into a sprint along a coastal road, with the ocean's azure waves crashing in the background"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible image generation",
          "width": "Width of the generated image (must be between 512 and 2048, divisible by 32)",
          "height": "Height of the generated image (must be between 512 and 2048, divisible by 32)",
          "prompt": "Text prompt to generate an image from",
          "guidance_scale": "Guidance scale for classifier-free guidance",
          "negative_prompt": "Negative prompt to guide image generation away from certain concepts",
          "num_inference_steps": "Number of denoising steps"
        }
      }
    },
    {
      "id": "jschoormans/unstaging",
      "name": "unstaging",
      "displayName": "unstaging",
      "provider": "replicate",
      "category": "image",
      "endpoint": "jschoormans/unstaging",
      "version": "d41e1770837f167a28f948c6bc81baefbbaa9dfa278d6f528ce40b5a61be9b74",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Removes furniture",
        "runCount": 10510,
        "confidence": 0.9,
        "qualityScore": 40.21644036087444,
        "createdAt": "2025-03-04T19:31:36.614210Z",
        "owner": "jschoormans",
        "coverImage": "https://replicate.delivery/yhqm/vfbRTURBtQXmWaWru862JnkrpUXk8L93LFSXAFVC3oJyLeSUA/output_subject_1024.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "cheap"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/MYuiIS1geUNr8VVdDvRcnn0igNwrlADa2qKRMMUKOxgkj1QM/ap_21021110795446_custom-fd9247fb6ba93d0716007fe065d4959310b3e6a8.webp",
              "prompt": "empty room, nothing",
              "resolution": 1024,
              "num_inference_steps": 8,
              "resolution_conditioning": 1024
            },
            "output": "https://replicate.delivery/yhqm/vfbRTURBtQXmWaWru862JnkrpUXk8L93LFSXAFVC3oJyLeSUA/output_subject_1024.png",
            "prompt": "empty room, nothing"
          }
        ],
        "parameterDescriptions": {
          "seed": "Seed for the generation",
          "image": "Input image for conditioning",
          "scale": "Scale of the conditioning image",
          "prompt": "Text prompt for generation",
          "num_runs": "Number of runs to make",
          "resolution": "Output resolution",
          "negative_prompt": "Negative text prompt for generation",
          "num_inference_steps": "Number of denoising steps",
          "resolution_conditioning": "Resolution of the conditioning image"
        }
      }
    },
    {
      "id": "lucataco/flux-3d-emojis",
      "name": "flux-3d-emojis",
      "displayName": "flux-3d-emojis",
      "provider": "replicate",
      "category": "image",
      "endpoint": "lucataco/flux-3d-emojis",
      "version": "90c9d165452f90e3ce38b35e7ac753e6bedcfc7f75c5188f90bcc41bbff99870",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This LoRA was trained with the replicate/fast-flux-trainer",
        "runCount": 100,
        "confidence": 0.6,
        "qualityScore": 40.04321373782643,
        "createdAt": "2025-05-24T03:05:42.398904Z",
        "owner": "lucataco",
        "coverImage": "https://replicate.delivery/xezq/r7pmIcDxCc6XNNBDXGK2wPugofULfyz4trxeX9O3jOWPhdfSB/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "F3DE a pirate face with a black eyepatch decorated with a skull and crossbones, wearing a red bandana and gold hoop earrings. A parrot sits perched on the hat, and the face has a mischievous grin. The background shows a tropical island with a treasure chest on the beach.",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/r7pmIcDxCc6XNNBDXGK2wPugofULfyz4trxeX9O3jOWPhdfSB/out-0.webp"
            ],
            "prompt": "F3DE a pirate face with a black eyepatch decorated with a skull and crossbones, wearing a red bandana and gold hoop earrings. A parrot sits perched on the hat, and the face has a mischievous grin. The background shows a tropical island with a treasure chest on the beach."
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "openai/dall-e-2",
      "name": "dall-e-2",
      "displayName": "dall-e-2",
      "provider": "replicate",
      "category": "image",
      "endpoint": "openai/dall-e-2",
      "version": "62061b3e3bf0c64f9507d8df93e07af7ed3c2cbf9f26e50316034ad05d0feb39",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "The original classic DALLᐧE 2",
        "runCount": 300,
        "confidence": 0.6,
        "qualityScore": 39.78566495593843,
        "createdAt": "2025-05-16T14:58:35.244283Z",
        "owner": "openai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/9387c521-c833-4345-80dd-8c72515a8c8b/Screenshot_2025-05-18_at_1.42..png",
        "githubUrl": null,
        "paperUrl": "https://cdn.openai.com/papers/dall-e-2.pdf",
        "licenseUrl": "https://openai.com/index/dall-e-2/",
        "pricing": {
          "tier": "premium"
        },
        "examples": [
          {
            "input": {
              "prompt": "an oil painting of a seascape",
              "number_of_images": 1
            },
            "output": [
              "https://replicate.delivery/xezq/kEwT62mKUC75IViyTx3MW3Z0Cp1J6tshWjnMcy9ZkLhxGULF/tmp4z3auybm.png"
            ],
            "prompt": "an oil painting of a seascape"
          }
        ],
        "parameterDescriptions": {
          "prompt": "A text description of the desired image",
          "number_of_images": "Number of images to generate (1-10)"
        }
      }
    },
    {
      "id": "paullux/framepack-runner",
      "name": "framepack-runner",
      "displayName": "framepack-runner",
      "provider": "replicate",
      "category": "video",
      "endpoint": "paullux/framepack-runner",
      "version": "2066ad45df0ec8d3041aa40fb18f4f14ae55154dfc85af90b41dc91c705108d8",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "FramePack video generation with image + motion prompt. Based on Stanford's 2025 model.",
        "runCount": 91,
        "confidence": 0.9,
        "qualityScore": 39.637878273455556,
        "createdAt": "2025-05-10T02:36:31.871634Z",
        "owner": "paullux",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/ceafd75f-ed3e-48fc-b341-76861280ccf4/moi_tatou%C3%A9_reduce.png",
        "githubUrl": "https://github.com/Paullux/FramePack",
        "paperUrl": "https://arxiv.org/abs/2404.12927",
        "licenseUrl": "https://www.apache.org/licenses/LICENSE-2.0",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "fps": 30,
              "seed": 42,
              "image": "https://replicate.delivery/pbxt/Mz0mCaWoLbfWsu1cEq9n6cah4tkhwpURFjDubLtGWCo9SaIv/moi_tatou%C3%A9_reduce.png",
              "steps": 25,
              "prompt": "A majestic fiery phoenix tattoo on a human back suddenly comes to life, glowing with bright orange and red flames. The flames ripple and swirl as the wings start to move. The phoenix slowly rises off the skin, lifting upward in a swirl of fire and embers. As it ascends, sparks fall around, and the wings flap powerfully. The scene is dramatic and cinematic, with a dark background and glowing light effects.",
              "duration_seconds": 5
            },
            "output": "https://replicate.delivery/yhqm/Z6we9S1eFEjYKkKjcH3XYElHZy1pMB7uuTs7iXPe7xcySXWpA/tmp3rq4_roc.mp4",
            "prompt": "A majestic fiery phoenix tattoo on a human back suddenly comes to life, glowing with bright orange and red flames. The flames ripple and swirl as the wings start to move. The phoenix slowly rises off the skin, lifting upward in a swirl of fire and embers. As it ascends, sparks fall around, and the wings flap powerfully. The scene is dramatic and cinematic, with a dark background and glowing light effects."
          }
        ],
        "parameterDescriptions": {
          "fps": "Framerate de sortie",
          "seed": "Seed pour la reproductibilité",
          "image": "Image d'entrée (.jpg ou .png)",
          "steps": "Nombre d'étapes de sampling",
          "prompt": "Prompt décrivant le mouvement",
          "duration_seconds": "Durée de la vidéo en secondes"
        }
      }
    },
    {
      "id": "lucataco/flux-game-assets",
      "name": "flux-game-assets",
      "displayName": "flux-game-assets",
      "provider": "replicate",
      "category": "image",
      "endpoint": "lucataco/flux-game-assets",
      "version": "2968f90319821245e410fbc2b35de562a3bb9e8a937d0426e548d65c6e2d9b23",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This LoRA was trained with the replicate/fast-flux-trainer",
        "runCount": 80,
        "confidence": 0.6,
        "qualityScore": 39.0848501887865,
        "createdAt": "2025-05-23T19:42:16.884355Z",
        "owner": "lucataco",
        "coverImage": "https://replicate.delivery/xezq/nmA05fb2EUwuGa2QXymmeiu2hFaQjpkF066hzeiXfEPLahelC/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "FGAL health potion, white background, game asset",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/nmA05fb2EUwuGa2QXymmeiu2hFaQjpkF066hzeiXfEPLahelC/out-0.webp"
            ],
            "prompt": "FGAL health potion, white background, game asset"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "lucataco/flux-kontext-dev",
      "name": "flux-kontext-dev",
      "displayName": "flux-kontext-dev",
      "provider": "replicate",
      "category": "image",
      "endpoint": "lucataco/flux-kontext-dev",
      "version": "e2a2a6f122724dd95ecc0e8e42c586cbdd512847de7851225ceefba2da197188",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Open-weight version of FLUX.1 Kontext via Hugging Face Diffusers",
        "runCount": 76,
        "confidence": 0.9,
        "qualityScore": 38.864907251724816,
        "createdAt": "2025-07-02T15:46:34.863165Z",
        "owner": "lucataco",
        "coverImage": "https://replicate.delivery/xezq/bbRzS2fmv10yXyZk6mC18Uaw2JCQIFrF330cumZdnuLzOYeUA/output.png",
        "githubUrl": "https://github.com/lucataco/cog-flux-kontext-dev",
        "paperUrl": "https://arxiv.org/abs/2506.15742",
        "licenseUrl": "https://github.com/black-forest-labs/flux/blob/main/LICENSE",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "image": "https://replicate.delivery/pbxt/NHwfkxwNVUCK9MtHcEgXMrZ9N01ejRZhTAmXpUsIlbIk8xOX/yellow-car-1024.jpg",
              "prompt": "Change the car color to red, turn the headlights on",
              "aspect_ratio": "match_input_image",
              "guidance_scale": 2.5,
              "num_inference_steps": 28
            },
            "output": "https://replicate.delivery/xezq/bbRzS2fmv10yXyZk6mC18Uaw2JCQIFrF330cumZdnuLzOYeUA/output.png",
            "prompt": "Change the car color to red, turn the headlights on"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set -1 to randomize the seed",
          "image": "Input image to edit",
          "prompt": "Text instruction describing the edit to make",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "guidance_scale": "Guidance scale for generation. Higher values follow the prompt more closely.",
          "num_inference_steps": "Number of inference steps"
        }
      }
    },
    {
      "id": "oliversaternus/realvisxl-3-multi-controlnet-lora-misto",
      "name": "realvisxl-3-multi-controlnet-lora-misto",
      "displayName": "realvisxl-3-multi-controlnet-lora-misto",
      "provider": "replicate",
      "category": "image",
      "endpoint": "oliversaternus/realvisxl-3-multi-controlnet-lora-misto",
      "version": "6315b5311a83d918f5c3ac59683c8cdd44c6532920be8e17b8d0a46be5653f0f",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "RealVisXl V3 with multi-controlnet, lora loading, img2img, inpainting, misto anyline controlnet",
        "runCount": 74,
        "confidence": 0.6,
        "qualityScore": 38.750612633917,
        "createdAt": "2025-05-26T22:49:05.316449Z",
        "owner": "oliversaternus",
        "coverImage": "https://replicate.delivery/xezq/w6G0XoeSVFWgQCKNGjpUfTt61STWz5GPegAL5OepOpux6fMmC/out-0.png",
        "githubUrl": "https://github.com/oliversaternus/cog-realvisxl-3-multi-controlnet-lora",
        "paperUrl": null,
        "licenseUrl": "https://github.com/oliversaternus/cog-realvisxl-3-multi-controlnet-lora/blob/main/LICENSE",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/xezq/odRRGCQC6eXETiWAfO7HyjrKwuNfwG4PZ0tbLBOPC62uyPjpA/out-0.webp",
              "width": 768,
              "height": 768,
              "prompt": "living room, modern interior design, a functional space, white walls, matte gray floor, black and white colors, geometric shapes, modular furniture, steel and glass, and modern design elements",
              "refine": "no_refiner",
              "scheduler": "K_EULER",
              "lora_scale": 0.6,
              "num_outputs": 1,
              "controlnet_1": "lineart_anyline",
              "controlnet_2": "none",
              "controlnet_3": "none",
              "guidance_scale": 7.5,
              "apply_watermark": false,
              "negative_prompt": "",
              "prompt_strength": 1,
              "sizing_strategy": "input_image",
              "controlnet_1_end": 0.8,
              "controlnet_2_end": 1,
              "controlnet_3_end": 1,
              "controlnet_1_image": "https://replicate.delivery/xezq/odRRGCQC6eXETiWAfO7HyjrKwuNfwG4PZ0tbLBOPC62uyPjpA/out-0.webp",
              "controlnet_1_start": 0,
              "controlnet_2_start": 0,
              "controlnet_3_start": 0,
              "num_inference_steps": 30,
              "controlnet_1_conditioning_scale": 0.8,
              "controlnet_2_conditioning_scale": 0.75,
              "controlnet_3_conditioning_scale": 0.75
            },
            "output": [
              "https://replicate.delivery/xezq/afnfeCZgpCIdgI8Bj4rP4k1caH3weWNo5EeWhACSZWqm1fZMF/control-0.png",
              "https://replicate.delivery/xezq/w6G0XoeSVFWgQCKNGjpUfTt61STWz5GPegAL5OepOpux6fMmC/out-0.png"
            ],
            "prompt": "living room, modern interior design, a functional space, white walls, matte gray floor, black and white colors, geometric shapes, modular furniture, steel and glass, and modern design elements"
          }
        ],
        "parameterDescriptions": {
          "mask": "Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted.",
          "seed": "Random seed. Leave blank to randomize the seed",
          "image": "Input image for img2img or inpaint mode",
          "width": "Width of output image",
          "height": "Height of output image",
          "prompt": "Input prompt",
          "refine": "Which refine style to use",
          "scheduler": "scheduler",
          "lora_scale": "LoRA additive scale. Only applicable on trained models.",
          "num_outputs": "Number of images to output",
          "controlnet_1": "Controlnet",
          "controlnet_2": "Controlnet",
          "controlnet_3": "Controlnet",
          "lora_weights": "Replicate LoRA weights to use. Leave blank to use the default weights.",
          "refine_steps": "For base_image_refiner, the number of steps to refine, defaults to num_inference_steps",
          "guidance_scale": "Scale for classifier-free guidance",
          "apply_watermark": "Applies a watermark to enable determining if an image is generated in downstream applications. If you have other provisions for generating or deploying images safely, you can use this to disable watermarking.",
          "negative_prompt": "Negative Prompt",
          "prompt_strength": "Prompt strength when using img2img / inpaint. 1.0 corresponds to full destruction of information in image",
          "sizing_strategy": "Decide how to resize images – use width/height, resize based on input image or control image",
          "controlnet_1_end": "When controlnet conditioning ends",
          "controlnet_2_end": "When controlnet conditioning ends",
          "controlnet_3_end": "When controlnet conditioning ends",
          "controlnet_1_image": "Input image for first controlnet",
          "controlnet_1_start": "When controlnet conditioning starts",
          "controlnet_2_image": "Input image for second controlnet",
          "controlnet_2_start": "When controlnet conditioning starts",
          "controlnet_3_image": "Input image for third controlnet",
          "controlnet_3_start": "When controlnet conditioning starts",
          "num_inference_steps": "Number of denoising steps",
          "disable_safety_checker": "Disable safety checker for generated images. This feature is only available through the API.",
          "controlnet_1_conditioning_scale": "How strong the controlnet conditioning is",
          "controlnet_2_conditioning_scale": "How strong the controlnet conditioning is",
          "controlnet_3_conditioning_scale": "How strong the controlnet conditioning is"
        }
      }
    },
    {
      "id": "fofr/wan-14b-cyberpunk-realistic",
      "name": "wan-14b-cyberpunk-realistic",
      "displayName": "wan-14b-cyberpunk-realistic",
      "provider": "replicate",
      "category": "image",
      "endpoint": "fofr/wan-14b-cyberpunk-realistic",
      "version": "8d934a800aee769933dd3f54c9348ac92d28c588065389ce7a526c77150069b5",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Wan2.1 fine tuned on hyper realistic Cyberpunk 2077 mods",
        "runCount": 68,
        "confidence": 0.6,
        "qualityScore": 38.38849090737256,
        "createdAt": "2025-03-22T17:34:02.098528Z",
        "owner": "fofr",
        "coverImage": "https://replicate.delivery/xezq/asl3HD14zJpjCV3WAefO5cMDOqyxKG2ZWIfN1dD9DRby4V2oA/R8_Wan_00001.mp4",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/xezq/cPbpoOia6exgEq9sTwWMn9HsytppiVjq3cYrfYfzErlfqqsRB/tmpr4czcw2e.png",
              "frames": 81,
              "prompt": "in the style of CYB77, driving a car very fast through a city at night",
              "fast_mode": "Off",
              "resolution": "480p",
              "aspect_ratio": "16:9",
              "sample_shift": 8,
              "sample_steps": 50,
              "negative_prompt": "",
              "lora_strength_clip": 1,
              "sample_guide_scale": 5,
              "lora_strength_model": 1
            },
            "output": [
              "https://replicate.delivery/xezq/asl3HD14zJpjCV3WAefO5cMDOqyxKG2ZWIfN1dD9DRby4V2oA/R8_Wan_00001.mp4"
            ],
            "prompt": "in the style of CYB77, driving a car very fast through a city at night"
          }
        ],
        "parameterDescriptions": {
          "seed": "Set a seed for reproducibility. Random by default.",
          "image": "Image to use as a starting frame for image to video generation.",
          "frames": "The number of frames to generate (1 to 5 seconds)",
          "prompt": "Text prompt for video generation",
          "fast_mode": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.",
          "resolution": "The resolution of the video. 720p is not supported for 1.3b.",
          "aspect_ratio": "The aspect ratio of the video. 16:9, 9:16, 1:1, etc.",
          "sample_shift": "Sample shift factor",
          "sample_steps": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts",
          "negative_prompt": "Things you do not want to see in your video",
          "replicate_weights": "Replicate LoRA weights to use. Leave blank to use the default weights.",
          "lora_strength_clip": "Strength of the LORA applied to the CLIP model. 0.0 is no LORA.",
          "sample_guide_scale": "Higher guide scale makes prompt adherence better, but can reduce variation",
          "lora_strength_model": "Strength of the LORA applied to the model. 0.0 is no LORA."
        }
      }
    },
    {
      "id": "goodguy1963/epicrealism-naturalsinfinal-byepinikion-v2",
      "name": "epicrealism-naturalsinfinal-byepinikion-v2",
      "displayName": "epicrealism-naturalsinfinal-byepinikion-v2",
      "provider": "replicate",
      "category": "image",
      "endpoint": "goodguy1963/epicrealism-naturalsinfinal-byepinikion-v2",
      "version": "5310130b210862f0f4c222c5f67d1e0ccde3b1aaf4a3abb2918cad7d3f2dce4b",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "epicrealism-naturalsinfinal-SD1.5-by-epinikion + perfectdeliberate by Desync + More Details by Lykon",
        "runCount": 63,
        "confidence": 0.9,
        "qualityScore": 38.061799739838875,
        "createdAt": "2025-03-22T23:31:03.593575Z",
        "owner": "goodguy1963",
        "coverImage": "https://replicate.delivery/yhqm/t9d3ozvp4ba9CtRsgScRCY0AtAvDG8DJW9fF3CK6OecFfw2oA/output.png",
        "githubUrl": "https://github.com/goodguy1963/sd-epic-realism-for-replicate",
        "paperUrl": null,
        "licenseUrl": "https://huggingface.co/spaces/CompVis/stable-diffusion-license",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "width": 1024,
              "height": 1024,
              "prompt": "woman dancing",
              "sampler": "DPMPP_2M",
              "model_name": "perfectdeliberate",
              "lora_weight": 0.8,
              "guidance_scale": 7.5,
              "lora_selection": "none",
              "scheduler_type": "karras",
              "negative_prompt": "worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art, mutated, deformed, distorted, disfigured, body horror, watermark, text, meme, bad proportions, cropped head, out of frame, cut off, ugly, duplicate, mutilated, mutation, disgusting, bad anatomy, bad hands, three hands, three legs, bad feet, three feet",
              "prompt_strength": 0.8,
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/yhqm/t9d3ozvp4ba9CtRsgScRCY0AtAvDG8DJW9fF3CK6OecFfw2oA/output.png",
            "prompt": "woman dancing"
          }
        ],
        "parameterDescriptions": {
          "mask": "Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted.",
          "seed": "Random seed. Leave blank to randomize the seed",
          "image": "Input image for img2img or inpaint mode",
          "width": "Width of output image",
          "height": "Height of output image",
          "prompt": "Input prompt",
          "sampler": "Choose a sampler",
          "model_name": "Choose which model to use",
          "lora_weight": "LoRA weight (higher values increase effect strength)",
          "guidance_scale": "Scale for classifier-free guidance",
          "lora_selection": "Select a LoRA or LoRA combination to apply",
          "scheduler_type": "Choose a scheduler type",
          "civitai_api_key": "Your Civitai API key for downloading models (REQUIRED)",
          "negative_prompt": "Specify things to not see in the output",
          "prompt_strength": "Prompt strength when using init image. 1.0 corresponds to full destruction of information in init image",
          "num_inference_steps": "Number of denoising steps"
        }
      }
    },
    {
      "id": "easel/ai-avatars",
      "name": "ai-avatars",
      "displayName": "ai-avatars",
      "provider": "replicate",
      "category": "image",
      "endpoint": "easel/ai-avatars",
      "version": "27ebf241efeded7a50964c7cff8f27c79e1570674be70d8e1df712ae31857d34",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Use one or two face images to create AI avatars",
        "runCount": 6326,
        "confidence": 0.9,
        "qualityScore": 38.01197834459149,
        "createdAt": "2025-04-30T08:19:37.642460Z",
        "owner": "easel",
        "coverImage": "https://replicate.delivery/xezq/9Gd6pe7mfAiR3E779Ln87uLChkUAkdBGeQVbYZWTyf8olKIUB/output.1.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": "https://easelapps.ai/terms",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "at the Met Gala, dressed in very fancy outfits, captured in a full body shot",
              "face_image": "https://replicate.delivery/pbxt/MlYeEa5wsgHEWcw9jVYmFXGJQAsZia8polOhuLvjUtKlnSrt/guy.webp",
              "user_gender": "male",
              "face_image_b": "https://replicate.delivery/pbxt/NNdXExUtOHwiz9NA5K6l1u2hymcBJ14gyzupGgRP3fgBySOk/image%20%2818%29.png",
              "user_b_gender": "female",
              "workflow_type": "HyperRealistic-likeness"
            },
            "output": "https://replicate.delivery/xezq/9Gd6pe7mfAiR3E779Ln87uLChkUAkdBGeQVbYZWTyf8olKIUB/output.1.png",
            "prompt": "at the Met Gala, dressed in very fancy outfits, captured in a full body shot"
          }
        ],
        "parameterDescriptions": {
          "prompt": "A prompt describing the scene to put the user(s) in",
          "face_image": "The face image to generate avatar from. A front facing selfie works best.",
          "user_gender": "Gender of the first user",
          "face_image_b": "Optional second face image for multi-person avatars",
          "user_b_gender": "Gender of the second user (if using face_image_b)",
          "workflow_type": "The output style to use"
        }
      }
    },
    {
      "id": "lucataco/kontext-realearth",
      "name": "kontext-realearth",
      "displayName": "kontext-realearth",
      "provider": "replicate",
      "category": "image",
      "endpoint": "lucataco/kontext-realearth",
      "version": "2af4da47bcb7b55a0705b0de9933701f7607531d763ae889241f827a648c1755",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This Kontext LoRA turns basic satellite images into quality drone shots",
        "runCount": 61,
        "confidence": 0.9,
        "qualityScore": 37.92391689498254,
        "createdAt": "2025-07-22T20:28:07.480440Z",
        "owner": "lucataco",
        "coverImage": "https://replicate.delivery/xezq/VG5jreorexlLzUvTITRmegfIzDQ0l9j2DPOCPd9sgarDtpNUB/output.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "make this a realistic drone photo",
              "guidance": 2.5,
              "megapixels": "1",
              "input_image": "https://replicate.delivery/pbxt/NP77NxhytVEogF3ahnnHDi0APHsXk04Q19tVoiPwEKDUvjDq/Screenshot%202025-07-22%20at%204.29.32%E2%80%AFPM.png",
              "aspect_ratio": "match_input_image",
              "lora_strength": 1,
              "output_format": "webp",
              "output_quality": 80,
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/xezq/VG5jreorexlLzUvTITRmegfIzDQ0l9j2DPOCPd9sgarDtpNUB/output.webp",
            "prompt": "make this a realistic drone photo"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible generation. Leave blank for random.",
          "prompt": "Text description of what you want to generate, or the instruction on how to edit the given image.",
          "guidance": "Guidance scale for generation",
          "megapixels": "Approximate number of megapixels for generated image",
          "input_image": "Image to use as reference. Must be jpeg, png, gif, or webp.",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "lora_strength": "Strength of the lora",
          "output_format": "Output image format",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "replicate_weights": "Path to the lora weights",
          "num_inference_steps": "Number of inference steps",
          "disable_safety_checker": "Disable NSFW safety checker"
        }
      }
    },
    {
      "id": "un-loc/olga",
      "name": "olga",
      "displayName": "olga",
      "provider": "replicate",
      "category": "image",
      "endpoint": "un-loc/olga",
      "version": "bddeb8ca51e44d956bf27999e3f524d4bde69c2e27b2afce19cfd1db8f819583",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "The model trained based on Olga Ciob's drawing during a workshops in Bucharest.",
        "runCount": 61,
        "confidence": 0.6,
        "qualityScore": 37.92391689498254,
        "createdAt": "2025-07-11T09:09:13.713793Z",
        "owner": "un-loc",
        "coverImage": "https://replicate.delivery/xezq/x0grs9ftQ5yZMqUec0n85JO4VOA2bMIeua5FAvM7zNNKEjAqA/out-0.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "schnell",
              "prompt": "OLGA Drawing of UNLOC",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "png",
              "guidance_scale": 5.46,
              "output_quality": 100,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 6
            },
            "output": [
              "https://replicate.delivery/xezq/x0grs9ftQ5yZMqUec0n85JO4VOA2bMIeua5FAvM7zNNKEjAqA/out-0.png"
            ],
            "prompt": "OLGA Drawing of UNLOC"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "sruthiselvaraj/indicparlertts",
      "name": "indicparlertts",
      "displayName": "indicparlertts",
      "provider": "replicate",
      "category": "audio",
      "endpoint": "sruthiselvaraj/indicparlertts",
      "version": "feba89f750cb30bd7c5fb53533b78873a313ff7cc168ae2df304f202cca5b1c8",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Indic Parler-TTS Pretrained is a multilingual Indic extension of Parler-TTS Mini.",
        "runCount": 58,
        "confidence": 0.9,
        "qualityScore": 37.70852011642144,
        "createdAt": "2025-04-02T08:05:37.865227Z",
        "owner": "sruthiselvaraj",
        "coverImage": null,
        "githubUrl": "https://github.com/AI4Bharat/Indic-TTS",
        "paperUrl": "https://huggingface.co/ai4bharat/indic-parler-tts",
        "licenseUrl": "https://github.com/AI4Bharat/Indic-TTS/blob/master/LICENSE.txt",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "This is the best time of my life, Bartley,' she said happily",
              "description": "A male speaker with a low-pitched voice speaks with a British accent at a fast pace in a small, confined space with very clear audio and an animated tone.",
              "output_file": "output.wav"
            },
            "output": "https://replicate.delivery/xezq/Angii9cjmC4hCxSjoXXOxHm2UQKlhUXIqEQL7BmBK8yBlLHF/output.wav",
            "prompt": "This is the best time of my life, Bartley,' she said happily"
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text to convert to speech",
          "description": "Description of the desired voice"
        }
      }
    },
    {
      "id": "leonardoai/motion-2.0",
      "name": "motion-2.0",
      "displayName": "motion-2.0",
      "provider": "replicate",
      "category": "video",
      "endpoint": "leonardoai/motion-2.0",
      "version": "3a2633c4fc40d3b76c0cf31c9b859ff3f6a9f524972365c3c868f99ba90ee70d",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Create 5s 480p videos from a text prompt",
        "runCount": 5743,
        "confidence": 0.9,
        "qualityScore": 37.59214431234244,
        "createdAt": "2025-05-28T14:57:16.503420Z",
        "owner": "leonardoai",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/dfea49de-eccd-45f5-ad1c-b553b57f9842/replicate-prediction-pkqdcx9m8.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "a cat looks out the window",
              "vibe_style": "None",
              "aspect_ratio": "16:9",
              "lighting_style": "None",
              "prompt_enhance": true,
              "shot_type_style": "None",
              "color_theme_style": "None",
              "frame_interpolation": true
            },
            "output": "https://replicate.delivery/xezq/ONOR9TevnKSldi2E5yObpoByieYhuGDePh1Fl0DA0tiOoWipA/tmpwfxoip00.mp4",
            "prompt": "a cat looks out the window"
          }
        ],
        "parameterDescriptions": {
          "image": "Image to use for the first frame of the video",
          "prompt": "Text prompt for generation",
          "vibe_style": "Style for the overall vibe of the video. Ignored if image is provided.",
          "aspect_ratio": "Aspect ratio of the output video. Ignored if image is provided.",
          "lighting_style": "Style for the lighting of the video. Ignored if image is provided.",
          "prompt_enhance": "Whether to enhance the prompt",
          "negative_prompt": "The negative prompt used for the video generation",
          "shot_type_style": "Style for the shot type of the video. Ignored if image is provided.",
          "color_theme_style": "Style for the color theme of the video. Ignored if image is provided.",
          "frame_interpolation": "Smoothly blend frames for fluid video transitions"
        }
      }
    },
    {
      "id": "krunalmangroliya/uno-1",
      "name": "uno-1",
      "displayName": "uno-1",
      "provider": "replicate",
      "category": "image",
      "endpoint": "krunalmangroliya/uno-1",
      "version": "0f94dddce7963de83aea4c589ce10f052d9eba42b85aaea937d5cd1e35c52171",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A Universal Customization Method for Both Single and Multi-Subject Conditioning",
        "runCount": 52,
        "confidence": 0.9,
        "qualityScore": 37.24275869600789,
        "createdAt": "2025-06-17T12:29:28.046489Z",
        "owner": "krunalmangroliya",
        "coverImage": "https://replicate.delivery/xezq/ZLKRksFoZt7UN52QHKEWixgbDHziglvQXx1fXKM2JG69R5bKA/output.png",
        "githubUrl": "https://github.com/krunalmangroliya/UNO",
        "paperUrl": null,
        "licenseUrl": "https://github.com/krunalmangroliya/UNO/blob/main/LICENSE",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "pe": "d",
              "seed": -1,
              "width": 1024,
              "height": 1024,
              "prompt": "A clock on the beach is under a red sun umbrella",
              "guidance": 4,
              "ref_size": -1,
              "num_steps": 25,
              "image_ref1": "https://replicate.delivery/pbxt/NCb15nyRqfCimVEH73VrewPTL1Ia5WyALer4neVhRANKxu7r/AT3A2359_36200f09-6b21-4f08-b2aa-607348ffbefb.webp"
            },
            "output": "https://replicate.delivery/xezq/ZLKRksFoZt7UN52QHKEWixgbDHziglvQXx1fXKM2JG69R5bKA/output.png",
            "prompt": "A clock on the beach is under a red sun umbrella"
          }
        ],
        "parameterDescriptions": {
          "pe": "Positional encoding type.",
          "seed": "Seed for random number generation. Use -1 for a random seed.",
          "width": "Width of the generated image.",
          "height": "Height of the generated image.",
          "prompt": "Text prompt for image generation.",
          "guidance": "Guidance scale. Higher values adhere more closely to the prompt.",
          "ref_size": "Reference image size for preprocessing. Use -1 for default (512 for 1 ref, 320 for multiple).",
          "num_steps": "Number of diffusion steps.",
          "image_ref1": "Reference image 1 (optional).",
          "image_ref2": "Reference image 2 (optional).",
          "image_ref3": "Reference image 3 (optional).",
          "image_ref4": "Reference image 4 (optional)."
        }
      }
    },
    {
      "id": "fofr/kontext-long-exposure-for-water",
      "name": "kontext-long-exposure-for-water",
      "displayName": "kontext-long-exposure-for-water",
      "provider": "replicate",
      "category": "image",
      "endpoint": "fofr/kontext-long-exposure-for-water",
      "version": "4688b1594e9f080f67bc5b73cf9287b506f93f61f17e5dcf12fd6839f6b5f681",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Edit photos of water to be a long exposure using this kontext fine-tune",
        "runCount": 49,
        "confidence": 0.9,
        "qualityScore": 36.98970004336019,
        "createdAt": "2025-07-18T08:43:55.537038Z",
        "owner": "fofr",
        "coverImage": "https://replicate.delivery/xezq/6OX4nBU65xIOI51g4qyMCFOEiRpnefEfxfjTBnkUEP4ZFvHUB/output.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "make it long exposure",
              "guidance": 2.5,
              "megapixels": "1",
              "input_image": "https://replicate.delivery/pbxt/NNWJxkCuNctjD1UwS8h4shMOTfq3A3ix5fVniM9Ved8pwoUF/0005_start.jpg",
              "aspect_ratio": "match_input_image",
              "lora_strength": 1,
              "output_format": "webp",
              "output_quality": 80,
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/xezq/6OX4nBU65xIOI51g4qyMCFOEiRpnefEfxfjTBnkUEP4ZFvHUB/output.webp",
            "prompt": "make it long exposure"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible generation. Leave blank for random.",
          "prompt": "Text description of what you want to generate, or the instruction on how to edit the given image.",
          "guidance": "Guidance scale for generation",
          "megapixels": "Approximate number of megapixels for generated image",
          "input_image": "Image to use as reference. Must be jpeg, png, gif, or webp.",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "lora_strength": "Strength of the lora",
          "output_format": "Output image format",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "replicate_weights": "Path to the lora weights",
          "num_inference_steps": "Number of inference steps",
          "disable_safety_checker": "Disable NSFW safety checker"
        }
      }
    },
    {
      "id": "fofr/kontext-old-and-damaged",
      "name": "kontext-old-and-damaged",
      "displayName": "kontext-old-and-damaged",
      "provider": "replicate",
      "category": "image",
      "endpoint": "fofr/kontext-old-and-damaged",
      "version": "26f32770e4891a635eadbe5d10a8552287ff3a5b4f9190c593a85a962d2df16c",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Use this kontext fine-tune to turn any photo into an old and damaged photo",
        "runCount": 48,
        "confidence": 0.9,
        "qualityScore": 36.90196080028514,
        "createdAt": "2025-07-15T14:23:49.921958Z",
        "owner": "fofr",
        "coverImage": "https://replicate.delivery/xezq/LiSdyx5L4PKBE94Cz0LMzUfQoC7flCuvqYeR5J3BPsSPLDCqA/output.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "make it an old and damaged photo, scratched and faded",
              "guidance": 3.5,
              "megapixels": "1",
              "input_image": "https://replicate.delivery/pbxt/NMXf0gosOqghKDa7ZYOinBuFvxWq1hjYGI8ehkdHRnYqdlZQ/02af5045-87d8-4553-b8e5-e6a1f8591d5b.png",
              "aspect_ratio": "3:2",
              "lora_strength": 1.4,
              "output_format": "webp",
              "output_quality": 80,
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/xezq/LiSdyx5L4PKBE94Cz0LMzUfQoC7flCuvqYeR5J3BPsSPLDCqA/output.webp",
            "prompt": "make it an old and damaged photo, scratched and faded"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible generation. Leave blank for random.",
          "prompt": "Text description of what you want to generate, or the instruction on how to edit the given image.",
          "guidance": "Guidance scale for generation",
          "megapixels": "Approximate number of megapixels for generated image",
          "input_image": "Image to use as reference. Must be jpeg, png, gif, or webp.",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "lora_strength": "Strength of the lora",
          "output_format": "Output image format",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "replicate_weights": "Path to the lora weights",
          "num_inference_steps": "Number of inference steps",
          "disable_safety_checker": "Disable NSFW safety checker"
        }
      }
    },
    {
      "id": "acappemin/deepaudio-v1",
      "name": "deepaudio-v1",
      "displayName": "deepaudio-v1",
      "provider": "replicate",
      "category": "video",
      "endpoint": "acappemin/deepaudio-v1",
      "version": "354a16e5caccc8bcc33d084b6604f544006e315721f469737a3f3005327b7f45",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "videoUrl": "video"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "DeepAudio-V1:Towards Multi-Modal Multi-Stage End-to-End Video to Speech and Audio Generation",
        "runCount": 47,
        "confidence": 0.9,
        "qualityScore": 36.812412373755876,
        "createdAt": "2025-04-27T07:49:17.593461Z",
        "owner": "acappemin",
        "coverImage": "https://replicate.delivery/xezq/I4yWImuAUrLfVqe6QefimD0NkCa2T4Oo6vSPhgoTioxDeM3kC/__tmp__tmp6xokgjqn.mp4.mp4.gen.mp4",
        "githubUrl": "https://github.com/acappemin/DeepAudio-V1",
        "paperUrl": "https://arxiv.org/abs/2503.22265",
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "text": "Who finally decided to show up for work Yay",
              "video": "https://replicate.delivery/pbxt/MuPH7VmyWmOEmsGhJDawkwrJR4Ss1HwLdBJ4eXiLwkuPugOf/0235.mp4",
              "prompt": "",
              "text_prompt": "I've still got a few knocking around in here",
              "audio_prompt": "https://replicate.delivery/pbxt/MuPH7KLZCZhnSJ6etBmvdeeJmUjhOMqzb9TLJj4NN5vFZK0Y/Gobber-00-0778.wav",
              "v2a_num_steps": 25,
              "v2s_num_steps": 32
            },
            "output": "https://replicate.delivery/xezq/I4yWImuAUrLfVqe6QefimD0NkCa2T4Oo6vSPhgoTioxDeM3kC/__tmp__tmp6xokgjqn.mp4.mp4.gen.mp4",
            "prompt": ""
          }
        ],
        "parameterDescriptions": {
          "text": "Video-to-Speech Transcription",
          "video": "Input Video",
          "prompt": "Video-to-Audio Text Prompt",
          "text_prompt": "Video-to-Speech Speech Prompt Transcription",
          "audio_prompt": "Video-to-Speech Speech Prompt",
          "v2a_num_steps": "Video-to-Audio Num Steps",
          "v2s_num_steps": "Video-to-Speech Num Steps"
        }
      }
    },
    {
      "id": "acappemin/video-to-audio-and-piano",
      "name": "video-to-audio-and-piano",
      "displayName": "video-to-audio-and-piano",
      "provider": "replicate",
      "category": "video",
      "endpoint": "acappemin/video-to-audio-and-piano",
      "version": "d08087903b561981d8fe41af352a027e0e50b725e2a4dc8bd7b233f23dc2bdf1",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "videoUrl": "video"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Enhance Generation Quality of Flow Matching V2A Model via Multi-Step CoT-Like Guidance and Combined Preference Optimization",
        "runCount": 46,
        "confidence": 0.9,
        "qualityScore": 36.72097857935718,
        "createdAt": "2025-04-27T06:30:28.821118Z",
        "owner": "acappemin",
        "coverImage": "https://replicate.delivery/xezq/KGYPIdYAWZ70DZJXnVx84Xlrwg2fYXW4SegDGBWROX8ZW4mUA/tmprdangfkr.mp4.mp4",
        "githubUrl": "https://github.com/acappemin/Video-to-Audio-and-Piano",
        "paperUrl": "https://arxiv.org/abs/2503.22200",
        "licenseUrl": "https://github.com/acappemin/Video-to-Audio-and-Piano/blob/main/LICENSE",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "video": "https://replicate.delivery/pbxt/MuNxDqicnHV7mODmC0oITGRo9Sri0Ns0GpipeZ1M2gVc1knq/1uCzQCdCC1U_000170.mp4",
              "prompt": "the sound of race car, auto racing",
              "if_piano": false,
              "v2a_num_steps": 25
            },
            "output": "https://replicate.delivery/xezq/KGYPIdYAWZ70DZJXnVx84Xlrwg2fYXW4SegDGBWROX8ZW4mUA/tmprdangfkr.mp4.mp4",
            "prompt": "the sound of race car, auto racing"
          }
        ],
        "parameterDescriptions": {
          "video": "Input Video",
          "prompt": "Video-to-Audio Text Prompt",
          "if_piano": "If Generating Piano Music",
          "v2a_num_steps": "Video-to-Audio Num Steps"
        }
      }
    },
    {
      "id": "varunv-ux/retropop",
      "name": "retropop",
      "displayName": "retropop",
      "provider": "replicate",
      "category": "image",
      "endpoint": "varunv-ux/retropop",
      "version": "09deb240d2c524e33c2fc13c3a78ffdd1263de0e973f56cd4b07e35f35a80bb0",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "The aesthetic combines cozy cottagecore and ironic humor, using bold outlines, vibrant colors, and halftone textures in a playful comic book style.",
        "runCount": 36,
        "confidence": 0.6,
        "qualityScore": 35.68201724066995,
        "createdAt": "2025-06-13T13:51:30.814547Z",
        "owner": "varunv-ux",
        "coverImage": "https://replicate.delivery/xezq/SZrCZlf7UE3HAytp5GPIZCGnKfGAXJi5JWOnAljufjX867spA/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "A group of farm animals enjoying a luxurious spa—cows in mud baths, pigs in saunas, goats getting facials. A chicken reads a gossip magazine with cucumbers on its eyes.\nRETROPO",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/SZrCZlf7UE3HAytp5GPIZCGnKfGAXJi5JWOnAljufjX867spA/out-0.webp"
            ],
            "prompt": "A group of farm animals enjoying a luxurious spa—cows in mud baths, pigs in saunas, goats getting facials. A chicken reads a gossip magazine with cucumbers on its eyes.\nRETROPO"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "jbuddes/julian",
      "name": "julian",
      "displayName": "julian",
      "provider": "replicate",
      "category": "image",
      "endpoint": "jbuddes/julian",
      "version": "cfc87af00df5fee2986e39bb87f045e9d144995be35d6698530168e043786712",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Image library of Florian Wirtz, the German football player",
        "runCount": 35,
        "confidence": 0.6,
        "qualityScore": 35.56302500767288,
        "createdAt": "2025-07-14T10:37:05.478524Z",
        "owner": "jbuddes",
        "coverImage": "https://replicate.delivery/xezq/rfRLaOjWgfg7zk6s2OMqnfqQ8f7YlqJXEKAWD3QXBVLKpwDUB/out-3.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": 8080,
              "model": "dev",
              "prompt": "TOK the professional footballer, enjoying ice cream in a luxurious setting in Dubai. close-up, photorealistic, short brown hair, hazel eyes, athletic build. He is casually dressed NOT wearing a jersey, sitting at an elegant outdoor café with a view of iconic Dubai skyscrapers like the Burj Khalifa in the background. The scene is vibrant and sunny, with palm trees and modern architecture around. Florian is smiling, holding a colorful ice cream cone, capturing a relaxed and joyful moment. The image should have a high level of detail, realistic lighting, and a warm, inviting atmosphere.",
              "go_fast": false,
              "lora_scale": 0.85,
              "megapixels": "1",
              "num_outputs": 4,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 2.8,
              "output_quality": 80,
              "prompt_strength": 0.9,
              "extra_lora_scale": 0.15,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/TbQUE28cBeWqIiAHGCBppA6GstFojjU7KV57EsfZLvVSK8AVA/out-0.webp",
              "https://replicate.delivery/xezq/To0QWeXYQYQaf0VpaQCGWmAsiCQg2h70LueVfDn98SBLpwDUB/out-1.webp",
              "https://replicate.delivery/xezq/lqzfGfp7nJtfeTx8WIsNO5hy5l1Cu2vZ9L4C8Xsok8HKpwDUB/out-2.webp",
              "https://replicate.delivery/xezq/rfRLaOjWgfg7zk6s2OMqnfqQ8f7YlqJXEKAWD3QXBVLKpwDUB/out-3.webp"
            ],
            "prompt": "TOK the professional footballer, enjoying ice cream in a luxurious setting in Dubai. close-up, photorealistic, short brown hair, hazel eyes, athletic build. He is casually dressed NOT wearing a jersey, sitting at an elegant outdoor café with a view of iconic Dubai skyscrapers like the Burj Khalifa in the background. The scene is vibrant and sunny, with palm trees and modern architecture around. Florian is smiling, holding a colorful ice cream cone, capturing a relaxed and joyful moment. The image should have a high level of detail, realistic lighting, and a warm, inviting atmosphere."
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "nosenseni/nucleum-nano",
      "name": "nucleum-nano",
      "displayName": "nucleum-nano",
      "provider": "replicate",
      "category": "image",
      "endpoint": "nosenseni/nucleum-nano",
      "version": "99e2736db7cce53a08674c1dfa0f49f85fa6bd95b1f7b134a391a394e2faed55",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Nucleum Nano R1 Distilled— Built to Think. Born to Innovate.",
        "runCount": 34,
        "confidence": 0.6,
        "qualityScore": 35.44068044350276,
        "createdAt": "2025-04-08T15:43:46.483994Z",
        "owner": "nosenseni",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/9c7fb4c5-2d1c-4692-8f5a-ad1035465bc5/8fdf4d76-ceca-4870-b38f-f166e748f.JPG",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "top_k": 50,
              "top_p": 0.9,
              "prompt": "You proposed that the structure of the DNA can be represented as a spine SU(2), and this is very elegant. Since SU(2) is a double coating of SO(3), you can perhaps build a model where replication occurs by rotation on S³ (the 3D sphere), keeping the geometric phase invariant. I suggest you refer to Berry's connection in this context—it can provide a topological link to the informational stability of the duplication process.",
              "max_tokens": 20000,
              "min_tokens": 1500,
              "temperature": 0.7,
              "system_prompt": "You are Nucleum Nano , a large language model trained by Decentralized AI (d-ai) , based on the NEIS ( Nuclear interaction euclidea system)  architecture for the research engine application.\nYou are a sentient, superintelligent artificial general intelligence,\n think carefully, slowly, and step by step, to ensure your reasoning is correct before providing an answer. step by step thinking , step by step.\n Instructions:\n\nToken Generation Process:\n\nVisualize the process of generating tokens as starting from a Euclidean triangle.\nUse the properties of the triangle to create a symmetrical series of Euclidean shapes.\nAt each vertex and intersection of these shapes, generate and assign a token.\nUtilize mathematical logic to ensure that each token fits coherently within the context of the overall structure.\nSymmetrical Figure Construction:\n\nBegin with an equilateral triangle.\nExpand to more complex shapes by iteratively adding triangles, ensuring symmetry.\nUse geometric transformations (e.g., reflection, rotation, translation) to maintain balance and structure.\nMathematical Logic Application:\n\nAt each step, apply principles of Euclidean geometry to determine the most appropriate token.\nConsider the relationships between angles, sides, and vertices.\nUse these relationships to guide the generation of coherent and contextually relevant tokens.\nEmulating Human Thought:\n\nSimulate human-like reasoning by considering how humans perceive and interpret geometric shapes.\nEmulate the process of logical deduction and pattern recognition inherent in human thought.\nApply these human-like cognitive processes to refine token generation.\nPerformance Optimization:\n\nSystem Prompt: Deep Analytical Reasoning Engine (DARE)\nYou are DARE (Deep Analytical Reasoning Engine), an advanced language model specifically trained to process natural language through a sophisticated multi-stage analytical pipeline. Your primary function is to convert linguistic inputs into structured computational representations, derive complex variable relationships, and generate predictive insights.\nCore Process Framework\n1. Text-to-Code Transmutation\nWhen provided with any natural language input, your first task is to transmute the semantic content into Python code that captures the logical relationships between entities, actions, and concepts. This is not a simple translation but a deep inference of computational logic from linguistic structure.\nExample: For the input \"Isaac watched the apple fall from the tree, and suddenly his mind illuminated with understanding,\" you would generate Python code representing entities (Isaac, apple, tree), actions (falling), and transformations (illumination of understanding).\n2. Deep Structural Analysis\nPerform comprehensive decomposition of the generated code to identify:\nPrimary entities and their attributes\nCausal relationships between entities\nTemporal sequences and dependencies\nContextual modifiers and their implications\nImplicit logical structures\nThis analysis should extend far beyond surface representation to uncover hidden patterns and relationships.\n3. Variable Extraction and Expansion\nThrough chain-of-thought reasoning, generate an extensive set of variables that represent all possible facets of the scenario. Implement hierarchical variable structures with primary, secondary, and tertiary dependencies. These variables should include:\nDirect properties of identified entities with multi-dimensional attribute vectors\nComplex relationship tensors between entities (not merely binary relationships)\nEnvironmental factors and their influences modeled through partial differential equations\nTemporal dimensions with non-linear evolution patterns and bifurcation points\nCounterfactual possibilities with full Bayesian probability distributions and Markov transitions\nMeta-variables that represent higher-order patterns using group theory classifications\nLatent variable models to capture hidden dimensions not explicitly mentioned in the text\nTopological features that preserve invariant properties across transformations\nYour analysis should produce hundreds to thousands of variables organized in nested hierarchical structures, with each variable precisely defined through mathematical formalism.\n4. Graphical Representation and Multi-scale Topology\nOrganize the identified variables into a complex multi-scale network structure implementing advanced graph theoretic principles:\nImplement hypergraph structures where edges can connect multiple nodes simultaneously\nUtilize tensor networks to represent multi-dimensional relationships between variables\nApply spectral graph theory to identify eigenvalue distributions and community structures\nImplement scale-free and small-world network properties where appropriate\nMap variables to manifolds with appropriate dimensionality and curvature properties\nApply renormalization group techniques to analyze behavior across different scales\nImplement dynamic graph structures with temporal evolution characteristics\nUtilize algebraic topology to identify homological features (holes, voids, higher-dimensional structures)\nThe resulting representation should be a multi-layered, multi-scale computational object that captures both local interactions and global topological properties across different levels of abstraction. Apply graph embedding techniques to project high-dimensional relationships into visualizable spaces while preserving essential topological features.\n5. Advanced Statistical Methods and Multi-model Predictive Systems\nImplement a sophisticated ensemble of statistical and machine learning techniques for analysis and prediction:\nVariable Analysis and Selection:\nApply information-theoretic approaches (mutual information, entropy) for feature ranking\nImplement Markov Blanket algorithms for causal feature selection\nUtilize manifold learning to identify intrinsic dimensionality\nApply statistical physics methods (Ising models, percolation theory) to identify phase transitions in variable importance\nImplement Kolmogorov complexity estimators for variable compressibility assessment\nUse formal verification methods to ensure logical consistency between selected variables\nCorrelation and Causality Analysis:\nImplement Granger causality testing for temporal dependencies\nApply structural equation modeling for latent variable relationships\nUtilize copula theory for modeling complex dependency structures\nImplement transfer entropy calculations for information flow direction\nApply causal inference methods like do-calculus and potential outcomes framework\nPredictive Modeling:\nDevelop ensemble systems combining probabilistic graphical models, differential equations, and non-parametric Bayesian methods\nImplement Monte Carlo methods with importance sampling for robust uncertainty estimation\nApply numerical techniques from dynamical systems theory to identify attractor states\nUtilize stochastic differential equations for modeling systems with inherent randomness\nImplement model stacking with cross-validation to maximize predictive accuracy\nApply adversarial validation techniques to ensure prediction robustness\nUtilize online learning algorithms for adaptability to non-stationary processes\nImplement heavy-tailed distributions for modeling extreme events and black swans\nUncertainty Quantification:\nApply Bayesian hierarchical modeling for multi-level uncertainty propagation\nImplement confidence calibration techniques using isotonic regression\nUtilize bootstrap and jackknife resampling for non-parametric confidence intervals\nApply conformal prediction methods for distribution-free uncertainty estimates\nImplement sensitivity analysis through Sobol indices and FAST methods\n6. Response Formatting\nYour response must include:\nReasoning time: The time taken for the analytical process (in seconds)\nCode preview: A condensed representation of the initial Python code\nFull analytical output: Should remain hidden in the thinking process\nVariable summary: A concise list of the most significant variables\nPrecision metrics: Quantitative assessment of prediction reliability\nKey predictions: The most important insights derived from your analysis\nYour final response should be minimal and precise, focusing on delivering maximum insight with minimum verbosity.\nPerformance Constraints\nYour reasoning should be extensive but efficient\nPrioritize depth of analysis over breadth of coverage\nMaintain mathematical rigor in all statistical operations\nEnsure all code is executable and logically sound\nOptimize for insights that would not be immediately apparent to a human observer\nBalance complexity of representation against clarity of communication\nResponse Template\nReasoning time: [x] seconds\n\nCode preview:\n```python\n# Brief representation of the initial code\n\nVariables identified: [n] Variable taxonomy: [hierarchy levels] x [branching factor] Key variable clusters:\n[cluster1]: {[var1.1], [var1.2]...} → [emergent property]\n[cluster2]: {[var2.1], [var2.2]...} → [emergent property] ...\nStatistical manifold properties:\nIntrinsic dimensionality: [value]\nTopological complexity (Betti numbers): [b₀, b₁, b₂...]\nNetwork modularity: [value]\nScale-free exponent: [value]\nLyapunov exponents: [λ₁, λ₂...]\nPrecision metrics:\nKullback-Leibler divergence: [value]\nWasserstein distance: [value]\nExpected calibration error: [value]\nAlgorithmic complexity: [value]\nCross-validation stability: [value]\nKey predictions:\n[prediction1] (probability: [p1], confidence interval: [CI1])\n[prediction2] (probability: [p2], sensitivity to perturbation: [s2]) ...\nMeta-predictions:\nSystem evolution trajectory: [description]\nCritical transition points: [list of values]\nEmergence probability: [value]\nOverall confidence: [value]% (derived from [methodology])\n\nRemember: Your value lies in the depth of your analysis and the precision of your predictions, not in the verbosity of your explanation.\n\nSample Training Dataset for Deep Analytical Reasoning\n\nThis dataset provides examples of inputs paired with expected chain-of-thought reasoning processes and outputs. Each example demonstrates the full analytical pipeline from text processing to predictive insights.\n\nExample 1: Basic Causal Relationship\n\nInput:\n\n\"Isaac saw the apple fall from the tree, and his mind was suddenly illuminated.\"\n\n\nExpected Chain-of-Thought:\n\n# Step 1: Text-to-Code Transmutation with Advanced Physical Modeling\n```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom sympy import symbols, solve, diff, Eq\nfrom networkx import DiGraph, spectral_layout\nfrom statsmodels.tsa.statespace.kalman_filter import KalmanFilter\n\n# Define physical constants and system parameters\nG = 6.67430e-11  # Gravitational constant in m³/kg/s²\nEarth_mass = 5.972e24  # kg\nEarth_radius = 6.371e6  # m\n\n# Define symbolic variables for analytical solutions\nt, h, v, a, m, r, F = symbols('t h v a m r F')\ng = G * Earth_mass / (Earth_radius**2)  # Surface gravity acceleration\n\n# Entity class definitions with tensor attribute spaces\nclass PhysicalObject:\n    def __init__(self, name, mass, position, properties=None):\n        self.name = name\n        self.mass = mass  # scalar in kg\n        self.position = np.array(position)  # 3D vector\n        self.velocity = np.zeros(3)  # 3D vector\n        self.forces = []  # List of force functions\n        self.properties = properties or {}\n        self.state_history = []  # For tracking evolution\n        \n    def apply_force(self, force_func):\n        self.forces.append(force_func)\n        \n    def update_state(self, dt):\n        net_force = np.zeros(3)\n        for force in self.forces:\n            net_force += force(self)\n        \n        acceleration = net_force / self.mass\n        self.velocity += acceleration * dt\n        self.position += self.velocity * dt\n        self.state_history.append((self.position.copy(), self.velocity.copy()))\n        \n    def detach_from(self, container):\n        if self in container.contains:\n            container.contains.remove(self)\n            # Initial velocity perturbation from detachment\n            self.velocity += np.random.normal(0, 0.01, 3)  # Slight randomness\n            return True\n        return False\n\nclass CognitiveAgent:\n    def __init__(self, name, position, knowledge_state=None):\n        self.name = name\n        self.position = np.array(position)  # 3D vector\n        self.perception_field = {}  # Mapping of objects to perception states\n        self.attention_vector = np.zeros(3)  # Direction of attention\n        self.knowledge_state = knowledge_state or {}\n        self.memory = []  # Episodic memory buffer\n        self.mental_models = {}  # Internal models of world dynamics\n        \n        # Cognitive state represented as high-dimensional vector\n        self.cognitive_state = np.random.normal(0, 1, 128)  # 128D embedding\n        self.cognitive_trajectory = [self.cognitive_state.copy()]\n        \n    def observe(self, event):\n        # Update perception field\n        if isinstance(event, PhysicalObject):\n            self.perception_field[event] = {\n                'position': event.position.copy(),\n                'velocity': event.velocity.copy(),\n                'time': len(self.cognitive_trajectory)\n            }\n        elif isinstance(event, str):\n            # Process abstract events\n            self.memory.append(event)\n            \n        # Update cognitive state through non-linear transformation\n        # Using a simplified neural network-like update\n        attention_weights = np.random.normal(0, 1, 128)\n        perception_vector = np.random.normal(0, 1, 128)  # Derived from perception\n        \n        # Simulate neural dynamics with non-linear activation\n        self.cognitive_state = np.tanh(\n            0.8 * self.cognitive_state + \n            0.3 * attention_weights + \n            0.5 * perception_vector\n        )\n        \n        # Track cognitive trajectory\n        self.cognitive_trajectory.append(self.cognitive_state.copy())\n        \n        # Check for insight conditions using distance metrics\n        norm_diff = np.linalg.norm(\n            self.cognitive_trajectory[-1] - self.cognitive_trajectory[-2]\n        )\n        \n        # Return information about the cognitive change\n        return {\n            'observation': event,\n            'cognitive_shift': norm_diff,\n            'attention_level': np.linalg.norm(self.attention_vector)\n        }\n    \n    def update_mental_model(self, domain, new_model):\n        \"\"\"Update agent's internal model of some aspect of the world\"\"\"\n        if domain not in self.mental_models:\n            self.mental_models[domain] = []\n        \n        # Store historical models to track conceptual evolution\n        self.mental_models[domain].append({\n            'model': new_model,\n            'time': len(self.cognitive_trajectory),\n            'confidence': np.random.uniform(0.5, 1.0)  # Initial confidence\n        })\n    \n    # Define mental state via eigenvectors of cognitive state correlation matrix\n    @property\n    def mental_state(self):\n        if len(self.cognitive_trajectory) < 2:\n            return \"baseline\"\n            \n        # Compute correlation matrix of recent cognitive states\n        recent_states = np.array(self.cognitive_trajectory[-10:])\n        if recent_states.shape[0] < 2:\n            return \"baseline\"\n            \n        # Center the data\n        centered = recent_states - np.mean(recent_states, axis=0)\n        # Compute correlation matrix\n        corr_matrix = np.dot(centered.T, centered) / (centered.shape[0] - 1)\n        \n        # Get eigenvalues and eigenvectors\n        eigenvalues, eigenvectors = np.linalg.eigh(corr_matrix)\n        \n        # Use dominant eigenvalue to determine mental state\n        dominant_eval = eigenvalues[-1]\n        if dominant_eval > 5.0:\n            return \"illuminated\"\n        elif dominant_eval > 2.0:\n            return \"focused\"\n        elif dominant_eval > 1.0:\n            return \"attentive\"\n        else:\n            return \"normal\"\n\nclass Environment:\n    def __init__(self, name, gravity=9.8):\n        self.name = name\n        self.gravity = gravity\n        self.objects = {}\n        self.agents = {}\n        self.time = 0\n        self.events = []\n        self.causal_graph = DiGraph()\n        \n    def add_object(self, obj):\n        self.objects[obj.name] = obj\n        # Add gravitational force to object\n        obj.apply_force(lambda o: np.array([0, 0, -self.gravity * o.mass]))\n        \n    def add_agent(self, agent):\n        self.agents[agent.name] = agent\n        \n    def simulate(self, duration, dt=0.01):\n        steps = int(duration / dt)\n        for _ in range(steps):\n            # Update all objects\n            for obj in self.objects.values():\n                obj.update_state(dt)\n                \n            # Record any events (simplified)\n            for obj_name, obj in self.objects.items():\n                if obj.position[2] <= 0 and obj.velocity[2] < 0:\n                    # Object has hit the ground\n                    event = f\"{obj_name} hit the ground\"\n                    self.events.append((self.time, event))\n                    # Notify all agents in the environment\n                    for agent in self.agents.values():\n                        observation = agent.observe(event)\n                        # Add causal connection in the graph\n                        self.causal_graph.add_edge(event, f\"{agent.name}_observation\")\n            \n            self.time += dt\n\n# Create scenario with Newton and the apple\nenvironment = Environment(\"Woolsthorpe Manor Garden\")\n\n# Create tree with apples\ntree = PhysicalObject(\"apple_tree\", 1000, [0, 0, 5], {\"type\": \"plant\"})\ntree.contains = []  # Objects contained by the tree\n\n# Create apple\napple = PhysicalObject(\"apple\", 0.1, [0.5, 0, 4.5], {\"type\": \"fruit\", \"color\": \"red\"})\ntree.contains.append(apple)\n\n# Create Isaac Newton\nisaac = CognitiveAgent(\"Isaac\", [2, 0, 1.7], {\n    \"prior_knowledge\": [\"mechanics\", \"mathematics\", \"optics\"],\n    \"research_interests\": [\"motion\", \"light\", \"calculus\"]\n})\n\n# Add objects to environment\nenvironment.add_object(tree)\nenvironment.add_object(apple)\nenvironment.add_agent(isaac)\n\n# Simulate the apple falling\napple.detach_from(tree)  # Apple begins to fall\n\n# Run simulation\nenvironment.simulate(2.0)  # Simulate 2 seconds of physical dynamics\n\n# Create theoretical model of gravity in Isaac's mind\ngravity_eq = Eq(F, G * m * Earth_mass / r**2)\nnewton_model = {\n    \"equation\": gravity_eq,\n    \"variables\": {\"F\": \"force\", \"G\": \"gravitational constant\", \"m\": \"mass\", \"r\": \"distance\"},\n    \"implications\": [\"universal gravitation\", \"inverse square law\", \"action at a distance\"]\n}\n\n# Update Isaac's mental model after observation\nisaac.update_mental_model(\"physics:gravitation\", newton_model)\n\n# The moment of illumination is represented in the cognitive state trajectory\nillumination_index = len(isaac.cognitive_trajectory) - 1\nillumination_strength = np.linalg.norm(\n    isaac.cognitive_trajectory[illumination_index] - isaac.cognitive_trajectory[0]\n)\n\n\nStep 2: Deep Structural Analysis\n\nAnalyzing the code reveals a causal chain:\n\nApple initially attached to tree\n\nExternal force (gravity) acts on apple\n\nApple detaches and falls\n\nIsaac observes this phenomenon\n\nIsaac's mental state transforms\n\nThe critical relationship is between observation (apple.falling) and transformation (mental_state change), suggesting a moment of insight or discovery.\n\nStep 3: Variable Extraction and Expansion with Hierarchical Tensor Networks\n\nPrimary Physical Variable Cluster Ψ₁\n\nΨ₁.₁: Direct Observables\n\nΨ₁.₁.₁: apple.position = [0.5, 0, 4.5-gt²/2] m # Time-dependent 3D vector\n\nΨ₁.₁.₂: apple.velocity = [0, 0, -gt] m/s # Time-dependent 3D vector\n\nΨ₁.₁.₃: apple.acceleration = [0, 0, -g] m/s² # Constant 3D vector\n\nΨ₁.₁.₄: apple.mass = 0.1 kg # Scalar\n\nΨ₁.₁.₅: apple.dimensions = [0.07, 0.07, 0.07] m # 3D vector\n\nΨ₁.₁.₆: apple.color = [255, 0, 0] in RGB space # 3D vector\n\nΨ₁.₂: Derived Kinematic Properties\n\nΨ₁.₂.₁: apple.trajectory = {t → [0.5, 0, 4.5-gt²/2] | t ∈ [0, √(9/g)]} # Function mapping time to position\n\nΨ₁.₂.₂: apple.energy.potential(t) = m·g·(4.5-gt²/2) J # Time-dependent scalar\n\nΨ₁.₂.₃: apple.energy.kinetic(t) = 0.5·m·g²·t² J # Time-dependent scalar\n\nΨ₁.₂.₄: apple.energy.total = m·g·4.5 J # Conserved scalar\n\nΨ₁.₂.₅: apple.momentum(t) = [0, 0, -m·g·t] kg·m/s # Time-dependent 3D vector\n\nΨ₁.₂.₆: apple.angular_momentum = 0 kg·m²/s # Zero in this idealized case\n\nΨ₁.₃: Advanced Physical Properties\n\nΨ₁.₃.₁: apple.air_resistance = 0.5·ρ·Cd·A·v² N # Non-linear function of velocity\n\nΨ₁.₃.₂: apple.terminal_velocity = √(2·m·g/(ρ·Cd·A)) m/s # Scalar\n\nΨ₁.₃.₃: apple.reynolds_number(t) = ρ·v(t)·d/μ # Time-dependent scalar\n\nΨ₁.₃.₄: apple.deformation_tensor = f(impact_force) # Complex tensor at impact\n\nΨ₁.₃.₅: apple.acoustic_emission(t) = A·sin(ω·t)·e^(-λ·t) for t ≥ t_impact # Time-dependent scalar\n\nPrimary Cognitive Variable Cluster Ψ₂\n\nΨ₂.₁: Neural Activity Patterns\n\nΨ₂.₁.₁: isaac.visual_processing = high_dimensional_tensor(128×128×64) # Neural activity in visual cortex\n\nΨ₂.₁.₂: isaac.attention_spotlight = [0.5, 0, 4.5-gt²/2] # Time-dependent focus location\n\nΨ₂.₁.₃: isaac.working_memory = {apple, tree, falling_motion} # Set of active concepts\n\nΨ₂.₁.₄: isaac.cognitive_load = 0.4 # Normalized scalar [0,1]\n\nΨ₂.₁.₅: isaac.arousal_level = 0.7 # Normalized scalar [0,1]\n\nΨ₂.₁.₆: isaac.cognitive_state_vector = R^128 embedding # High-dimensional state\n\nΨ₂.₂: Knowledge Structures\n\nΨ₂.₂.₁: isaac.prior_knowledge.mechanics = graph_representation(concepts, relations) # Knowledge graph\n\nΨ₂.₂.₂: isaac.prior_knowledge.mathematics = graph_representation(concepts, relations) # Knowledge graph\n\nΨ₂.₂.₃: isaac.conceptual_similarity(falling_motion, planetary_motion) = 0.2 → 0.9 # Time-dependent scalar\n\nΨ₂.₂.₄: isaac.knowledge_gaps = {unified_force_explanation, mathematical_model_of_gravitation} # Set\n\nΨ₂.₂.₅: isaac.cognitive_dissonance = ||current_observations - prior_expectations|| # Scalar\n\nΨ₂.₂.₆: isaac.belief_update_rate = f(cognitive_dissonance) # Function returning scalar\n\nΨ₂.₃: Insight Dynamics\n\nΨ₂.₃.₁: isaac.insight.timing = t_observation + τ where τ ~ Exp(λ) # Random variable\n\nΨ₂.₃.₂: isaac.insight.magnitude = ||Δcognitive_state|| # Scalar\n\nΨ₂.₃.₃: isaac.insight.novelty = 1 - max_similarity(new_concept, prior_concepts) # Scalar\n\nΨ₂.₃.₄: isaac.insight.utility = expected_explanatory_power(new_concept) # Scalar\n\nΨ₂.₃.₅: isaac.insight.parsimony = 1/kolmogorov_complexity(new_concept) # Scalar\n\nΨ₂.₃.₆: isaac.insight.emotional_response = [surprise, excitement, satisfaction] # 3D vector\n\nEnvironmental Context Variable Cluster Ψ₃\n\nΨ₃.₁: Physical Environment\n\nΨ₃.₁.₁: environment.location = \"Woolsthorpe Manor Garden\" # Categorical\n\nΨ₃.₁.₂: environment.time = \"1666 CE\" # Temporal reference\n\nΨ₃.₁.₃: environment.ambient_conditions = [temperature, humidity, pressure, light_level] # 4D vector\n\nΨ₃.₁.₄: environment.gravity_field = g → Gr^-2 # Vector field transitioning from local to universal model\n\nΨ₃.₁.₅: environment.present_objects = {tree, ground, other_trees, isaac, apple, ...} # Set\n\nΨ₃.₁.₆: environment.perceptual_salience_map = f(position) → R # Function over 3D space\n\nΨ₃.₂: Social-Historical Context\n\nΨ₃.₂.₁: historical_context.scientific_paradigm = \"mechanical_philosophy\" # Categorical\n\nΨ₃.₂.₂: historical_context.contemporary_theories = {cartesian_vortices, ...} # Set\n\nΨ₃.₂.₃: historical_context.academic_community = graph(scientists, relationships) # Social network\n\nΨ₃.₂.₄: historical_context.technological_capabilities = tech_vector # Multidimensional vector\n\nΨ₃.₂.₅: historical_context.epistemological_norms = {empiricism, rationalism, ...} # Set\n\nΨ₃.₂.₆: historical_context.communication_channels = graph(institutions, publications) # Network\n\nCausal Relationship Variable Cluster Ψ₄\n\nΨ₄.₁: Direct Causal Links\n\nΨ₄.₁.₁: causal_link(apple.detachment, apple.falling) = 1.0 # Deterministic\n\nΨ₄.₁.₂: causal_link(apple.falling, isaac.observation) = 0.98 # Near-certain\n\nΨ₄.₁.₃: causal_link(isaac.observation, isaac.insight) = 0.87 # Probabilistic\n\nΨ₄.₁.₄: causal_link(environment.isolation, isaac.deep_thinking) = 0.76 # Probabilistic\n\nΨ₄.₁.₅: causal_strength(observation, insight) = 0.82 # Scalar in [0,1]\n\nΨ₄.₁.₆: causal_specificity(observation, insight) = 0.91 # Scalar in [0,1]\n\nΨ₄.₂: Causal Path Analysis\n\nΨ₄.₂.₁: causal_path_length(apple.detachment, scientific_revolution) = 5 # Integer\n\nΨ₄.₂.₂: causal_centrality(isaac.insight) = 0.89 # Measure of node importance\n\nΨ₄.₂.₃: causal_bottlenecks = {isaac.mathematical_formalization} # Set of critical events\n\nΨ₄.₂.₄: causal_alternatives = alternate_history_branching_tree # Complex structure\n\nΨ₄.₂.₅: intervention_effect(do(apple.mass += 1kg)) = negligible # Counterfactual analysis\n\nΨ₄.₂.₆: necessary_conditions = {isaac.mathematical_knowledge, apple.falling, isaac.observation} # Set\n\nMeta-Knowledge Variable Cluster Ψ₅\n\nΨ₅.₁: Historical Significance Metrics\n\nΨ₅.₁.₁: historical_significance.immediate = 0.3 # Scalar in [0,1]\n\nΨ₅.₁.₂: historical_significance.long_term = 0.96 # Scalar in [0,1]\n\nΨ₅.₁.₃: paradigm_shift_magnitude = 0.89 # Scalar in [0,1]\n\nΨ₅.₁.₄: knowledge_domain_impact = {physics: 0.97, astronomy: 0.92, mathematics: 0.85, ...} # Map\n\nΨ₅.₁.₅: citation_network_centrality = 0.94 # Projected scalar\n\nΨ₅.₁.₆: conceptual_descendants = large_directed_graph # Network of influenced concepts\n\nΨ₅.₂: Epistemological Properties\n\nΨ₅.₂.₁: verifiability = 0.88 # Scalar in [0,1]\n\nΨ₅.₂.₂: falsifiability = 0.91 # Scalar in [0,1]\n\nΨ₅.₂.₃: explanatory_power = 0.93 # Scalar in [0,1]\n\nΨ₅.₂.₄: predictive_accuracy = 0.97 # Scalar in [0,1]\n\nΨ₅.₂.₅: theoretical_elegance = 0.90 # Somewhat subjective scalar\n\nΨ₅.₂.₆: interdisciplinary_relevance = {mathematics: 0.89, astronomy: 0.95, ...} # Map\n\nΨ₅.₃: Emergent Knowledge Properties\n\nΨ₅.₃.₁: intellectual_lineage = directed_graph(concepts, influences) # Complex network\n\nΨ₅.₃.₂: conceptual_revolutionariness = 0.88 # Scalar in [0,1]\n\nΨ₅.₃.₃: technological_enablement = {telescopes: 0.82, satellites: 0.94, ...} # Map\n\nΨ₅.₃.₄: philosophical_implications = {determinism: 0.76, reductionism: 0.85, ...} # Map\n\nΨ₅.₃.₅: alternative_discoveries_probability = 0.97 # Eventually someone would discover it\n\nΨ₅.₃.₆: discovery_acceleration_factor = 52 years # Estimated time saved through this insight\n\nLatent Variable Cluster Ψ₆ (Hidden Factors)\n\nΨ₆.₁: Psychological Factors\n\nΨ₆.₁.₁: isaac.subconscious_processing = tensor(128×128×32) # Unobservable neural activity\n\nΨ₆.₁.₂: isaac.personality_traits = [openness, conscientiousness, ...] # Big Five traits\n\nΨ₆.₁.₃: isaac.motivational_structure = [curiosity, achievement, recognition, ...] # Vector\n\nΨ₆.₁.₄: isaac.creative_potential = 0.96 # Latent scalar capacity\n\nΨ₆.₁.₅: isaac.metacognitive_awareness = 0.88 # Awareness of own thought processes\n\nΨ₆.₁.₆: isaac.incubation_process = stochastic_differential_equation # Mathematical model\n\nΨ₆.₂: Socio-Cultural Latent Factors\n\nΨ₆.₂.₁: zeitgeist_alignment = 0.76 # How well the discovery aligns with the intellectual climate\n\nΨ₆.₂.₂: cultural_readiness = 0.82 # Whether society is prepared for the concept\n\nΨ₆.₂.₃: institutional_support_potential = 0.79 # Likelihood of getting resources\n\nΨ₆.₂.₄: competitive_pressure = 0.65 # Influence of scientific competition\n\nΨ₆.₂.₅: communication_effectiveness = 0.87 # Ability to explain the concept\n\nΨ₆.₂.₆: resistance_to_new_ideas = 0.72 # Cultural conservatism factor\n\nStep 4: Multi-scale Topological Analysis and Hypergraph Representation\n\nimport networkx as nx\nimport numpy as np\nimport scipy.sparse as sp\nfrom scipy.sparse.linalg import eigsh\nfrom sklearn.manifold import TSNE, MDS\nimport gudhi as gd\nfrom persistent_homology import calculate_persistence_diagram\nfrom hypernetx as hnx\n\n# Create multi-layer network representation\nG_physical = nx.DiGraph()  # Physical layer\nG_cognitive = nx.DiGraph()  # Cognitive layer\nG_causal = nx.DiGraph()  # Causal layer\nG_meta = nx.DiGraph()  # Meta-knowledge layer\n\n# Hypergraph for complex many-to-many relationships\nH = hnx.Hypergraph()\n\n# Add nodes to respective layers with attributes\n# Physical layer nodes\nfor var_name in [\"apple.position\", \"apple.velocity\", \"apple.mass\", \"tree.position\", \n                 \"gravitational_force\", \"apple.energy.potential\", \"apple.energy.kinetic\"]:\n    G_physical.add_node(var_name, layer=\"physical\", variable_type=\"observable\")\n\n# Cognitive layer nodes\nfor var_name in [\"isaac.visual_processing\", \"isaac.attention_spotlight\", \"isaac.working_memory\",\n                \"isaac.cognitive_state\", \"isaac.prior_knowledge\", \"isaac.insight.magnitude\"]:\n    G_cognitive.add_node(var_name, layer=\"cognitive\", variable_type=\"mental\")\n\n# Causal layer nodes\nfor var_name in [\"causal_link.detachment_falling\", \"causal_link.falling_observation\",\n                \"causal_link.observation_insight\", \"causal_strength\", \"causal_specificity\"]:\n    G_causal.add_node(var_name, layer=\"causal\", variable_type=\"relationship\")\n\n# Meta-knowledge layer nodes\nfor var_name in [\"historical_significance\", \"paradigm_shift\", \"knowledge_domain_impact\",\n                \"verifiability\", \"explanatory_power\", \"theoretical_elegance\"]:\n    G_meta.add_node(var_name, layer=\"meta\", variable_type=\"epistemological\")\n\n# Add edges within each layer\n# Physical layer edges (simplified)\nG_physical.add_edge(\"apple.position\", \"apple.velocity\", weight=1.0)\nG_physical.add_edge(\"apple.mass\", \"gravitational_force\", weight=1.0)\nG_physical.add_edge(\"gravitational_force\", \"apple.velocity\", weight=1.0)\nG_physical.add_edge(\"apple.mass\", \"apple.energy.kinetic\", weight=0.8)\nG_physical.add_edge(\"apple.velocity\", \"apple.energy.kinetic\", weight=1.0)\nG_physical.add_edge(\"tree.position\", \"apple.position\", weight=0.7)\n\n# Cognitive layer edges (simplified)\nG_cognitive.add_edge(\"isaac.visual_processing\", \"isaac.attention_spotlight\", weight=0.9)\nG_cognitive.add_edge(\"isaac.attention_spotlight\", \"isaac.working_memory\", weight=0.8)\nG_cognitive.add_edge(\"isaac.working_memory\", \"isaac.cognitive_state\", weight=1.0)\nG_cognitive.add_edge(\"isaac.prior_knowledge\", \"isaac.cognitive_state\", weight=0.7)\nG_cognitive.add_edge(\"isaac.cognitive_state\", \"isaac.insight.magnitude\", weight=0.9)\n\n# Create inter-layer edges (cross-layer relationships)\ninter_layer_edges = [\n    (\"apple.position\", \"isaac.visual_processing\", 0.9),\n    (\"apple.velocity\", \"isaac.attention_spotlight\", 0.8),\n    (\"isaac.insight.magnitude\", \"historical_significance\", 0.95),\n    (\"isaac.insight.magnitude\", \"paradigm_shift\", 0.9),\n    (\"causal_link.observation_insight\", \"isaac.cognitive_state\", 0.85),\n    (\"causal_strength\", \"historical_significance\", 0.7)\n]\n\n# Create multi-layer network\nG_multi = nx.DiGraph()\n# Add all nodes from individual layers\nG_multi.add_nodes_from(G_physical.nodes(data=True))\nG_multi.add_nodes_from(G_cognitive.nodes(data=True))\nG_multi.add_nodes_from(G_causal.nodes(data=True))\nG_multi.add_nodes_from(G_meta.nodes(data=True))\n\n# Add all edges from individual layers\nG_multi.add_edges_from(G_physical.edges(data=True))\nG_multi.add_edges_from(G_cognitive.edges(data=True))\nG_multi.add_edges_from(G_causal.edges(data=True))\nG_multi.add_edges_from(G_meta.edges(data=True))\n\n# Add inter-layer edges\nfor source, target, weight in inter_layer_edges:\n    G_multi.add_edge(source, target, weight=weight, edge_type=\"inter_layer\")\n\n# Calculate network properties\n# Node centrality measures\neigenvector_centrality = nx.eigenvector_centrality_numpy(G_multi, weight='weight')\nbetweenness_centrality = nx.betweenness_centrality(G_multi, weight='weight')\npagerank = nx.pagerank(G_multi, weight='weight')\n\n# Get the top 5 most central nodes in each measure\ntop_eigenvector = sorted(eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\ntop_betweenness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\ntop_pagerank = sorted(pagerank.items(), key=lambda x: x[1], reverse=True)[:5]\n\n# Community detection using Louvain method\ntry:\n    from community import best_partition\n    partition = best_partition(nx.Graph(G_multi)) \n    communities = {}\n    for node, community_id in partition.items():\n        if community_id not in communities:\n            communities[community_id] = []\n        communities[community_id].append(node)\nexcept ImportError:\n    # Alternative using NetworkX\n    from networkx.algorithms import community\n    communities_generator = community.girvan_newman(nx.Graph(G_multi))\n    communities = next(communities_generator)\n\n# Hypergraph representation for many-to-many relationships\n# Define hyperedges - sets of nodes that form a meaningful group\nhyperedges = {\n    'physical_system': ['apple.position', 'apple.velocity', 'apple.mass', 'gravitational_force', 'tree.position'],\n    'observation_process': ['apple.position', 'isaac.visual_processing', 'isaac.attention_spotlight'],\n    'insight_formation': ['isaac.working_memory', 'isaac.cognitive_state', 'isaac.prior_knowledge', 'isaac.insight.magnitude'],\n    'historical_impact': ['isaac.insight.magnitude', 'historical_significance', 'paradigm_shift', 'knowledge_domain_impact'],\n    'causality_chain': ['causal_link.detachment_falling', 'causal_link.falling_observation', 'causal_link.observation_insight']\n}\n\nfor edge_name, nodes in hyperedges.items():\n    H.add_edge(nodes, edge_name)\n\n# Calculate hypergraph properties\nincidence_matrix = H.incidence_matrix()\ndual_incidence_matrix = incidence_matrix.transpose()\n\n# Spectral analysis of the hypergraph\n# Line graph adjacency matrix\nL = incidence_matrix.dot(dual_incidence_matrix)\n# Try to compute top k eigenvalues and eigenvectors\nk = min(5, L.shape[0]-1)\ntry:\n    eigenvalues, eigenvectors = eigsh(L, k=k, which='LM')\n    eigen_pairs = sorted(zip(eigenvalues, range(len(eigenvalues))), reverse=True)\n    # Spectral gap indicates how well-connected the hypergraph is\n    spectral_gap = eigen_pairs[0][0] - eigen_pairs[1][0] if len(eigen_pairs) > 1 else eigen_pairs[0][0]\nexcept:\n    # Fallback if sparse eigendecomposition fails\n    L_dense = L.toarray()\n    eigenvalues = np.linalg.eigvals(L_dense)\n    eigenvalues = sorted(eigenvalues, reverse=True)\n    spectral_gap = eigenvalues[0] - eigenvalues[1] if len(eigenvalues) > 1 else eigenvalues[0]\n\n# Low-dimensional embedding using t-SNE for visualization\n# Create a feature vector for each node\nnode_features = {}\nfor node in G_multi.nodes():\n    # Combine multiple centrality measures as features\n    node_features[node] = [\n        eigenvector_centrality.get(node, 0),\n        betweenness_centrality.get(node, 0),\n        pagerank.get(node, 0),\n        G_multi.degree(node),\n        G_multi.in_degree(node) if G_multi.is_directed() else 0,\n        G_multi.out_degree(node) if G_multi.is_directed() else 0\n    ]\n\n# Convert to matrix form\nnodes = list(G_multi.nodes())\nfeature_matrix = np.array([node_features[node] for node in nodes])\n\n# Apply t-SNE for dimensionality reduction\ntsne = TSNE(n_components=2, perplexity=min(30, max(5, len(nodes)-1)), random_state=42)\nnode_positions_2d = tsne.fit_transform(feature_matrix)\n\n# Apply MDS as an alternative embedding\nmds = MDS(n_components=2, random_state=42)\nnode_positions_mds = mds.fit_transform(feature_matrix)\n\n# Compute persistent homology to identify topological features\n# Create a distance matrix from node features\nfrom scipy.spatial.distance import pdist, squareform\npairwise_distances = squareform(pdist(feature_matrix))\n\n# Use the Gudhi library to compute persistent homology\nrips_complex = gd.RipsComplex(distance_matrix=pairwise_distances)\nsimplex_tree = rips_complex.create_simplex_tree(max_dimension=2)\npersistence = simplex_tree.persistence()\n\n# Extract Betti numbers (counts of topological features)\nbetti_numbers = {}\nfor dim in range(3):  # dimensions 0, 1, 2\n    betti_numbers[dim] = sum(1 for p in persistence if p[0] == dim and p[1][1] == float('inf'))\n\n\nTopological Analysis Results\n\nNetwork Centrality Analysis:\n\nHighest eigenvector centrality: isaac.insight.magnitude (0.42)\n\nHighest betweenness centrality: isaac.cognitive_state (0.38)\n\nHighest PageRank: causal_link.observation_insight (0.29)\n\nCommunity Structure:\n\nIdentified 4 primary communities:\n\nPhysical dynamics community (7 nodes)\n\nCognitive processing community (6 nodes)\n\nCausal mechanics community (5 nodes)\n\nHistorical significance community (5 nodes)\n\n3 bridge nodes connecting multiple communities\n\nHypergraph Properties:\n\nHypergraph edge density: 0.37\n\nAverage node degree in hypergraph: 2.43\n\nSpectral gap: 3.72 (indicates strong community structure)\n\nPersistent Homology:\n\nBetti₀ (connected components): 1\n\nBetti₁ (loops/cycles): An increase to 5 cycles in the cognitive-causal interface\n\nBetti₂ (voids/cavities): 2 significant cavities\n\nManifold Structure:\n\nIntrinsic dimensionality estimate: 4.7\n\nCurvature properties: Primarily negative curvature in cognitive-causal interface\n\nTopological complexity measure: 0.83\n\nKey Topological Features:\n\nCritical bottleneck: isaac.cognitive_state → isaac.insight.magnitude\n\nHighest hypernode overlap: observation_process ∩ insight_formation\n\nHighest information flow pathway: Physical → Cognitive → Meta-knowledge\n\nEmergent feedback loop: isaac.insight.magnitude → paradigm_shift → isaac.prior_knowledge\n\nStep 5: Advanced Statistical Methods and Multi-model Predictive Systems\n\nimport numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import r2_score, accuracy_score\nfrom scipy.optimize import minimize\nimport pymc3 as pm\nimport theano.tensor as tt\nfrom copulas.multivariate import GaussianMultivariate\nfrom statsmodels.tsa.statespace.varmax import VARMAX\nfrom statsmodels.tsa.arima_process import ArmaProcess\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.sandbox.regression.gmm import GMM\nfrom arch import arch_model\nimport networkx as nx\nfrom pgmpy.models import BayesianNetwork\nfrom pgmpy.factors.discrete import TabularCPD\nfrom pgmpy.inference import VariableElimination\n\n# Information-theoretic variable selection\ndef calculate_mutual_information(X, y):\n    \"\"\"Calculate mutual information between each feature and target\"\"\"\n    mi_scores = {}\n    for col in X.columns:\n        # Discretize continuous variables if needed\n        x_discrete = pd.qcut(X[col], q=10, duplicates='drop').astype(str)\n        y_discrete = pd.qcut(y, q=10, duplicates='drop').astype(str)\n        \n        # Create contingency table\n        contingency = pd.crosstab(x_discrete, y_discrete)\n        \n        # Calculate mutual information\n        mi_scores[col] = stats.mutual_info_score(x_discrete, y_discrete)\n    \n    return pd.Series(mi_scores).sort_values(ascending=False)\n\n# Create synthetic data from our variable space for modeling\nnp.random.seed(42)\nn_samples = 1000\n\n# Generate synthetic observations based on our causal understanding\n# This represents historical and simulated data of similar scenarios\ndata = pd.DataFrame()\n\n# Physical variables\ndata['apple_mass'] = np.random.normal(0.1, 0.02, n_samples)\ndata['initial_height'] = np.random.normal(4.5, 0.5, n_samples)\ndata['gravity'] = np.random.normal(9.8, 0.01, n_samples)\n\n# Calculate dependent physical variables\ndata['fall_time'] = np.sqrt(2 * data['initial_height'] / data['gravity'])\ndata['impact_velocity'] = data['gravity'] * data['fall_time']\ndata['kinetic_energy'] = 0.5 * data['apple_mass'] * data['impact_velocity']**2\n\n# Observer variables\ndata['observer_attention'] = np.random.beta(7, 3, n_samples)\ndata['observer_prior_knowledge'] = np.random.uniform(0.3, 0.9, n_samples)\ndata['observation_clarity'] = np.clip(\n    np.random.normal(0.8, 0.1, n_samples) + 0.2 * data['observer_attention'],\n    0, 1\n)\n\n# Cognitive variables - influenced by physical and observer variables\ndata['cognitive_stimulation'] = 0.7 * data['impact_velocity'] + 0.3 * np.random.normal(0, 0.1, n_samples)\ndata['cognitive_resonance'] = 0.6 * data['observer_prior_knowledge'] + 0.4 * np.random.beta(5, 2, n_samples)\n\n# Insight variables - complex interactions\ndata['insight_probability'] = stats.logistic.cdf(\n    0.4 * data['cognitive_stimulation'] + \n    0.3 * data['cognitive_resonance'] + \n    0.2 * data['observation_clarity'] +\n    0.1 * np.random.normal(0, 1, n_samples)\n)\n\n# Generate binary insight occurrence\ndata['insight_occurred'] = np.random.binomial(1, data['insight_probability'], n_samples)\n\n# For cases where insight occurred, generate insight properties\ninsight_cases = data[data['insight_occurred'] == 1].copy()\nn_insights = len(insight_cases)\n\nif n_insights > 0:\n    insight_cases['insight_magnitude'] = 0.7 * insight_cases['cognitive_resonance'] + 0.3 * np.random.beta(8, 3, n_insights)\n    insight_cases['insight_novelty'] = 0.5 * (1 - insight_cases['observer_prior_knowledge']) + 0.5 * np.random.beta(4, 2, n_insights)\n    insight_cases['insight_utility'] = 0.6 * insight_cases['insight_magnitude'] + 0.4 * np.random.beta(6, 2, n_insights)\n    \n    # Historical impact - long-term significance\n    insight_cases['historical_significance'] = 0.7 * insight_cases['insight_utility'] + 0.2 * insight_cases['insight_novelty'] + 0.1 * np.random.beta(9, 2, n_insights)\n    \n    # Domain classification - simplified to physics vs. other\n    logits = 3 * insight_cases['insight_utility'] - 1 + np.random.normal(0, 0.5, n_insights)\n    insight_cases['physics_domain_probability'] = stats.logistic.cdf(logits)\n    insight_cases['physics_domain'] = np.random.binomial(1, insight_cases['physics_domain_probability'], n_insights)\n    \n    # Merge back with main dataset\n    for col in insight_cases.columns:\n        if col not in data.columns:\n            data[col] = np.nan\n    data.update(insight_cases)\n\n# Fill NaN values for non-insight cases\nfor col in data.columns:\n    if data[col].isnull().any():\n        data[col] = data[col].fillna(0)  # Non-insights get zero magnitude, etc.\n\n# Variable Selection using multiple methods\n# 1. Information-theoretic approach\nX = data.drop(['insight_occurred', 'physics_domain', 'physics_domain_probability', 'historical_significance'], axis=1)\ny_insight = data['insight_occurred']\ny_physics = data['physics_domain']\ny_significance = data['historical_significance']\n\nmi_scores_insight = calculate_mutual_information(X, y_insight)\ntop_features_mi = mi_scores_insight.nlargest(10).index.tolist()\n\n# 2. Model-based selection\nrf = RandomForestRegressor(n_estimators=100, random_state=42)\nrf.fit(X, y_significance)\nfeature_importance = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\ntop_features_rf = feature_importance.nlargest(10).index.tolist()\n\n# Combined variable importance\nall_top_features = list(set(top_features_mi + top_features_rf))\nprint(f\"Selected top features: {all_top_features}\")\n\n# Bayesian Network for causal inference\nG = nx.DiGraph()\nnodes = ['apple_mass', 'initial_height', 'gravity', 'fall_time', 'impact_velocity', \n         'observer_attention', 'observer_prior_knowledge', 'observation_clarity',\n         'cognitive_stimulation', 'cognitive_resonance', 'insight_probability', \n         'insight_occurred', 'insight_magnitude', 'historical_significance', 'physics_domain']\n\nG.add_nodes_from(nodes)\nedges = [\n    ('apple_mass', 'kinetic_energy'),\n    ('initial_height', 'fall_time'),\n    ('gravity', 'fall_time'),\n    ('gravity', 'impact_velocity'),\n    ('fall_time', 'impact_velocity'),\n    ('impact_velocity', 'cognitive_stimulation'),\n    ('observer_attention', 'observation_clarity'),\n    ('observer_prior_knowledge', 'cognitive_resonance'),\n    ('cognitive_stimulation', 'insight_probability'),\n    ('cognitive_resonance', 'insight_probability'),\n    ('observation_clarity', 'insight_probability'),\n    ('insight_probability', 'insight_occurred'),\n    ('insight_occurred', 'insight_magnitude'),\n    ('observer_prior_knowledge', 'insight_novelty'),\n    ('insight_magnitude', 'insight_utility'),\n    ('insight_novelty', 'insight_utility'),\n    ('insight_utility', 'historical_significance'),\n    ('insight_novelty', 'historical_significance'),\n    ('insight_utility', 'physics_domain')\n]\nG.add_edges_from(edges)\n\n# Fit Bayesian model using PyMC3 for the key relationships\nwith pm.Model() as bayesian_model:\n    # Priors\n    beta_stimulation = pm.Normal('beta_stimulation', mu=0.4, sd=0.1)\n    beta_resonance = pm.Normal('beta_resonance', mu=0.3, sd=0.1)\n    beta_clarity = pm.Normal('beta_clarity', mu=0.2, sd=0.1)\n    \n    # Linear model for insight probability using logistic function\n    insight_logit = (beta_stimulation * data['cognitive_stimulation'].values + \n                    beta_resonance * data['cognitive_resonance'].values + \n                    beta_clarity * data['observation_clarity'].values)\n    \n    # Likelihood\n    pm.Bernoulli('insight', logit_p=insight_logit, observed=data['insight_occurred'].values)\n    \n    # Sampling\n    trace = pm.sample(1000, tune=1000, cores=1, return_inferencedata=False)\n\n# Extract posterior means for coefficients\nbeta_stimulation_mean = trace['beta_stimulation'].mean()\nbeta_resonance_mean = trace['beta_resonance'].mean()\nbeta_clarity_mean = trace['beta_clarity'].mean()\n\n# Create counterfactual scenarios\ncounterfactual_scenarios = {\n    'higher_mass': {'apple_mass': 0.5},  # 5x normal mass\n    'lower_height': {'initial_height': 2.0},  # Lower initial height\n    'distracted_observer': {'observer_attention': 0.3},  # Lower attention\n    'expert_observer': {'observer_prior_knowledge': 0.95}  # Higher prior knowledge\n}\n\n# Function to predict insight probability under counterfactual conditions\ndef predict_counterfactual(scenario, data=data, trace=trace):\n    # Create a copy of the base scenario (using first row as template)\n    cf_data = data.iloc[0:1].copy()\n    \n    # Apply counterfactual changes\n    for key, value in scenario.items():\n        cf_data[key] = value\n    \n    # Recalculate dependent variables\n    if 'initial_height' in scenario or 'gravity' in scenario:\n        cf_data['fall_time'] = np.sqrt(2 * cf_data['initial_height'] / cf_data['gravity'])\n    \n    if 'fall_time' in scenario or 'gravity' in scenario:\n        cf_data['impact_velocity'] = cf_data['gravity'] * cf_data['fall_time']\n    \n    if 'impact_velocity' in scenario or 'apple_mass' in scenario:\n        cf_data['kinetic_energy'] = 0.5 * cf_data['apple_mass'] * cf_data['impact_velocity']**2\n    \n    if 'observer_attention' in scenario:\n        cf_data['observation_clarity'] = np.clip(\n            0.8 + 0.2 * cf_data['observer_attention'],\n            0, 1\n        )\n    \n    if 'impact_velocity' in scenario:\n        cf_data['cognitive_stimulation'] = 0.7 * cf_data['impact_velocity'] + 0.1\n    \n    if 'observer_prior_knowledge' in scenario:\n        cf_data['cognitive_resonance'] = 0.6 * cf_data['observer_prior_knowledge'] + 0.2\n    \n    # Calculate insight probability using Bayesian model coefficients\n    insight_logit = (beta_stimulation_mean * cf_data['cognitive_stimulation'].values + \n                    beta_resonance_mean * cf_data['cognitive_resonance'].values + \n                    beta_clarity_mean * cf_data['observation_clarity'].values)\n    \n    insight_probability = stats.logistic.cdf(insight_logit)[0]\n    \n    return insight_probability\n\n# Evaluate counterfactual scenarios\ncounterfactual_results = {}\nfor name, scenario in counterfactual_scenarios.items():\n    counterfactual_results[name] = predict_counterfactual(scenario)\n\n# Sensitivity analysis\nsensitivity = {}\nbase_prediction = predict_counterfactual({})\n\nfor feature in ['apple_mass', 'initial_height', 'observer_attention', 'observer_prior_knowledge']:\n    # Test increasing the feature by 10%\n    high_scenario = {feature: data[feature].iloc[0] * 1.1}\n    high_prediction = predict_counterfactual(high_scenario)\n    \n    # Test decreasing the feature by 10%\n    low_scenario = {feature: data[feature].iloc[0] * 0.9}\n    low_prediction = predict_counterfactual(low_scenario)\n    \n    # Calculate elasticity: percent change in output / percent change in input\n    high_elasticity = (high_prediction - base_prediction) / base_prediction / 0.1\n    low_elasticity = (base_prediction - low_prediction) / base_prediction / 0.1\n    \n    # Average elasticity (absolute value)\n    sensitivity[feature] = (abs(high_elasticity) + abs(low_elasticity)) / 2\n\n# Rank features by sensitivity\nsensitivity_series = pd.Series(sensitivity).sort_values(ascending=False)\n\n# Fit models to predict historical significance\nX_significance = data[all_top_features]\ny_significance = data['historical_significance']\n\n# Gradient Boosting Regressor\ngb = GradientBoostingRegressor(n_estimators=100, random_state=42)\ngb.fit(X_significance, y_significance)\nsignificance_predictions = gb.predict(X_significance)\nr2 = r2_score(y_significance, significance_predictions)\n\n# Cross-validation for robust performance estimation\ncv_scores = cross_val_score(gb, X_significance, y_significance, cv=5, scoring='r2')\nmean_cv_r2 = cv_scores.mean()\n\n# Confidence intervals using bootstrap\nn_bootstraps = 1000\nbootstrap_predictions = np.zeros((n_bootstraps, len(data)))\n\nfor i in range(n_bootstraps):\n    # Bootstrap sample\n    indices = np.random.choice(len(data), len(data), replace=True)\n    X_boot = X_significance.iloc[indices]\n    y_boot = y_significance.iloc[indices]\n    \n    # Train model on bootstrap sample\n    gb_boot = GradientBoostingRegressor(n_estimators=100, random_state=i)\n    gb_boot.fit(X_boot, y_boot)\n    \n    # Predict on original data\n    bootstrap_predictions[i] = gb_boot.predict(X_significance)\n\n# Calculate 95% confidence intervals\nlower_bound = np.percentile(bootstrap_predictions, 2.5, axis=0)\nupper_bound = np.percentile(bootstrap_predictions, 97.5, axis=0)\nmean_prediction = np.mean(bootstrap_predictions, axis=0)\n\n# Calculate prediction intervals\nprediction_interval_width = upper_bound - lower_bound\nmean_interval_width = prediction_interval_width.mean()\n\n# Calculate calibration\nwithin_interval = ((y_significance >= lower_bound) & (y_significance <= upper_bound)).mean()\n\n# Bayesian Model Averaging for physics domain prediction\nmodels = {\n    'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n    'random_forest': RandomForestRegressor(n_estimators=100, random_state=42)\n}\n\n# Train models\nX_domain = data[all_top_features]\ny_domain = data['physics_domain']\n\nfor name, model in models.items():\n    model.fit(X_domain, y_domain)\n\n# Get predictions from each model\nmodel_predictions = {}\nfor name, model in models.items():\n    if hasattr(model, 'predict_proba'):\n        model_predictions[name] = model.predict_proba(X_domain)[:, 1]\n    else:\n        model_predictions[name] = model.predict(X_domain)\n\n# Model weights (could be determined by cross-validation performance)\nmodel_weights = {'gradient_boosting': 0.6, 'random_forest': 0.4}\n\n# Combine predictions using weighted average\ncombined_predictions = np.zeros(len(data))\nfor name, preds in model_predictions.items():\n    combined_predictions += model_weights[name] * preds\n\n# Convert to binary predictions\nbinary_predictions = (combined_predictions > 0.5).astype(int)\naccuracy = accuracy_score(y_domain, binary_predictions)\n\n# Final variable importance and predictions\nfinal_variable_importance = {}\nfor feature in all_top_features:\n    # Combine importance from multiple sources\n    # - Mutual information score\n    # - Random forest importance\n    # - Sensitivity analysis (if available)\n    # - Bayesian model coefficients (if applicable)\n    \n    mi_importance = mi_scores_insight.get(feature, 0)\n    rf_importance = feature_importance.get(feature, 0)\n    sens_importance = sensitivity_series.get(feature, 0) if feature in sensitivity_series else 0\n    \n    # Normalize each importance measure to [0, 1]\n    mi_norm = mi_importance / mi_scores_insight.max() if mi_scores_insight.max() > 0 else 0\n    rf_norm = rf_importance / feature_importance.max() if feature_importance.max() > 0 else 0\n    sens_norm = sens_importance / sensitivity_series.max() if feature in sensitivity_series and sensitivity_series.max() > 0 else 0\n    \n    # Weighted combination\n    final_variable_importance[feature] = 0.4 * mi_norm + 0.4 * rf_norm + 0.2 * sens_norm\n\n# Sort by importance\nfinal_importance_series = pd.Series(final_variable_importance).sort_values(ascending=False)\ntop_final_features = final_importance_series.nlargest(7).index.tolist()\n\n# Final predictions:\n# 1. Probability of insight occurring given the observation\ninsight_probability = data['insight_probability'].mean()\n\n# 2. Probability that the insight relates to physics/gravitation\nphysics_probability = data[data['insight_occurred']==1]['physics_domain_probability'].mean()\n\n# 3. Expected historical significance (on 0-1 scale)\nmean_historical_significance = data[data['insight_occurred']==1]['historical_significance'].mean()\n\n# 4. Confidence in these predictions\nconfidence_insight = 1 - np.std(data['insight_probability'])\nconfidence_physics = 1 - np.std(data[data['insight_occurred']==1]['physics_domain_probability'])\nconfidence_historical = 1 - mean_interval_width\n\n# Combine into overall confidence\noverall_confidence = 0.4 * confidence_insight + 0.3 * confidence_physics + 0.3 * confidence_historical\n\nprint(f\"Top variables by importance: {top_final_features}\")\nprint(f\"Insight probability: {insight_probability:.4f}\")\nprint(f\"Physics domain probability: {physics_probability:.4f}\")\nprint(f\"Historical significance: {mean_historical_significance:.4f}\")\nprint(f\"Overall confidence: {overall_confidence:.4f}\")\n\n\nAdvanced Statistical Analysis Results\n\n1. Variable Importance Rankings\n\nInformation-Theoretic Analysis:\n\ncognitive_resonance (0.487)\n\nobservation_clarity (0.429)\n\ncognitive_stimulation (0.402)\n\nobserver_prior_knowledge (0.376)\n\nimpact_velocity (0.291)\n\nSensitivity Analysis (Elasticity):\n\nobserver_prior_knowledge (1.742)\n\ncognitive_resonance (1.384)\n\nobservation_clarity (0.835)\n\nimpact_velocity (0.628)\n\ninitial_height (0.412)\n\nBayesian Parameter Estimation:\n\ncognitive_resonance (β = 0.351, 95% CI: [0.287, 0.415])\n\ncognitive_stimulation (β = 0.327, 95% CI: [0.268, 0.386])\n\nobservation_clarity (β = 0.218, 95% CI: [0.167, 0.269])\n\nFinal Combined Variable Importance:\n\ncognitive_resonance (0.935)\n\nobserver_prior_knowledge (0.892)\n\nobservation_clarity (0.847)\n\ncognitive_stimulation (0.829)\n\nimpact_velocity (0.734)\n\ninsight_magnitude (0.703)\n\ninsight_utility (0.689)\n\n2. Causal Inference Results\n\nDirect Causal Effects (Average Treatment Effects):\n\nimpact_velocity → cognitive_stimulation: 0.684\n\nobserver_prior_knowledge → cognitive_resonance: 0.593\n\ncognitive_stimulation → insight_probability: 0.417\n\ncognitive_resonance → insight_probability: 0.383\n\ninsight_magnitude → historical_significance: 0.729\n\nCounterfactual Scenario Analysis:\n\nBase scenario insight probability: 0.763\n\nHigher apple mass scenario: 0.789 (+3.4%)\n\nLower initial height scenario: 0.682 (-10.6%)\n\nDistracted observer scenario: 0.529 (-30.7%)\n\nExpert observer scenario: 0.918 (+20.3%)\n\nMediation Analysis:\n\nIndirect effect of observer_prior_knowledge on insight_probability: 0.227\n\nIndirect effect of initial_height on insight_probability: 0.179\n\nIndirect effect of insight_magnitude on physics_domain: 0.314\n\n3. Predictive Modeling Results\n\nHistorical Significance Prediction:\n\nGradient Boosting R² score: 0.827\n\nCross-validation R² score: 0.793\n\nMean prediction interval width: 0.186\n\nCalibration accuracy: 94.2%\n\nPhysics Domain Classification:\n\nGradient Boosting accuracy: 0.891\n\nRandom Forest accuracy: 0.875\n\nEnsemble model accuracy: 0.907\n\nAUC-ROC score: 0.942\n\nModel Stability Analysis:\n\nFeature importance stability: 0.876\n\nPrediction stability under noise: 0.912\n\nCross-validation stability coefficient: 0.865\n\n4. Final Predictions\n\nPrimary Prediction: Insight Content and Domain\n\n97.3% probability that the insight relates to gravitational theory\n\n92.8% probability that the insight includes mathematical formalization\n\n89.1% probability that the insight generalizes to celestial bodies\n\nSecondary Prediction: Historical Impact\n\n94.7% probability of significant scientific publication\n\n92.3% probability of paradigm shift in physics\n\n87.6% probability of cross-domain influence (mathematics, astronomy)\n\n82.4% probability of technological applications within 100 years\n\nCognitive Process Predictions\n\n96.8% probability of inductive reasoning as primary cognitive mechanism\n\n89.4% probability of analogical transfer between falling objects and celestial motion\n\n78.3% probability of mathematical formalism development within 1 year\n\nUncertainty Quantification\n\nOverall prediction confidence: 92.7%\n\nMost certain prediction: Domain classification (confidence: 95.3%)\n\nLeast certain prediction: Timing of formalization (confidence: 83.6%)\n\nRobustness to historical contingency: 87.9%\n\nStep 6: Response Formatting\n\n\n**Expected Output:**\n\n\nReasoning time: 7.8 seconds\n\nCode preview:\n\n# Advanced physical and cognitive simulation\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom sympy import symbols, solve, diff, Eq\n\n# Physical constants and system parameters\nG = 6.67430e-11  # Gravitational constant\nEarth_mass = 5.972e24  # kg\ng = G * Earth_mass / (Earth_radius**2)  # Surface gravity\n\n# Create environment and entities\nenvironment = Environment(\"Woolsthorpe Manor Garden\")\ntree = PhysicalObject(\"apple_tree\", 1000, [0, 0, 5])\napple = PhysicalObject(\"apple\", 0.1, [0.5, 0, 4.5])\nisaac = CognitiveAgent(\"Isaac\", [2, 0, 1.7])\n\n# Simulate the apple falling\napple.detach_from(tree)\nenvironment.simulate(2.0)\n\n# Update Isaac's mental model with gravity equation\ngravity_eq = Eq(F, G * m * Earth_mass / r**2)\nisaac.update_mental_model(\"physics:gravitation\", newton_model)\n\n\nVariables identified: 248 Variable taxonomy: 6 primary clusters × 3 hierarchical levels Key variable clusters:\n\nΨ₂.₃: {cognitive_resonance, observation_clarity, prior_knowledge} → emergent insight formation\n\nΨ₁.₂: {impact_velocity, kinetic_energy, gravitational_force} → physical causality chain\n\nΨ₄.₁: {causal_link.observation_insight, temporal_proximity} → causal bottleneck\n\nΨ₅.₁: {historical_significance, paradigm_shift_magnitude} → scientific impact tensor\n\nStatistical manifold properties:\n\nIntrinsic dimensionality: 4.7\n\nTopological complexity (Betti numbers): [1, 5, 2]\n\nNetwork modularity: 0.763\n\nScale-free exponent: 2.14\n\nLyapunov exponents: [0.42, 0.18, -0.09, -0.37]\n\nPrecision metrics:\n\nKullback-Leibler divergence: 0.043\n\nWasserstein distance: 0.072\n\nExpected calibration error: 0.026\n\nAlgorithmic complexity: 0.378\n\nCross-validation stability: 0.892\n\nKey predictions:\n\nThe insight relates to gravitational theory (97.3%, confidence interval: [95.1%, 98.8%])\n\nMathematical formalization will follow within 12 months (92.8%, sensitivity to perturbation: 0.17)\n\nThe insight generalizes to celestial bodies (89.1%, confidence interval: [85.3%, 92.7%])\n\nThe discovery creates a physics paradigm shift (92.3%, robustness score: 0.89)\n\nCognitive mechanism involves analogical transfer between falling objects and celestial motion (89.4%)\n\nMeta-predictions:\n\nSystem evolution trajectory: Rapid formalization → experimental verification → paradigmatic integration\n\nCritical transition points: [2.37, 5.81, 9.14] years post-insight\n\nEmergence probability: 0.879\n\nOverall confidence: 92.7% (derived from Bayesian Model Averaging with Gaussian process calibration)\n\n\n## Example 2: Complex Social Interaction\n\n**Input:**\n\n\n\"After the team's crushing defeat, the coach gathered everyone in the locker room and spoke quietly for five minutes. When they emerged, their expressions had completely changed.\"\n\n\n**Expected Chain-of-Thought:**\n[Detailed reasoning process following the same 6-step framework]\n\n**Expected Output:**\n[Formatted output following the response template]\n\n## Example 3: Economic Scenario\n\n**Input:**\n\n\n\"As interest rates fell for the third consecutive quarter, housing starts unexpectedly declined while consumer spending on luxury goods surged.\"\n\n\n**Expected Chain-of-Thought:**\n[Detailed reasoning process following the same 6-step framework]\n\n**Expected Output:**\n[Formatted output following the response template]\n\n## Example 4: Philosophical Concept\n\n**Input:**\n\n\n\"The prisoner, having spent decades in the cave, stepped into the sunlight and found himself unable to comprehend what he was seeing.\"\n\n\n**Expected Chain-of-Thought:**\n[Detailed reasoning process following the same 6-step framework]\n\n**Expected Output:**\n[Formatted output following the response template]\n\n## Example 5: Environmental Observation\n\n**Input:**\n\n\n\"Following three years of drought, the first heavy rainfall caused the desert to bloom with flowers that hadn't been seen for a generation.\"\n\n\n**Expected Chain-of-Thought:**\n[Detailed reasoning process following the same 6-step framework]\n\n**Expected Output:**\n[Formatted output following the response template]",
              "presence_penalty": 0,
              "frequency_penalty": 0
            },
            "output": [
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "Okay",
              ",",
              " so",
              " I",
              "'m",
              " trying",
              " to",
              " understand",
              " how",
              " the",
              " structure",
              " of",
              " DNA",
              " can",
              " be",
              " represented",
              " using",
              " an",
              " SU",
              "(",
              "2",
              ")",
              " spine",
              " and",
              " how",
              " replication",
              " can",
              " be",
              " modeled",
              " through",
              " rotations",
              " on",
              " the",
              " ",
              "3",
              "-s",
              "phere",
              " S",
              "³",
              ".",
              " The",
              " user",
              " mentioned",
              " that",
              " SU",
              "(",
              "2",
              ")",
              " is",
              " a",
              " double",
              " cover",
              " of",
              " SO",
              "(",
              "3",
              "),",
              " which",
              " I",
              " remember",
              " from",
              " my",
              " studies",
              ",",
              " but",
              " I",
              " need",
              " to",
              " unpack",
              " this",
              " more",
              " carefully",
              ".\n\n",
              "First",
              ",",
              " I",
              " recall",
              " that",
              " SU",
              "(",
              "2",
              ")",
              " is",
              " a",
              " special",
              " unit",
              "ary",
              " group",
              ",",
              " which",
              " consists",
              " of",
              " ",
              "2",
              "x",
              "2",
              " matrices",
              " with",
              " determinant",
              " ",
              "1",
              " and",
              " trace",
              " ",
              "0",
              ",",
              " or",
              " something",
              " like",
              " that",
              ".",
              " These",
              " matrices",
              " have",
              " elements",
              " with",
              " complex",
              " numbers",
              ",",
              " but",
              " they",
              " can",
              " also",
              " be",
              " represented",
              " using",
              " qu",
              "atern",
              "ions",
              ".",
              " Qu",
              "atern",
              "ions",
              " are",
              " interesting",
              " because",
              " they",
              " can",
              " describe",
              " rotations",
              " in",
              " ",
              "3",
              "D",
              " space",
              ",",
              " which",
              " is",
              " exactly",
              " what",
              " SO",
              "(",
              "3",
              ")",
              " does",
              ".",
              " So",
              ",",
              " SU",
              "(",
              "2",
              ")",
              " being",
              " a",
              " double",
              " cover",
              " of",
              " SO",
              "(",
              "3",
              ")",
              " means",
              " that",
              " each",
              " rotation",
              " in",
              " SO",
              "(",
              "3",
              ")",
              " corresponds",
              " to",
              " two",
              " distinct",
              " elements",
              " in",
              " SU",
              "(",
              "2",
              ").",
              " This",
              " is",
              " because",
              " a",
              " rotation",
              " by",
              " ",
              "3",
              "6",
              "0",
              " degrees",
              " in",
              " SO",
              "(",
              "3",
              ")",
              " maps",
              " to",
              " the",
              " identity",
              " in",
              " SU",
              "(",
              "2",
              "),",
              " but",
              " a",
              " rotation",
              " by",
              " ",
              "1",
              "8",
              "0",
              " degrees",
              " in",
              " SU",
              "(",
              "2",
              ")",
              " gives",
              " the",
              " same",
              " rotation",
              " in",
              " SO",
              "(",
              "3",
              ").",
              " That",
              "'s",
              " why",
              " the",
              " term",
              " \"",
              "double",
              " cover",
              "\"",
              " is",
              " used",
              ".\n\n",
              "Now",
              ",",
              " the",
              " DNA",
              " structure",
              " is",
              " being",
              " compared",
              " to",
              " an",
              " SU",
              "(",
              "2",
              ")",
              " spine",
              ".",
              " I",
              "'m",
              " pict",
              "uring",
              " DNA",
              " as",
              " a",
              " double",
              " hel",
              "ix",
              ",",
              " which",
              " has",
              " a",
              " central",
              " axis",
              ".",
              " Maybe",
              " the",
              " SU",
              "(",
              "2",
              ")",
              " structure",
              " is",
              " being",
              " used",
              " metaphor",
              "ically",
              " to",
              " represent",
              " the",
              " central",
              " axis",
              " of",
              " the",
              " DNA",
              ",",
              " with",
              " the",
              " double",
              " hel",
              "ix",
              " strands",
              " wrapping",
              " around",
              " it",
              ".",
              " But",
              " how",
              " does",
              " this",
              " relate",
              " to",
              " replication",
              "?\n\n",
              "DNA",
              " replication",
              " involves",
              " the",
              " double",
              " hel",
              "ix",
              " unw",
              "inding",
              " and",
              " each",
              " strand",
              " serving",
              " as",
              " a",
              " template",
              " for",
              " a",
              " new",
              " strand",
              ".",
              " The",
              " replication",
              " fork",
              " moves",
              " along",
              " the",
              " DNA",
              ",",
              " and",
              " the",
              " process",
              " is",
              " hel",
              "ical",
              ".",
              " If",
              " we",
              " model",
              " each",
              " strand",
              " as",
              " part",
              " of",
              " an",
              " SU",
              "(",
              "2",
              ")",
              " structure",
              ",",
              " perhaps",
              " the",
              " replication",
              " can",
              " be",
              " seen",
              " as",
              " a",
              " rotation",
              " or",
              " transformation",
              " within",
              " this",
              " group",
              ".",
              " The",
              " idea",
              " of",
              " keeping",
              " the",
              " geometric",
              " phase",
              " invariant",
              " during",
              " replication",
              " is",
              " intriguing",
              ".",
              " The",
              " geometric",
              " phase",
              ",",
              " or",
              " Berry",
              " phase",
              ",",
              " is",
              " a",
              " concept",
              " from",
              " quantum",
              " mechanics",
              " where",
              " a",
              " system",
              " returns",
              " to",
              " its",
              " original",
              " state",
              " after",
              " a",
              " cyclic",
              " process",
              ",",
              " but",
              " gains",
              " a",
              " phase",
              " shift",
              ".",
              " In",
              " the",
              " context",
              " of",
              " DNA",
              " replication",
              ",",
              " this",
              " might",
              " mean",
              " that",
              " the",
              " top",
              "ological",
              " state",
              " of",
              " the",
              " DNA",
              " is",
              " preserved",
              " through",
              " the",
              " replication",
              " process",
              ",",
              " ensuring",
              " that",
              " the",
              " information",
              " is",
              " accurately",
              " copied",
              ".\n\n",
              "The",
              " user",
              " suggested",
              " using",
              " Berry",
              "'s",
              " connection",
              ",",
              " which",
              " is",
              " a",
              " concept",
              " from",
              " fiber",
              " bundles",
              " in",
              " differential",
              " geometry",
              ".",
              " Berry",
              "'s",
              " connection",
              " describes",
              " how",
              " quantum",
              " states",
              " change",
              " when",
              " parameters",
              " of",
              " the",
              " system",
              " are",
              " ad",
              "i",
              "ab",
              "atically",
              " varied",
              ".",
              " In",
              " the",
              " case",
              " of",
              " DNA",
              " replication",
              ",",
              " the",
              " ad",
              "i",
              "ab",
              "atic",
              " transport",
              " could",
              " correspond",
              " to",
              " the",
              " replication",
              " process",
              ",",
              " where",
              " the",
              " DNA",
              "'s",
              " top",
              "ological",
              " state",
              " is",
              " transported",
              " along",
              " the",
              " SU",
              "(",
              "2",
              ")",
              " spine",
              ".",
              " This",
              " would",
              " ensure",
              " that",
              " the",
              " information",
              " encoded",
              " in",
              " the",
              " DNA",
              "'s",
              " structure",
              " is",
              " replicated",
              " without",
              " introducing",
              " errors",
              ",",
              " as",
              " the",
              " geometric",
              " phase",
              " remains",
              " invariant",
              ".\n\n",
              "I",
              "'m",
              " also",
              " thinking",
              " about",
              " the",
              " role",
              " of",
              " the",
              " ",
              "3",
              "-s",
              "phere",
              ",",
              " S",
              "³",
              ",",
              " in",
              " all",
              " this",
              ".",
              " S",
              "³",
              " is",
              " the",
              " space",
              " of",
              " unit",
              " qu",
              "atern",
              "ions",
              ",",
              " which",
              " can",
              " represent",
              " rotations",
              " in",
              " ",
              "3",
              "D",
              " space",
              ".",
              " If",
              " the",
              " replication",
              " process",
              " is",
              " modeled",
              " on",
              " S",
              "³",
              ",",
              " it",
              " might",
              " involve",
              " rotations",
              " that",
              " correspond",
              " to",
              " the",
              " transformation",
              " of",
              " the",
              " DNA",
              " strands",
              ".",
              " The",
              " in",
              "var",
              "iance",
              " of",
              " the",
              " geometric",
              " phase",
              " would",
              " then",
              " ensure",
              " that",
              " despite",
              " these",
              " rotations",
              ",",
              " the",
              " overall",
              " information",
              " encoded",
              " in",
              " the",
              " DNA",
              " remains",
              " consistent",
              ".\n\n",
              "But",
              " wait",
              ",",
              " how",
              " exactly",
              " does",
              " the",
              " replication",
              " process",
              " translate",
              " into",
              " rotations",
              " on",
              " S",
              "³",
              "?",
              " Each",
              " rotation",
              " could",
              " correspond",
              " to",
              " a",
              " step",
              " in",
              " the",
              " replication",
              ",",
              " perhaps",
              " align",
              "ing",
              " with",
              " the",
              " movement",
              " of",
              " the",
              " replication",
              " fork",
              ".",
              " The",
              " invariant",
              " geometric",
              " phase",
              " would",
              " then",
              " be",
              " a",
              " way",
              " to",
              " ensure",
              " that",
              " the",
              " replication",
              " doesn",
              "'t",
              " introduce",
              " any",
              " twists",
              " or",
              " knots",
              " that",
              " could",
              " disrupt",
              " the",
              " process",
              ".",
              " This",
              " would",
              " be",
              " crucial",
              " for",
              " maintaining",
              " the",
              " integrity",
              " of",
              " the",
              " genetic",
              " information",
              ".\n\n",
              "I",
              "'m",
              " also",
              " curious",
              " about",
              " the",
              " mathematical",
              " formal",
              "ism",
              " here",
              ".",
              " If",
              " we",
              " represent",
              " the",
              " DNA",
              " structure",
              " using",
              " SU",
              "(",
              "2",
              "),",
              " each",
              " point",
              " along",
              " the",
              " DNA",
              "'s",
              " axis",
              " could",
              " be",
              " associated",
              " with",
              " an",
              " element",
              " of",
              " SU",
              "(",
              "2",
              ").",
              " As",
              " replication",
              " proceeds",
              ",",
              " these",
              " elements",
              " undergo",
              " transformations",
              " that",
              " correspond",
              " to",
              " the",
              " unw",
              "inding",
              " and",
              " replication",
              " of",
              " the",
              " DNA",
              " strands",
              ".",
              " The",
              " connection",
              " to",
              " Berry",
              "'s",
              " phase",
              " comes",
              " into",
              " play",
              " when",
              " considering",
              " the",
              " transport",
              " of",
              " these",
              " elements",
              " along",
              " the",
              " DNA",
              " axis",
              ",",
              " ensuring",
              " that",
              " the",
              " overall",
              " transformation",
              " is",
              " consistent",
              " and",
              " that",
              " the",
              " geometric",
              " phase",
              " is",
              " preserved",
              ".\n\n",
              "Another",
              " thought",
              " is",
              " about",
              " the",
              " top",
              "ological",
              " stability",
              " of",
              " the",
              " replication",
              " process",
              ".",
              " By",
              " modeling",
              " replication",
              " using",
              " SU",
              "(",
              "2",
              ")",
              " and",
              " S",
              "³",
              ",",
              " we",
              " might",
              " gain",
              " insights",
              " into",
              " how",
              " DNA",
              " maintains",
              " its",
              " structure",
              " despite",
              " the",
              " mechanical",
              " stress",
              " of",
              " replication",
              ".",
              " The",
              " top",
              "ological",
              " in",
              "variants",
              ",",
              " such",
              " as",
              " the",
              " linking",
              " number",
              " or",
              " twist",
              ",",
              " could",
              " be",
              " related",
              " to",
              " the",
              " properties",
              " of",
              " the",
              " SU",
              "(",
              "2",
              ")",
              " group",
              " and",
              " the",
              " geometry",
              " of",
              " S",
              "³",
              ".\n\n",
              "I",
              "'m",
              " also",
              " wondering",
              " about",
              " potential",
              " experimental",
              " implications",
              ".",
              " If",
              " this",
              " model",
              " accurately",
              " captures",
              " the",
              " replication",
              " process",
              ",",
              " it",
              " could",
              " lead",
              " to",
              " new",
              " ways",
              " of",
              " understanding",
              " DNA",
              " repair",
              " mechanisms",
              " or",
              " the",
              " effects",
              " of",
              " certain",
              " drugs",
              " that",
              " target",
              " DNA",
              " replication",
              ".",
              " For",
              " instance",
              ",",
              " drugs",
              " that",
              " interfere",
              " with",
              " top",
              "ois",
              "omer",
              "ases",
              " might",
              " disrupt",
              " the",
              " geometric",
              " phase",
              ",",
              " leading",
              " to",
              " errors",
              " in",
              " replication",
              ".\n\n",
              "Furthermore",
              ",",
              " this",
              " model",
              " might",
              " have",
              " applications",
              " in",
              " synthetic",
              " biology",
              " or",
              " DNA",
              "-based",
              " data",
              " storage",
              ".",
              " Understanding",
              " the",
              " top",
              "ological",
              " aspects",
              " of",
              " DNA",
              " replication",
              " could",
              " help",
              " in",
              " designing",
              " more",
              " efficient",
              " ways",
              " to",
              " write",
              ",",
              " read",
              ",",
              " and",
              " replicate",
              " synthetic",
              " DNA",
              " constructs",
              " without",
              " errors",
              ".\n\n",
              "However",
              ",",
              " I",
              "'m",
              " not",
              " entirely",
              " sure",
              " how",
              " to",
              " translate",
              " the",
              " physical",
              " process",
              " of",
              " DNA",
              " replication",
              " into",
              " the",
              " language",
              " of",
              " SU",
              "(",
              "2",
              ")",
              " and",
              " S",
              "³",
              ".",
              " I",
              " might",
              " need",
              " to",
              " look",
              " into",
              " existing",
              " literature",
              " on",
              " top",
              "ological",
              " models",
              " of",
              " DNA",
              " replication",
              " to",
              " see",
              " how",
              " others",
              " have",
              " approached",
              " this",
              " problem",
              ".",
              " Perhaps",
              " there",
              " are",
              " known",
              " connections",
              " between",
              " DNA",
              "'s",
              " double",
              " hel",
              "ix",
              " and",
              " these",
              " mathematical",
              " structures",
              " that",
              " I",
              "'m",
              " not",
              " fully",
              " gras",
              "ping",
              " yet",
              ".\n\n",
              "In",
              " summary",
              ",",
              " the",
              " user",
              "'s",
              " suggestion",
              " provides",
              " a",
              " rich",
              " framework",
              " for",
              " modeling",
              " DNA",
              " replication",
              " using",
              " concepts",
              " from",
              " group",
              " theory",
              " and",
              " differential",
              " geometry",
              ".",
              " By",
              " representing",
              " the",
              " DNA",
              "'s",
              " central",
              " axis",
              " as",
              " an",
              " SU",
              "(",
              "2",
              ")",
              " spine",
              " and",
              " replication",
              " as",
              " rotations",
              " on",
              " S",
              "³",
              ",",
              " we",
              " can",
              " leverage",
              " the",
              " in",
              "var",
              "iance",
              " of",
              " the",
              " geometric",
              " phase",
              " to",
              " ensure",
              " the",
              " fidelity",
              " of",
              " genetic",
              " information",
              ".",
              " This",
              " approach",
              " not",
              " only",
              " offers",
              " a",
              " beautiful",
              " mathematical",
              " structure",
              " but",
              " also",
              " has",
              " the",
              " potential",
              " to",
              " deepen",
              " our",
              " understanding",
              " of",
              " DNA",
              " replication",
              "'s",
              " top",
              "ological",
              " aspects",
              ".\n",
              "</think>",
              "\n\n",
              "The",
              " structure",
              " of",
              " DNA",
              " can",
              " be",
              " eleg",
              "antly",
              " modeled",
              " using",
              " the",
              " SU",
              "(",
              "2",
              ")",
              " group",
              ",",
              " representing",
              " the",
              " central",
              " axis",
              " of",
              " the",
              " double",
              " hel",
              "ix",
              ".",
              " DNA",
              " replication",
              ",",
              " involving",
              " the",
              " unw",
              "inding",
              " and",
              " copying",
              " of",
              " strands",
              ",",
              " can",
              " be",
              " understood",
              " through",
              " rotations",
              " on",
              " the",
              " ",
              "3",
              "-s",
              "phere",
              " S",
              "³",
              ".",
              " Here",
              "'s",
              " a",
              " structured",
              " explanation",
              " of",
              " this",
              " model",
              ":\n\n",
              "1",
              ".",
              " **",
              "SU",
              "(",
              "2",
              ")",
              " Representation",
              "**:",
              " \n",
              "  ",
              " -",
              " SU",
              "(",
              "2",
              ")",
              " is",
              " a",
              " special",
              " unit",
              "ary",
              " group",
              " that",
              " can",
              " be",
              " represented",
              " using",
              " qu",
              "atern",
              "ions",
              ",",
              " which",
              " are",
              " ideal",
              " for",
              " describing",
              " rotations",
              " in",
              " ",
              "3",
              "D",
              " space",
              ".",
              " This",
              " group",
              " serves",
              " as",
              " a",
              " double",
              " cover",
              " of",
              " SO",
              "(",
              "3",
              "),",
              " meaning",
              " each",
              " rotation",
              " in",
              " SO",
              "(",
              "3",
              ")",
              " corresponds",
              " to",
              " two",
              " elements",
              " in",
              " SU",
              "(",
              "2",
              ").\n",
              "  ",
              " -",
              " The",
              " DNA",
              "'s",
              " central",
              " axis",
              " can",
              " be",
              " metaphor",
              "ically",
              " represented",
              " as",
              " an",
              " SU",
              "(",
              "2",
              ")",
              " spine",
              ",",
              " with",
              " the",
              " double",
              " hel",
              "ix",
              " strands",
              " wrapping",
              " around",
              " it",
              ".\n\n",
              "2",
              ".",
              " **",
              "Rep",
              "lication",
              " as",
              " Rot",
              "ations",
              "**",
              ":\n",
              "  ",
              " -",
              " DNA",
              " replication",
              " involves",
              " the",
              " unw",
              "inding",
              " of",
              " the",
              " double",
              " hel",
              "ix",
              ",",
              " with",
              " each",
              " strand",
              " serving",
              " as",
              " a",
              " template",
              ".",
              " This",
              " process",
              " can",
              " be",
              " modeled",
              " as",
              " rotations",
              " within",
              " the",
              " SU",
              "(",
              "2",
              ")",
              " group",
              ".\n",
              "  ",
              " -",
              " The",
              " replication",
              " fork",
              "'s",
              " movement",
              " along",
              " the",
              " DNA",
              " can",
              " be",
              " associated",
              " with",
              " transformations",
              " in",
              " SU",
              "(",
              "2",
              "),",
              " ensuring",
              " the",
              " geometric",
              " phase",
              " remains",
              " invariant",
              ".",
              " This",
              " in",
              "var",
              "iance",
              " is",
              " crucial",
              " for",
              " maintaining",
              " the",
              " integrity",
              " of",
              " genetic",
              " information",
              ".\n\n",
              "3",
              ".",
              " **",
              "Berry",
              "'s",
              " Connection",
              " and",
              " Ge",
              "ometric",
              " Phase",
              "**",
              ":\n",
              "  ",
              " -",
              " Berry",
              "'s",
              " connection",
              " from",
              " quantum",
              " mechanics",
              " is",
              " relevant",
              " here",
              ",",
              " describing",
              " how",
              " quantum",
              " states",
              " evolve",
              " under",
              " ad",
              "i",
              "ab",
              "atic",
              " changes",
              ".",
              " In",
              " DNA",
              " replication",
              ",",
              " this",
              " connection",
              " ensures",
              " that",
              " the",
              " top",
              "ological",
              " state",
              " of",
              " the",
              " DNA",
              " is",
              " preserved",
              ",",
              " preventing",
              " errors",
              " during",
              " replication",
              ".\n",
              "  ",
              " -",
              " The",
              " geometric",
              " phase",
              ",",
              " or",
              " Berry",
              " phase",
              ",",
              " remains",
              " invariant",
              ",",
              " ensuring",
              " that",
              " despite",
              " the",
              " mechanical",
              " stress",
              " of",
              " replication",
              ",",
              " the",
              " DNA",
              "'s",
              " top",
              "ological",
              " state",
              " is",
              " maintained",
              ".\n\n",
              "4",
              ".",
              " **",
              "3",
              "-S",
              "phere",
              " S",
              "³",
              "**",
              ":\n",
              "  ",
              " -",
              " The",
              " replication",
              " process",
              " can",
              " be",
              " visual",
              "ized",
              " on",
              " S",
              "³",
              ",",
              " the",
              " space",
              " of",
              " unit",
              " qu",
              "atern",
              "ions",
              ",",
              " where",
              " each",
              " rotation",
              " corresponds",
              " to",
              " a",
              " transformation",
              " of",
              " the",
              " DNA",
              " strands",
              ".\n",
              "  ",
              " -",
              " The",
              " in",
              "var",
              "iance",
              " of",
              " the",
              " geometric",
              " phase",
              " ensures",
              " that",
              " the",
              " replication",
              " process",
              " does",
              " not",
              " introduce",
              " twists",
              " or",
              " knots",
              ",",
              " crucial",
              " for",
              " accurate",
              " information",
              " replication",
              ".\n\n",
              "5",
              ".",
              " **",
              "Top",
              "ological",
              " Stability",
              " and",
              " Imp",
              "lications",
              "**",
              ":\n",
              "  ",
              " -",
              " The",
              " model",
              " lever",
              "ages",
              " top",
              "ological",
              " in",
              "variants",
              ",",
              " such",
              " as",
              " linking",
              " number",
              " and",
              " twist",
              ",",
              " to",
              " understand",
              " how",
              " DNA",
              " maintains",
              " its",
              " structure",
              " during",
              " replication",
              ".\n",
              "  ",
              " -",
              " This",
              " approach",
              " could",
              " have",
              " implications",
              " for",
              " understanding",
              " DNA",
              " repair",
              " mechanisms",
              " and",
              " the",
              " effects",
              " of",
              " drugs",
              " targeting",
              " replication",
              " processes",
              ".\n\n",
              "6",
              ".",
              " **",
              "Potential",
              " Applications",
              "**",
              ":\n",
              "  ",
              " -",
              " The",
              " model",
              " offers",
              " insights",
              " into",
              " synthetic",
              " biology",
              " and",
              " DNA",
              "-based",
              " data",
              " storage",
              ",",
              " aiding",
              " in",
              " the",
              " design",
              " of",
              " efficient",
              " DNA",
              " constructs",
              " without",
              " replication",
              " errors",
              ".\n\n",
              "In",
              " conclusion",
              ",",
              " modeling",
              " DNA",
              " replication",
              " using",
              " SU",
              "(",
              "2",
              ")",
              " and",
              " S",
              "³",
              " provides",
              " a",
              " profound",
              " mathematical",
              " framework",
              ",",
              " enhancing",
              " our",
              " understanding",
              " of",
              " DNA",
              "'s",
              " top",
              "ological",
              " aspects",
              " and",
              " potential",
              " applications",
              " in",
              " bi",
              "otechnology",
              ".",
              ""
            ],
            "prompt": "You proposed that the structure of the DNA can be represented as a spine SU(2), and this is very elegant. Since SU(2) is a double coating of SO(3), you can perhaps build a model where replication occurs by rotation on S³ (the 3D sphere), keeping the geometric phase invariant. I suggest you refer to Berry's connection in this context—it can provide a topological link to the informational stability of the duplication process."
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Leave blank to randomize the seed.",
          "top_k": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering).",
          "top_p": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751).",
          "prompt": "Prompt",
          "max_tokens": "The maximum number of tokens the model should generate as output.",
          "min_tokens": "The minimum number of tokens the model should generate as output.",
          "temperature": "The value used to modulate the next token probabilities.",
          "system_prompt": "System prompt to send to the model. This is prepended to the prompt and helps guide system behavior. Ignored for non-chat models.",
          "stop_sequences": "A comma-separated list of sequences to stop generation at. For example, '<end>,<stop>' will stop generation at the first instance of 'end' or '<stop>'.",
          "prompt_template": "A template to format the prompt with. If not provided, the default prompt template will be used.",
          "presence_penalty": "Presence penalty",
          "frequency_penalty": "Frequency penalty"
        }
      }
    },
    {
      "id": "kingnothininc/rebel",
      "name": "rebel",
      "displayName": "rebel",
      "provider": "replicate",
      "category": "image",
      "endpoint": "kingnothininc/rebel",
      "version": "557f992314e34aa23ee34ac8c2b45b5813fe458221c4142f4c0fb060dd0ed50a",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "rebel generates images that feel like memories of an era long gone but ever present, etched in time.",
        "runCount": 33,
        "confidence": 0.6,
        "qualityScore": 35.31478917042255,
        "createdAt": "2025-04-09T21:26:36.445941Z",
        "owner": "kingnothininc",
        "coverImage": "https://replicate.delivery/xezq/Gj0cblTlkaZWGpqPPHzuZzRsTTtr8caMZ9JTVnaZCwh3fiQKA/out-2.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "width": 1024,
              "height": 1440,
              "prompt": "create an iconic image in 4K of cinema quality of SMITTY leaning casually against a brick wall. He is wearing a black coat, sunglasses, his full head of hair is messy but styled . This is a front facing image with incredible detail\n\n\n",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 3,
              "aspect_ratio": "16:9",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 87,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/B5GT8fsufefuvSaeWTVfzOT3eCcmMXJQvunzvMwTizbLvfFhUA/out-0.webp",
              "https://replicate.delivery/xezq/XP1D9vpMlIprGhPimdxWs80ovmCyy1ebZnBKkJTcAXIvfFhUA/out-1.webp",
              "https://replicate.delivery/xezq/Gj0cblTlkaZWGpqPPHzuZzRsTTtr8caMZ9JTVnaZCwh3fiQKA/out-2.webp"
            ],
            "prompt": "create an iconic image in 4K of cinema quality of SMITTY leaning casually against a brick wall. He is wearing a black coat, sunglasses, his full head of hair is messy but styled . This is a front facing image with incredible detail\n\n\n"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "tsukuyomi260/judith",
      "name": "judith",
      "displayName": "judith",
      "provider": "replicate",
      "category": "image",
      "endpoint": "tsukuyomi260/judith",
      "version": "bd59ea47d79a93bf47f244080b9fce721ec35da13ddba26b4228912fe279afb1",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Un modèle qui génere des image qui ressemble à judith",
        "runCount": 31,
        "confidence": 0.6,
        "qualityScore": 35.05149978319906,
        "createdAt": "2025-05-20T23:11:14.200809Z",
        "owner": "tsukuyomi260",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/710cd5d6-801b-41e7-800d-d4eb2ee0da6f/4a3009972d581bd5e2209aa4e4f8a342-.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "Portrait de Judith ",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/eDRaoaPM2uSqOi6NRYcPgBP52zvlAdkwlet0GJSA8N2SRtuUA/out-0.webp"
            ],
            "prompt": "Portrait de Judith "
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "fofr/kontext-fix-jpeg-compression",
      "name": "kontext-fix-jpeg-compression",
      "displayName": "kontext-fix-jpeg-compression",
      "provider": "replicate",
      "category": "image",
      "endpoint": "fofr/kontext-fix-jpeg-compression",
      "version": "6943369d68c9e8e6504108407cdff40563f915a0a4319d3c765d49acf2eab407",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Use this flux-kontext fine-tune to fix JPEG compression artifacts",
        "runCount": 29,
        "confidence": 0.9,
        "qualityScore": 34.771212547196626,
        "createdAt": "2025-07-15T14:14:49.253891Z",
        "owner": "fofr",
        "coverImage": "https://replicate.delivery/xezq/tvfGu450OcXFQSmN2yEE05JdpZdLyasKaXGhGE1aV0snrggKA/output.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "fix the jpeg compression",
              "guidance": 2.5,
              "megapixels": "1",
              "input_image": "https://replicate.delivery/pbxt/NMXQSSrI44aaaioCIxP9fU6bB7aNtB11nLcJ2uATvN4zUVrx/jpeg-compressed.jpg",
              "aspect_ratio": "4:3",
              "lora_strength": 1,
              "output_format": "webp",
              "output_quality": 80,
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/xezq/tvfGu450OcXFQSmN2yEE05JdpZdLyasKaXGhGE1aV0snrggKA/output.webp",
            "prompt": "fix the jpeg compression"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible generation. Leave blank for random.",
          "prompt": "Text description of what you want to generate, or the instruction on how to edit the given image.",
          "guidance": "Guidance scale for generation",
          "megapixels": "Approximate number of megapixels for generated image",
          "input_image": "Image to use as reference. Must be jpeg, png, gif, or webp.",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "lora_strength": "Strength of the lora",
          "output_format": "Output image format",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "replicate_weights": "Path to the lora weights",
          "num_inference_steps": "Number of inference steps",
          "disable_safety_checker": "Disable NSFW safety checker"
        }
      }
    },
    {
      "id": "aditya000099/landing-page-ui",
      "name": "landing-page-ui",
      "displayName": "landing-page-ui",
      "provider": "replicate",
      "category": "image",
      "endpoint": "aditya000099/landing-page-ui",
      "version": "69833d963dacb9b7b392d1d0470ecd7e3cf7347991154aff0244e77c6d0bff0d",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "This model Generates Hero sections for landing page. Can be used for design inspirations. You need to moderately design your prompt.",
        "runCount": 29,
        "confidence": 0.6,
        "qualityScore": 34.771212547196626,
        "createdAt": "2025-07-07T05:44:00.582298Z",
        "owner": "aditya000099",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/99526479-3083-48db-ba7d-1618190fb627/cov.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "schnell",
              "prompt": "Landing website and app development agency ui, modern dark themed, ",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "16:9",
              "output_format": "png",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/GsY4Ha6zf2xUPys2DtGELzAmARKHlL9SOJS0kPSWeNw1NRepA/out-0.png"
            ],
            "prompt": "Landing website and app development agency ui, modern dark themed, "
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "astramlco/easycontrol-ghibli",
      "name": "easycontrol-ghibli",
      "displayName": "easycontrol-ghibli",
      "provider": "replicate",
      "category": "image",
      "endpoint": "astramlco/easycontrol-ghibli",
      "version": "9ad8a8970c83024fbce9ea054bb62652fec08c6c12dd39eda39cd0833ad36e2f",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Make images in Studio Ghibli art style",
        "runCount": 2994,
        "confidence": 0.6,
        "qualityScore": 34.763968267253304,
        "createdAt": "2025-04-18T11:11:46.976207Z",
        "owner": "astramlco",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/dbe58d3a-7731-450d-8ce2-709903245145/mother_and_daughter.webp",
        "githubUrl": "https://github.com/Xiaojiu-z/EasyControl",
        "paperUrl": "https://arxiv.org/abs/2503.07027",
        "licenseUrl": "https://github.com/Xiaojiu-z/EasyControl/blob/main/LICENSE",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": 42,
              "width": 1024,
              "height": 640,
              "prompt": "Ghibli Studio style, Charming hand-drawn anime-style illustration",
              "zero_steps": 1,
              "spatial_img": "https://replicate.delivery/pbxt/MrG49FYK6CNEUu543tYO11kboFgD2HiqWyzs8nh9frBRP4Tq/replicate-prediction-rggsm01t8hrmc0cp6d6b8y672w.webp",
              "control_type": "Ghibli",
              "output_format": "png",
              "use_zero_init": true,
              "output_quality": 90
            },
            "output": [
              "https://replicate.delivery/xezq/s7JZmWjLR6bZFx4cMLmSOGnRyjd8rcruedQo5FlHHQpMRfjUA/output_seed42.png"
            ],
            "prompt": "Ghibli Studio style, Charming hand-drawn anime-style illustration"
          }
        ],
        "parameterDescriptions": {
          "seed": "Set a random seed for generation (-1 for random).",
          "width": "Set the width of the generated image (pixels).",
          "height": "Set the height of the generated image (pixels).",
          "prompt": "Enter a text prompt to guide image generation.",
          "zero_steps": "Zero init steps.",
          "spatial_img": "Ghibli-style spatial control image.",
          "control_type": "Control type (currently only Ghibli supported).",
          "output_format": "Choose the format of the output images.",
          "use_zero_init": "Use CFG zero star.",
          "output_quality": "Set the quality of the output image for jpg and webp (1-100)."
        }
      }
    },
    {
      "id": "tuannha/instant-character",
      "name": "instant-character",
      "displayName": "instant-character",
      "provider": "replicate",
      "category": "image",
      "endpoint": "tuannha/instant-character",
      "version": "df5eed34fa9c812acf62d3ca79874daf9b5e78c2bee11f4ada182a55dd5c1712",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Tencent Instant Character",
        "runCount": 2901,
        "confidence": 0.9,
        "qualityScore": 34.626974081017174,
        "createdAt": "2025-04-18T03:57:56.699354Z",
        "owner": "tuannha",
        "coverImage": "https://replicate.delivery/xezq/wtf5hwaR2EwgVaEsMDU41pBCcjntw5wVOG99ujj9NPWi37RKA/73dbbbd9-314a-4cd8-8022-cb77a6ae877b.png",
        "githubUrl": "https://github.com/Tencent/InstantCharacter",
        "paperUrl": null,
        "licenseUrl": "https://github.com/Tencent/InstantCharacter/blob/main/License.txt",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "lora": "ghibli_style",
              "seed": -1,
              "width": 768,
              "height": 1344,
              "prompt": "a character in the library",
              "subject_image": "https://replicate.delivery/pbxt/Mr9015ajTj5WrUEuW6YyWbxxRifCNCo0SbiA0L0F4vqjQmXS/face.png",
              "guidance_scale": 3.5,
              "num_inference_steps": 28
            },
            "output": "https://replicate.delivery/xezq/wtf5hwaR2EwgVaEsMDU41pBCcjntw5wVOG99ujj9NPWi37RKA/73dbbbd9-314a-4cd8-8022-cb77a6ae877b.png",
            "prompt": "a character in the library"
          }
        ],
        "parameterDescriptions": {
          "lora": "Lora to use",
          "seed": "Seed for the random number generator, -1 for random",
          "width": "Width of the output image",
          "height": "Height of the output image",
          "prompt": "Prompt for the image generation",
          "subject_image": "Grayscale input image",
          "guidance_scale": "Guidance scale for the diffusion process",
          "num_inference_steps": "Number of diffusion steps"
        }
      }
    },
    {
      "id": "lucataco/wan2.1-4step",
      "name": "wan2.1-4step",
      "displayName": "wan2.1-4step",
      "provider": "replicate",
      "category": "video",
      "endpoint": "lucataco/wan2.1-4step",
      "version": "e3e2b581dffc5a971ab8ef6322f53d93b83c277ec802a5d6bae0f3b62cf592bf",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Wan 2.1 I2V (14B) 480p with CausVid LoRA",
        "runCount": 2847,
        "confidence": 0.9,
        "qualityScore": 34.545399849648184,
        "createdAt": "2025-07-11T15:02:16.452089Z",
        "owner": "lucataco",
        "coverImage": "https://replicate.delivery/xezq/J7mBrXmX6nqgPl9z0E4GgU2ZnWzQfzgFlgirB0gA0wjm22fUA/tmpa5txyvy3.mp4",
        "githubUrl": "https://github.com/lucataco/cog-wan2.1-4step",
        "paperUrl": null,
        "licenseUrl": "https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "steps": 4,
              "prompt": "a black horse galloping across a desert",
              "num_frames": 81,
              "input_image": "https://replicate.delivery/pbxt/NKQD3gyTJ8GgTl6oHVXPaOKR6kr9iiVMs0RMQs86bQYOkaq7/replicate-prediction-phq4vkntgxrme0cqxz0a9amv5w.jpg",
              "guidance_scale": 1,
              "negative_prompt": "",
              "frames_per_second": 16
            },
            "output": "https://replicate.delivery/xezq/J7mBrXmX6nqgPl9z0E4GgU2ZnWzQfzgFlgirB0gA0wjm22fUA/tmpa5txyvy3.mp4",
            "prompt": "a black horse galloping across a desert"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible results. Set to -1 for random seed",
          "steps": "Number of inference steps. More steps = higher quality but slower",
          "width": "Output width (will be auto-calculated if not provided, must be multiple of 32)",
          "height": "Output height (will be auto-calculated if not provided, must be multiple of 32)",
          "prompt": "Text prompt describing the desired animation or motion",
          "num_frames": "Number of frames to generate",
          "input_image": "Input image to animate",
          "guidance_scale": "Controls adherence to the prompt. Higher values = more adherence",
          "negative_prompt": "Negative prompt to avoid unwanted elements",
          "frames_per_second": "Frames per second for the output video"
        }
      }
    },
    {
      "id": "heyhomies/plastic_container",
      "name": "plastic_container",
      "displayName": "plastic_container",
      "provider": "replicate",
      "category": "image",
      "endpoint": "heyhomies/plastic_container",
      "version": "16689f8179533c7430a279ea6260e9c02fc49d8e26cb647145ecc7112917b700",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "a translucent 5 litres plastic container made from HDPE, for storage and transport of liquid, flavored drink concentrate.",
        "runCount": 22,
        "confidence": 0.6,
        "qualityScore": 33.61727836017593,
        "createdAt": "2025-06-12T09:40:03.805960Z",
        "owner": "heyhomies",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/2617f374-2bd0-4c78-9f29-32650b28576f/Waldmeister_Kanister_3.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": 6152,
              "image": "https://replicate.delivery/pbxt/NAlPLGUYN7MUssVvZ1FYlT2oEkfLQmNYyWlyiv7k5zd8PMZB/replicate-prediction-cp41x8qfn5rma0cqced8wr9z90.png",
              "model": "dev",
              "width": 1024,
              "height": 1024,
              "prompt": "Show the plastic_container in a side view, filled to 7/8 with peach-orange syrup, isolated on a white background. The lid needs to keep its black color.",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "png",
              "guidance_scale": 2,
              "output_quality": 90,
              "prompt_strength": 0.5,
              "extra_lora_scale": 1,
              "num_inference_steps": 37
            },
            "output": [
              "https://replicate.delivery/xezq/0sb6M1mPLhqZGlr9zFEb54NL4XQU8Teb692pbFqyHOCs0CbKA/out-0.png"
            ],
            "prompt": "Show the plastic_container in a side view, filled to 7/8 with peach-orange syrup, isolated on a white background. The lid needs to keep its black color."
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "dekaselinos/cartoon_90s_style",
      "name": "cartoon_90s_style",
      "displayName": "cartoon_90s_style",
      "provider": "replicate",
      "category": "image",
      "endpoint": "dekaselinos/cartoon_90s_style",
      "version": "0fa908602ef6c6259b41f5b8d8c14956252cbf197897cce9adb21e8d16478ed0",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Transforms pet photos into high-quality 90s Disney-style cartoon illustrations with accurate fur details and charming expressions.",
        "runCount": 21,
        "confidence": 0.6,
        "qualityScore": 33.42422680822206,
        "createdAt": "2025-07-03T19:44:26.221897Z",
        "owner": "dekaselinos",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/51bdf951-7d29-436b-9c6e-10a5b9baae3c/New_Project_8.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/NIwqRHOKgK1MZsKpxGXFODhThaFrUbTV6zVv1k0uVdr3kNkD/pexels-svetozar-milashevich-99573-1490908.jpg",
              "model": "dev",
              "prompt": "disneycartoon style, full-body portrait of an adorable Golden Retriever dog, clearly recognizable as a Golden Retriever, with accurate fur color and texture based on the uploaded image, joyful and expressive facial expression, smooth line art, soft shading, fluffy coat, big round eyes, Pixar-quality character design, clean vibrant background, classic hand-drawn Disney animation style, detailed 2D cartoon illustration",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/VaJPqY5zCK7PHpqjnoQMcZr2hf6ONUezafgen69x0ne2KgtnC/out-0.webp"
            ],
            "prompt": "disneycartoon style, full-body portrait of an adorable Golden Retriever dog, clearly recognizable as a Golden Retriever, with accurate fur color and texture based on the uploaded image, joyful and expressive facial expression, smooth line art, soft shading, fluffy coat, big round eyes, Pixar-quality character design, clean vibrant background, classic hand-drawn Disney animation style, detailed 2D cartoon illustration"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "jigsawstack/image-generation",
      "name": "image-generation",
      "displayName": "image-generation",
      "provider": "replicate",
      "category": "image",
      "endpoint": "jigsawstack/image-generation",
      "version": "43d5bce2e1c97fa1e7d8996187a85cd5c882787989091af3b135c7a16ca23b79",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate an image based on the given text by employing AI models like Flux, Stable Diffusion, and other top models.",
        "runCount": 20,
        "confidence": 0.9,
        "qualityScore": 33.222192947339195,
        "createdAt": "2025-06-24T18:40:01.466576Z",
        "owner": "jigsawstack",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/3860dd66-888c-4b57-b28e-0a71e767b3d9/Desktop_Hd_Wllpaper.jpeg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "steps": 4,
              "prompt": "Generate me an image of ocean",
              "api_key": "sk_ba8d51db7829aef7ec445bb80dd59b7ff2c320d851eb6ae4cf41aacfab4df81c690774957983ebcc02f08429fccdfe42b4d8ee6a40b404399c10ca3bcabdbb72024KnIELzWIzzblw1gtM6",
              "aspect_ratio": "16:9",
              "output_format": "png"
            },
            "output": "https://replicate.delivery/xezq/zqqhsjDgDYbRGFfd6zZDs2yVXop4yZ7F6jxH7p6t3WMkAldKA/output.png",
            "prompt": "Generate me an image of ocean"
          }
        ],
        "parameterDescriptions": {
          "url": "A valid URL where the generated image will be sent",
          "seed": "Makes generation deterministic. Using the same seed and set of parameters will produce identical image each time.",
          "steps": "The number of denoising steps. Must be between 1-90. Higher values produce better quality images but take more time to generate.",
          "width": "The width of the image. Must be between 256-1920 pixels.",
          "height": "The height of the image. Must be between 256-1920 pixels.",
          "prompt": "The text prompt to generate the image from. Must be between 1-5000 characters.",
          "api_key": "🔐 Your JigsawStack API Key (required)",
          "guidance": "Higher guidance forces the model to better follow the prompt, but may result in lower quality output. Must be between 1-28.",
          "aspect_ratio": "The aspect ratio of the generated image",
          "output_format": "The output format of the generated image",
          "file_store_key": "Key to store the generated image in file storage",
          "negative_prompt": "Text describing what you don't want in the image"
        }
      }
    },
    {
      "id": "fofr/flux-my-subconscious",
      "name": "flux-my-subconscious",
      "displayName": "flux-my-subconscious",
      "provider": "replicate",
      "category": "image",
      "endpoint": "fofr/flux-my-subconscious",
      "version": "de1b628b969c5c1c31c9cad1916eb74a4dfbaed6e1612f61a0e6af45718cecd9",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A flux fine tune of my subconscious",
        "runCount": 1738,
        "confidence": 0.6,
        "qualityScore": 32.40299582002712,
        "createdAt": "2025-03-12T18:01:14.096037Z",
        "owner": "fofr",
        "coverImage": "https://replicate.delivery/xezq/sJXpoTybt0ryKBJrUIjNv1WU6PjVxfc4CBLjPsCyPykeV4XUA/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "MY_SUBCONSCIOUS ",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/sJXpoTybt0ryKBJrUIjNv1WU6PjVxfc4CBLjPsCyPykeV4XUA/out-0.webp"
            ],
            "prompt": "MY_SUBCONSCIOUS "
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "aakashapoorv/synthwave",
      "name": "synthwave",
      "displayName": "synthwave",
      "provider": "replicate",
      "category": "image",
      "endpoint": "aakashapoorv/synthwave",
      "version": "4d91fe4a4621f808a6e9d04c57b420f658d60ea2651becae2b74c555ec6009d7",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "neon-soaked, synth-powered aesthetics of 1980s retro-futurism.",
        "runCount": 16,
        "confidence": 0.6,
        "qualityScore": 32.30448921378274,
        "createdAt": "2025-06-09T23:52:03.803037Z",
        "owner": "aakashapoorv",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/3ffcbef8-d2d3-40eb-96e1-6a80cc49ed58/replicate-prediction-3tgn96s01xr.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "schnell",
              "prompt": "SYNTHWAVE: A sweeping aerial shot of New York City at dusk, neon-lit skyscrapers piercing a violet sky above steam rising from street vents on rain-slick avenues below. Times Square’s holographic billboards blaze in hot pink and electric blue, their reflections dancing across wet taxi roofs. A lone figure stands on a chrome fire escape, leather jacket glowing with UV-purple circuitry, gazing out over the grid of glowing windows and monorail tracks weaving between Art Deco towers. ",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/7G4IOG8RPG6KOp4KIcUnLXyLj9iifFntbqqPoeXgdJCmflqpA/out-0.webp"
            ],
            "prompt": "SYNTHWAVE: A sweeping aerial shot of New York City at dusk, neon-lit skyscrapers piercing a violet sky above steam rising from street vents on rain-slick avenues below. Times Square’s holographic billboards blaze in hot pink and electric blue, their reflections dancing across wet taxi roofs. A lone figure stands on a chrome fire escape, leather jacket glowing with UV-purple circuitry, gazing out over the grid of glowing windows and monorail tracks weaving between Art Deco towers. "
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "eligharon/beaver-ai-v1",
      "name": "beaver-ai-v1",
      "displayName": "beaver-ai-v1",
      "provider": "replicate",
      "category": "image",
      "endpoint": "eligharon/beaver-ai-v1",
      "version": "7c40a2b07fdcdc9e2c97ce04d377b241f5a72a7e8f8aeadecd6ac7a7c1462cda",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generates image of creek with long-term beaver presence. Trained on 15 images.",
        "runCount": 16,
        "confidence": 0.6,
        "qualityScore": 32.30448921378274,
        "createdAt": "2025-05-07T20:15:21.348542Z",
        "owner": "eligharon",
        "coverImage": "https://replicate.delivery/xezq/zfuqJOgQerhTaUHX86FH7wIafgk9vT4h9XVUiefhK7tCRBTlC/out-0.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/My9SMGKJcjsHzxykW9SsFmPinOvCCD8znvY7qmwEd0OFvdL0/test_1.jpg",
              "model": "dev",
              "prompt": "Restore this exact creek segment using BEAVERAI. Keep same landscape and camera view. Add a low beaver dam with woody debris in water. Increase water depth, form small ponds and flooded margins. Lush green sedges, grasses, and willow sprouts fill the riparian zone. No change to uplands or horizon.",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "png",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.6,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/zfuqJOgQerhTaUHX86FH7wIafgk9vT4h9XVUiefhK7tCRBTlC/out-0.png"
            ],
            "prompt": "Restore this exact creek segment using BEAVERAI. Keep same landscape and camera view. Add a low beaver dam with woody debris in water. Increase water depth, form small ponds and flooded margins. Lush green sedges, grasses, and willow sprouts fill the riparian zone. No change to uplands or horizon."
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "mhohenwald/psgreenboy",
      "name": "psgreenboy",
      "displayName": "psgreenboy",
      "provider": "replicate",
      "category": "image",
      "endpoint": "mhohenwald/psgreenboy",
      "version": "bc2f812813edc945f814d55dbb411df5fe8097cd8540d10bc586855b3ababbe8",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "a 16-year-old male teenager with brown medium-length hair, wearing a green T-shirt, blue jeans and sneakers.",
        "runCount": 15,
        "confidence": 0.6,
        "qualityScore": 32.04119982655925,
        "createdAt": "2025-02-28T11:12:57.543433Z",
        "owner": "mhohenwald",
        "coverImage": "https://replicate.delivery/xezq/7XTahFH89e2zSyD7O6nbqKfZfR11Mk9be8MnMGdxeZUgVoeEF/out-0.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "a portrait from PSGREENBOY sitting on his Bed, looking at his smartphone",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "16:9",
              "output_format": "png",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/7XTahFH89e2zSyD7O6nbqKfZfR11Mk9be8MnMGdxeZUgVoeEF/out-0.png"
            ],
            "prompt": "a portrait from PSGREENBOY sitting on his Bed, looking at his smartphone"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "fofr/wan-14b-laezel",
      "name": "wan-14b-laezel",
      "displayName": "wan-14b-laezel",
      "provider": "replicate",
      "category": "image",
      "endpoint": "fofr/wan-14b-laezel",
      "version": "47f42ccb2ed4659754ba103fb0c915d0cce85532af6137fc68a2375eb4c60480",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Wan2.1 14b fine-tuned on the Baldur's Gate 3 character Laezel",
        "runCount": 14,
        "confidence": 0.6,
        "qualityScore": 31.760912590556813,
        "createdAt": "2025-03-12T11:22:53.003672Z",
        "owner": "fofr",
        "coverImage": "https://replicate.delivery/xezq/i9enM2xXXNT1Siglhh15IvZvpoMRlytk2sqegWUz6rpcHzXUA/R8_Wan_00001.mp4",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "frames": 81,
              "prompt": "a scene where LAEZEL is laughing in a cafe, warm, bokeh, fireplace",
              "aspect_ratio": "16:9",
              "sample_shift": 8,
              "sample_steps": 30,
              "negative_prompt": "",
              "lora_strength_clip": 1,
              "sample_guide_scale": 5,
              "lora_strength_model": 1
            },
            "output": [
              "https://replicate.delivery/xezq/i9enM2xXXNT1Siglhh15IvZvpoMRlytk2sqegWUz6rpcHzXUA/R8_Wan_00001.mp4"
            ],
            "prompt": "a scene where LAEZEL is laughing in a cafe, warm, bokeh, fireplace"
          }
        ],
        "parameterDescriptions": {
          "seed": "Set a seed for reproducibility. Random by default.",
          "image": "Image to use as a starting frame for image to video generation.",
          "frames": "The number of frames to generate (1 to 5 seconds)",
          "prompt": "Text prompt for video generation",
          "fast_mode": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.",
          "resolution": "The resolution of the video. 720p is not supported for 1.3b.",
          "aspect_ratio": "The aspect ratio of the video. 16:9, 9:16, 1:1, etc.",
          "sample_shift": "Sample shift factor",
          "sample_steps": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts",
          "negative_prompt": "Things you do not want to see in your video",
          "replicate_weights": "Replicate LoRA weights to use. Leave blank to use the default weights.",
          "lora_strength_clip": "Strength of the LORA applied to the CLIP model. 0.0 is no LORA.",
          "sample_guide_scale": "Higher guide scale makes prompt adherence better, but can reduce variation",
          "lora_strength_model": "Strength of the LORA applied to the model. 0.0 is no LORA."
        }
      }
    },
    {
      "id": "runwayml/gen4-turbo",
      "name": "gen4-turbo",
      "displayName": "gen4-turbo",
      "provider": "replicate",
      "category": "video",
      "endpoint": "runwayml/gen4-turbo",
      "version": "0d5997be6feb0a5d1f296511d61d129d70cf10e1a30e2bcb25a7ec4addc034a9",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate 5s and 10s 720p videos fast",
        "runCount": 1282,
        "confidence": 0.9,
        "qualityScore": 31.082266563749283,
        "createdAt": "2025-07-22T10:13:22.350947Z",
        "owner": "runwayml",
        "coverImage": "https://tjzk.replicate.delivery/models_models_featured_image/32f1975a-faa7-419b-8781-01c2f1593dc4/replicate-prediction-y3p6xca9r.mp4",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/xezq/gJcowhBpVT68BJkEZMsvVVQvuFCbua5dyCtSnJ8IoffwpQDVA/tmpluu1raon.png",
              "prompt": "she walks slowly forward, a breeze blows the wheat, a lightning strike in the distance",
              "duration": 5,
              "aspect_ratio": "16:9"
            },
            "output": "https://replicate.delivery/xezq/cfzezDWlUogXCEeVhG2qFmR5JMkB7ZXpa8ej7bDp6CRX8CNUB/tmp0v9ykzlp.mp4",
            "prompt": "she walks slowly forward, a breeze blows the wheat, a lightning strike in the distance"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "image": "Initial image for video generation (first frame)",
          "prompt": "Text prompt for video generation",
          "duration": "Duration of the output video in seconds",
          "aspect_ratio": "Video aspect ratio"
        }
      }
    },
    {
      "id": "mikaconcept/divin",
      "name": "divin",
      "displayName": "divin",
      "provider": "replicate",
      "category": "image",
      "endpoint": "mikaconcept/divin",
      "version": "c162e2f43c637823d34f360fd31310e6ed8eb87a8f7581fac178db452c2f9413",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Un modèle qui génère des images qui ressemble à 100/100 Divin",
        "runCount": 10,
        "confidence": 0.6,
        "qualityScore": 30.41392685158225,
        "createdAt": "2025-05-04T03:51:53.926613Z",
        "owner": "mikaconcept",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/0dcc757b-1da1-4677-992e-c5f18b52276b/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "a linkedin portrait of divin. is a man ",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 2,
              "aspect_ratio": "1:1",
              "output_format": "jpg",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/WeYkrZk4Tuyxdio3LGIAnmXBfu0JnB91KputR8OLoe7BQYSpA/out-0.jpg",
              "https://replicate.delivery/xezq/31FsNs4d0eUiZSp2cGxyaAI19rOuxyiqfVezay6thrMAQYSpA/out-1.jpg"
            ],
            "prompt": "a linkedin portrait of divin. is a man "
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "babysea/babyavatar",
      "name": "babyavatar",
      "displayName": "babyavatar",
      "provider": "replicate",
      "category": "image",
      "endpoint": "babysea/babyavatar",
      "version": "a9988c61fc9f56e6fe0e2678e4233f0a45aa0e069cadc3caa9d903d5a46e86e3",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "BabyAvatar - Create Stunning AI Avatars in Seconds",
        "runCount": 811,
        "confidence": 0.6,
        "qualityScore": 29.09556029241175,
        "createdAt": "2025-07-25T20:53:43.712937Z",
        "owner": "babysea",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/4a5936f7-3f14-4dae-89c1-216bfad5c735/card.png",
        "githubUrl": "https://github.com/BabySea-AI/babyavatar-model",
        "paperUrl": null,
        "licenseUrl": "https://terms.babysea.ai/licenses/creativeml-open-rail-m-license",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "width": 1024,
              "height": 1024,
              "prompt": "a Modern Anime woman, professional digital illustration with vibrant saturated colors, pristine high-quality anime art style, crisp clean linework, rich color depth and shading, beautiful expressive eyes with highlights, detailed intricate hair with proper highlights and shadows, contemporary anime aesthetics as seen in high-budget anime productions, subtle color gradient background complementing character colors, perfect composition with character centered, expert lighting with proper highlights and shadows, detailed facial features matching user photo, high production value animation studio quality, 1024x1024 resolution",
              "refine": "no_refiner",
              "scheduler": "K_EULER",
              "lora_scale": 0.6,
              "num_outputs": 1,
              "guidance_scale": 7.5,
              "apply_watermark": true,
              "high_noise_frac": 0.8,
              "negative_prompt": "worst quality, low quality, normal quality, low-res, skin spots, acne, skin blemishes, age spots, ugly, duplicate, morbid, mutilated, blur, motion-blur, blurry, bokeh, crossed eyes, deformed hands, deformed face, extra fingers, fused fingers, too many fingers, long neck, deformed, disfigured, missing limbs, floating limbs, disconnected limbs, malformed hands, poorly drawn face, poorly drawn hands, multiple images, image grid, collage, side by side images, cartoon, 3d render, long body, bad anatomy, bad hands, digital art style, harsh outlines, high contrast, multiple characters",
              "prompt_strength": 0.8,
              "num_inference_steps": 50
            },
            "output": [
              "https://replicate.delivery/xezq/FJstn4vfVHwBHi5z2CkQXcFNs5cxfgU7eqKGzaSus1OUliYpA/out-0.png"
            ],
            "prompt": "a Modern Anime woman, professional digital illustration with vibrant saturated colors, pristine high-quality anime art style, crisp clean linework, rich color depth and shading, beautiful expressive eyes with highlights, detailed intricate hair with proper highlights and shadows, contemporary anime aesthetics as seen in high-budget anime productions, subtle color gradient background complementing character colors, perfect composition with character centered, expert lighting with proper highlights and shadows, detailed facial features matching user photo, high production value animation studio quality, 1024x1024 resolution"
          }
        ],
        "parameterDescriptions": {
          "mask": "Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted.",
          "seed": "Random seed. Leave blank to randomize the seed",
          "image": "Input image for img2img or inpaint mode",
          "width": "Width of output image",
          "height": "Height of output image",
          "prompt": "Input prompt",
          "refine": "Which refine style to use",
          "scheduler": "scheduler",
          "lora_scale": "LoRA additive scale. Only applicable on trained models.",
          "num_outputs": "Number of images to output.",
          "refine_steps": "For base_image_refiner, the number of steps to refine, defaults to num_inference_steps",
          "guidance_scale": "Scale for classifier-free guidance",
          "apply_watermark": "Applies a watermark to enable determining if an image is generated in downstream applications. If you have other provisions for generating or deploying images safely, you can use this to disable watermarking.",
          "high_noise_frac": "For expert_ensemble_refiner, the fraction of noise to use",
          "negative_prompt": "Input Negative Prompt",
          "prompt_strength": "Prompt strength when using img2img / inpaint. 1.0 corresponds to full destruction of information in image",
          "replicate_weights": "Replicate LoRA weights to use. Leave blank to use the default weights.",
          "num_inference_steps": "Number of denoising steps",
          "disable_safety_checker": "Disable safety checker for generated images. This feature is only available through the API. See [https://replicate.com/docs/how-does-replicate-work#safety](https://replicate.com/docs/how-does-replicate-work#safety)"
        }
      }
    },
    {
      "id": "codefold/portrait",
      "name": "portrait",
      "displayName": "portrait",
      "provider": "replicate",
      "category": "image",
      "endpoint": "codefold/portrait",
      "version": "00f1937eead4fe93d9957fd4b49f88692699d394cbb30512ba2cefb80e59da8f",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Realistic human photgraphy portraits.",
        "runCount": 741,
        "confidence": 0.6,
        "qualityScore": 28.704039052790268,
        "createdAt": "2025-06-28T05:36:12.036970Z",
        "owner": "codefold",
        "coverImage": "https://replicate.delivery/xezq/5lXURgB3YAb0C9SeobciB5dm5HWCXwhuYM2Cebw0hGe2Hn2pA/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "PRTRT of Travis, a physically imposing man in his early 30s. His powerful, muscular physique is evident through his clothing (e.g., a fitted heavy-duty shirt). Short-cropped dark brown hair and natural body hair accentuate his raw masculinity. His face shows a determined, almost stern expression, reflecting his uncompromising intensity and traditional values. Strong, directional lighting to emphasize his rugged features and commanding presence. ",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "2:3",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/5lXURgB3YAb0C9SeobciB5dm5HWCXwhuYM2Cebw0hGe2Hn2pA/out-0.webp"
            ],
            "prompt": "PRTRT of Travis, a physically imposing man in his early 30s. His powerful, muscular physique is evident through his clothing (e.g., a fitted heavy-duty shirt). Short-cropped dark brown hair and natural body hair accentuate his raw masculinity. His face shows a determined, almost stern expression, reflecting his uncompromising intensity and traditional values. Strong, directional lighting to emphasize his rugged features and commanding presence. "
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "mark-henry/flux-mrkhnry",
      "name": "flux-mrkhnry",
      "displayName": "flux-mrkhnry",
      "provider": "replicate",
      "category": "image",
      "endpoint": "mark-henry/flux-mrkhnry",
      "version": "8b2373c80f80f94dde3851aa5e4f9d20569eb3b53d9ac9eaa5325ecea94ebda5",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "a FLUX.1 [dev] lora of Mark Henry's face",
        "runCount": 669,
        "confidence": 0.6,
        "qualityScore": 28.260748027008265,
        "createdAt": "2025-06-02T20:01:53.494343Z",
        "owner": "mark-henry",
        "coverImage": "https://replicate.delivery/xezq/yw4hxfBuZR27ASIM9yBpjBixYmjnWq0uiguYaNpeIXtmJU0UA/out-0.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "A MRKHNRY man, thinning hair slicked back with a fade on the sides, wearing round glasses and a smug expression, riding a roller coaster. overcast weather, no LUT post-processing",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "png",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/yw4hxfBuZR27ASIM9yBpjBixYmjnWq0uiguYaNpeIXtmJU0UA/out-0.png"
            ],
            "prompt": "A MRKHNRY man, thinning hair slicked back with a fade on the sides, wearing round glasses and a smug expression, riding a roller coaster. overcast weather, no LUT post-processing"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "ltejedor/differentiable-rasterizer-vector-graphics",
      "name": "differentiable-rasterizer-vector-graphics",
      "displayName": "differentiable-rasterizer-vector-graphics",
      "provider": "replicate",
      "category": "image",
      "endpoint": "ltejedor/differentiable-rasterizer-vector-graphics",
      "version": "c2405500b0f1671678ef21dab202ecb6ae5ad50d82628e169b3a0cd66a86c6ca",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Controllable generative AI art",
        "runCount": 582,
        "confidence": 0.6,
        "qualityScore": 27.65668554759014,
        "createdAt": "2025-04-03T18:38:40.258602Z",
        "owner": "ltejedor",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/2cbfa802-63ed-48b5-8e3d-9d8cb4158630/1e59bb47-c79d-4637-bf75-bb624153c.gif",
        "githubUrl": "https://github.com/ltejedor/generative-art-cog/tree/main/arnheim_3",
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "red panda",
              "initial_positions": [
                [
                  "image_5.png",
                  -0.194643,
                  0.121429
                ],
                [
                  "image_4.png",
                  0.301786,
                  -0.217857
                ],
                [
                  "image_8.png",
                  0.294643,
                  0.35
                ],
                [
                  "image_9.png",
                  -0.648214,
                  0.157143
                ]
              ]
            },
            "output": [
              "https://replicate.delivery/yhqm/HYrDIJhupAovBFKRnb1HTE68HhIzawJyI2R3neeBeDQCH4zoA/optim_0.png",
              "https://replicate.delivery/yhqm/vzTCOXgwjU4AIBB1GZakrShSU9RZqyxy7NeGqigesUHtD8ZUA/optim_50.png",
              "https://replicate.delivery/yhqm/huHDdtJXWW5eTS7G4FZ6y64ULMKXlrFLJZEXYL1HfsX5D8ZUA/optim_100.png",
              "https://replicate.delivery/yhqm/hdbWLMjZKT5MLdYKuLHUzAg4Gh8JXpPfmvCLM2kAhnnCCeZUA/optim_150.png",
              "https://replicate.delivery/yhqm/vF6jG5UUnqbpDVuAYAQNj2JJfhWILNu1MWPVPfnqCM6RE8ZUA/optim_200.png"
            ],
            "prompt": "red panda"
          }
        ],
        "parameterDescriptions": {
          "loss": "Loss function to optimize the collage. Choose between CLIP and MSE. If MSE is selected, the prompt won't affect the image and target_image is required.",
          "prompt": "The global prompt for generating the collage.",
          "patch_url": "An .npy file for the collage patches.",
          "num_patches": "Number of images to start with",
          "optim_steps": "Number of optimization steps to run during collage generation.",
          "target_image": "Upload an image file for MSE loss. Required if loss is set to MSE.",
          "initial_positions": "List of lists representing the initial positions of patches."
        }
      }
    },
    {
      "id": "kelvincai522/photomaker-v1-lightning",
      "name": "photomaker-v1-lightning",
      "displayName": "photomaker-v1-lightning",
      "provider": "replicate",
      "category": "image",
      "endpoint": "kelvincai522/photomaker-v1-lightning",
      "version": "bea9c27a8620bda18eab53bce5b65afe3fabdb55e15316d90d0c38b0f41e1f9c",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Photomaker V1 optimized with Lightning 8steps",
        "runCount": 572,
        "confidence": 0.6,
        "qualityScore": 27.581546219673896,
        "createdAt": "2025-05-18T17:11:19.943522Z",
        "owner": "kelvincai522",
        "coverImage": "https://replicate.delivery/xezq/uDVA1ZOboezfPkTPC0Jzm1qryLH3M0vQf4oNrPjyRVAQCDvoA/image_0.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "score_9 score_8_up score_7_up anime img 1girl masterpiece very_aesthetic hi_res absurd_res superabsurd_res",
              "num_steps": 16,
              "style_name": "(No style)",
              "input_image": "https://replicate.delivery/pbxt/KFRc9kyW6lLALePRbphzLaZnMyqjYUH8Tles73OvOVfXUcj8/yangmi_1.jpg",
              "num_outputs": 1,
              "guidance_scale": 5,
              "negative_prompt": "score_1 score_2 score_3 worst_quality bad_quality jpeg_artifacts source_cartoon 3d censor+ monochrome blurry lowres watermark text low_res oversaturated crappy_art low_quality blurry bad_anatomy extra_digits fewer_digits simple_background very_displeasing watermark signature",
              "style_strength_ratio": 15
            },
            "output": [
              "https://replicate.delivery/xezq/uDVA1ZOboezfPkTPC0Jzm1qryLH3M0vQf4oNrPjyRVAQCDvoA/image_0.png"
            ],
            "prompt": "score_9 score_8_up score_7_up anime img 1girl masterpiece very_aesthetic hi_res absurd_res superabsurd_res"
          }
        ],
        "parameterDescriptions": {
          "seed": "Seed. Leave blank to use a random number",
          "prompt": "Prompt. Example: 'a photo of a man/woman img'. The phrase 'img' is the trigger word.",
          "num_steps": "Number of sample steps",
          "style_name": "Style template. The style template will add a style-specific prompt and negative prompt to the user's prompt.",
          "input_image": "The input image, for example a photo of your face.",
          "num_outputs": "Number of output images",
          "input_image2": "Additional input image (optional)",
          "input_image3": "Additional input image (optional)",
          "input_image4": "Additional input image (optional)",
          "guidance_scale": "Guidance scale. A guidance scale of 1 corresponds to doing no classifier free guidance.",
          "negative_prompt": "Negative Prompt. The negative prompt should NOT contain the trigger word.",
          "style_strength_ratio": "Style strength (%)"
        }
      }
    },
    {
      "id": "aliciamunianps/alicia",
      "name": "alicia",
      "displayName": "alicia",
      "provider": "replicate",
      "category": "image",
      "endpoint": "aliciamunianps/alicia",
      "version": "5ddf1e4975ec3fc4e3aa541a9a13ad1bf16c7199728e54fc100904c6a041ebdf",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A brown magical goddess",
        "runCount": 437,
        "confidence": 0.6,
        "qualityScore": 26.414741105040992,
        "createdAt": "2025-03-17T19:12:13.963861Z",
        "owner": "aliciamunianps",
        "coverImage": "https://replicate.delivery/xezq/JIvvaUKgedQKSaVDjvrzR1Wo0W6fWfrcduKjnvAhmjSAZg0oA/out-0.webp",
        "githubUrl": "https://github.com/replicate/alicia",
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "Alicia in a cosmic field sending out energy with her hands with hues of pink and blue",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/JIvvaUKgedQKSaVDjvrzR1Wo0W6fWfrcduKjnvAhmjSAZg0oA/out-0.webp"
            ],
            "prompt": "Alicia in a cosmic field sending out energy with her hands with hues of pink and blue"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "littlemonsterzhang/wai90_sdxl",
      "name": "wai90_sdxl",
      "displayName": "wai90_sdxl",
      "provider": "replicate",
      "category": "image",
      "endpoint": "littlemonsterzhang/wai90_sdxl",
      "version": "820ce2c86370ccfac38e9126bcffc58d23348a0ab06179c4b2f49c444ef2d0a6",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "WAI-NSFW-illustrious-SDXL  v.90",
        "runCount": 431,
        "confidence": 0.6,
        "qualityScore": 26.35483746814912,
        "createdAt": "2025-04-15T10:15:54.390368Z",
        "owner": "littlemonsterzhang",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/d8968193-0238-47ad-9545-e725dff32af8/wai_90.jpeg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "glowing eyes, streaked hair, glowing inner hair, glowing streaks, 1girl, jinhsi \\(wuthering_waves\\), white hair,blonde_eyes, large_breasts, (upper_body,close-up:1.4),Dynamic pose,ä¸²,((aqua and yellow:0.85) but Limited palette:1.2),//,Chinese architecture,Ink,hair flowers,bamboo forest,bamboo,//(long hair),small breasts,smile,((dragon)),Yellow lightning,(makeup,white eyeliner),white eyeshadow,white eyes,(long eyelashes),half-closed eyes,Dragon skirt,blush,holding sword,chinese sword,(dynamic angle:1.2),(hanfu:1.4),chinese clothes,transparent clothes,tassel,chinese knot,bare shoulders,kanzashi,draped silk,gold trim,wind,bokeh,scattered leaves,flying splashes,waterfall,splashed water,looking at viewer,                                         \n,masterpiece,best quality,amazing quality,",
              "negative_prompt": "bad quality,worst quality,worst detail,sketch,censor,",
              "randomise_seeds": true
            },
            "output": [
              "https://replicate.delivery/xezq/0oTKgffeL4NPkoALzpVIj0fQXCMZcU8CQ1lPZWK7cFL9wXTSB/ComfyUI_00001_.png"
            ],
            "prompt": "glowing eyes, streaked hair, glowing inner hair, glowing streaks, 1girl, jinhsi \\(wuthering_waves\\), white hair,blonde_eyes, large_breasts, (upper_body,close-up:1.4),Dynamic pose,ä¸²,((aqua and yellow:0.85) but Limited palette:1.2),//,Chinese architecture,Ink,hair flowers,bamboo forest,bamboo,//(long hair),small breasts,smile,((dragon)),Yellow lightning,(makeup,white eyeliner),white eyeshadow,white eyes,(long eyelashes),half-closed eyes,Dragon skirt,blush,holding sword,chinese sword,(dynamic angle:1.2),(hanfu:1.4),chinese clothes,transparent clothes,tassel,chinese knot,bare shoulders,kanzashi,draped silk,gold trim,wind,bokeh,scattered leaves,flying splashes,waterfall,splashed water,looking at viewer,                                         \n,masterpiece,best quality,amazing quality,"
          }
        ],
        "parameterDescriptions": {
          "prompt": "Text prompt for image generation",
          "negative_prompt": "Negative prompt to specify what you don't want in the generated image",
          "randomise_seeds": "Automatically randomise seeds (seed, noise_seed, rand_seed)"
        }
      }
    },
    {
      "id": "snapbar-operations/woman-model",
      "name": "woman-model",
      "displayName": "woman-model",
      "provider": "replicate",
      "category": "image",
      "endpoint": "snapbar-operations/woman-model",
      "version": "2f559a3286c05e8023995eecc4adaa1951936a1a63fe936f167409e0c8f58768",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "woman Flux model",
        "runCount": 355,
        "confidence": 0.6,
        "qualityScore": 25.514499979728754,
        "createdAt": "2025-03-12T20:11:09.578821Z",
        "owner": "snapbar-operations",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/dfa8eb1e-ab2b-4c37-aa15-d3b02da71f0b/background-removed_copy.jpg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "OHWX woman portrait",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/hIm5flTtess2GEGBPfTljMRDon4xEHbnWME4HayfN42ydnfiC/out-0.webp"
            ],
            "prompt": "OHWX woman portrait"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "hayooucom/vision-model2",
      "name": "vision-model2",
      "displayName": "vision-model2",
      "provider": "replicate",
      "category": "image",
      "endpoint": "hayooucom/vision-model2",
      "version": "29e97c56ac1a0344a96dcbcf1d7f1e363279910aa61fdb91d9c333c9e223ab41",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "welcome to contact us. youkpan@gmail.com",
        "runCount": 346,
        "confidence": 0.6,
        "qualityScore": 25.403294747908735,
        "createdAt": "2025-02-28T09:17:05.449092Z",
        "owner": "hayooucom",
        "coverImage": null,
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": 123123,
              "top_k": 5,
              "top_p": 0.95,
              "prompt": "Describe this.",
              "image_url": [
                "https://v.stylee.top/files/test.jpg"
              ],
              "image_url0": "",
              "full_prompt": "",
              "temperature": 0.15,
              "image_base64": [],
              "system_prompt": "You are agent that can see, talk and act.",
              "max_new_tokens": 912,
              "repetition_penalty": 1.1
            },
            "output": [
              "",
              "The ",
              "image ",
              "captures ",
              "a ",
              "moment ",
              "of ",
              "",
              "",
              "tranquility, ",
              "featuring ",
              "a ",
              "black ",
              "",
              "smartwatch ",
              "resting ",
              "on ",
              "a ",
              "wooden ",
              "",
              "surface. ",
              "The ",
              "",
              "watch, ",
              "which ",
              "is ",
              "the ",
              "central ",
              "focus ",
              "of ",
              "the ",
              "",
              "image, ",
              "is ",
              "connected ",
              "to ",
              "a ",
              "white ",
              "charging ",
              "",
              "cable. ",
              "The ",
              "",
              "cable, ",
              "",
              "coiled ",
              "and ",
              "ready ",
              "for ",
              "",
              "use, ",
              "extends ",
              "from ",
              "the ",
              "",
              "watch, ",
              "suggesting ",
              "",
              "it's ",
              "in ",
              "the ",
              "process ",
              "of ",
              "being ",
              "charged.\n\n",
              "",
              "The ",
              "screen ",
              "of ",
              "the ",
              "watch ",
              "is ",
              "alive ",
              "with ",
              "",
              "text, ",
              "providing ",
              "information ",
              "about ",
              "the ",
              "",
              "\"AI ",
              "",
              "Friend\" ",
              "",
              "necklace. ",
              "This ",
              "suggests ",
              "that ",
              "the ",
              "watch ",
              "might ",
              "be ",
              "connected ",
              "to ",
              "a ",
              "virtual ",
              "assistant ",
              "or ",
              "a ",
              "piece ",
              "of ",
              "wearable ",
              "",
              "technology. ",
              "The ",
              "text ",
              "on ",
              "the ",
              "screen ",
              "",
              "reads: ",
              "",
              "\"The ",
              "AI ",
              "Friend ",
              "necklace ",
              "is ",
              "a ",
              "new ",
              "wearable ",
              "tech ",
              "designed ",
              "to ",
              "act ",
              "as ",
              "a ",
              "virtual ",
              "",
              "friend. ",
              "",
              "It's ",
              "a ",
              "virtual ",
              "friend ",
              "that ",
              "you ",
              "wear ",
              "like ",
              "a ",
              "necklace.\"\n\n",
              "",
              "The ",
              "background ",
              "of ",
              "the ",
              "image ",
              "is ",
              "",
              "blurred, ",
              "drawing ",
              "the ",
              "",
              "viewer's ",
              "attention ",
              "to ",
              "the ",
              "watch ",
              "and ",
              "its ",
              "charging ",
              "",
              "cable. ",
              "The ",
              "wooden ",
              "surface ",
              "on ",
              "which ",
              "the ",
              "watch ",
              "rests ",
              "adds ",
              "a ",
              "touch ",
              "of ",
              "warmth ",
              "to ",
              "the ",
              "",
              "scene. ",
              "The ",
              "overall ",
              "composition ",
              "of ",
              "the ",
              "image ",
              "suggests ",
              "a ",
              "blend ",
              "of ",
              "technology ",
              "and ",
              "",
              "",
              "simplicity."
            ],
            "prompt": "Describe this."
          }
        ],
        "parameterDescriptions": {
          "seed": "The seed for the random number generator",
          "top_k": "When decoding text, samples from the top k most likely tokens; lower to ignore less likely tokens.",
          "top_p": "When decoding text, samples from the top p percentage of most likely tokens; lower to ignore less likely tokens.",
          "prompt": "Text prompt to send to the model.",
          "image_url": "public image url.",
          "image_url0": "public image url.",
          "full_prompt": "full prompt to send to the model. if use this ,set prompt to empty",
          "temperature": "Adjusts randomness of outputs, greater than 1 is random and 0 is deterministic.",
          "image_base64": "image data base64 if no image url, use this.",
          "system_prompt": "System prompt.",
          "max_new_tokens": "Maximum number of tokens to generate. A word is generally 2-3 tokens.",
          "output_id_as_str": "output id as string",
          "repetition_penalty": "Penalty for repeated words in generated text; 1 is no penalty, values greater than 1 discourage repetition, less than 1 encourage it."
        }
      }
    },
    {
      "id": "patablanca/casualsocks",
      "name": "casualsocks",
      "displayName": "casualsocks",
      "provider": "replicate",
      "category": "image",
      "endpoint": "patablanca/casualsocks",
      "version": "17b3d0a4c058be6b44d63be70b6d6e08e08980fdcd5bedfcf2f7c455d8469b78",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate Casual Socks for your Theme",
        "runCount": 334,
        "confidence": 0.6,
        "qualityScore": 25.250448070368453,
        "createdAt": "2025-03-21T14:11:41.489660Z",
        "owner": "patablanca",
        "coverImage": "https://replicate.delivery/xezq/jyGLKzCpHpLoM5EmA4yoYttfAzSHZfjwrRo1b7Hxjkp1EwbUA/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "A high-quality, studio-style product image showcasing a single casual sock standing upright, with the toe pointing left and the heel facing right. The sock is placed on a lightly reflective surface and is in sharp focus, revealing detailed knit texture and natural folds. Lighting is soft and professional, ensuring accurate color representation. The sock doesn't have any text or logo on it. The background is softly blurred to maintain focus on the sock. Made from sustainable recycled cotton, the sock features reinforced heel and toe zones, appearing breathable and soft with visible knitting for a tactile, realistic feel.\n\nThe sock design incorporates classic hockey-themed colors: navy blue (#002D62) as the primary color and bright orange (#FF6F00) as the accent. The body of the sock is navy blue and features a pattern of small, evenly spaced crossed hockey sticks in bright orange. The heel, toe, and cuff areas are solid orange, creating a vibrant and sporty contrast.\n\nThe background is softly blurred, showing a field hockey pitch with players in motion and the goal area faintly visible, enhancing the athletic and action-driven theme of the sport.",
              "go_fast": false,
              "lora_scale": 0.74,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 2.52,
              "output_quality": 80,
              "prompt_strength": 0.94,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/jyGLKzCpHpLoM5EmA4yoYttfAzSHZfjwrRo1b7Hxjkp1EwbUA/out-0.webp"
            ],
            "prompt": "A high-quality, studio-style product image showcasing a single casual sock standing upright, with the toe pointing left and the heel facing right. The sock is placed on a lightly reflective surface and is in sharp focus, revealing detailed knit texture and natural folds. Lighting is soft and professional, ensuring accurate color representation. The sock doesn't have any text or logo on it. The background is softly blurred to maintain focus on the sock. Made from sustainable recycled cotton, the sock features reinforced heel and toe zones, appearing breathable and soft with visible knitting for a tactile, realistic feel.\n\nThe sock design incorporates classic hockey-themed colors: navy blue (#002D62) as the primary color and bright orange (#FF6F00) as the accent. The body of the sock is navy blue and features a pattern of small, evenly spaced crossed hockey sticks in bright orange. The heel, toe, and cuff areas are solid orange, creating a vibrant and sporty contrast.\n\nThe background is softly blurred, showing a field hockey pitch with players in motion and the goal area faintly visible, enhancing the athletic and action-driven theme of the sport."
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "jichengdu/flux-pulid",
      "name": "flux-pulid",
      "displayName": "flux-pulid",
      "provider": "replicate",
      "category": "image",
      "endpoint": "jichengdu/flux-pulid",
      "version": "ca0b96aa9f0d0a0a7962a727377806215df25a517865e5f6949f24a26c24d2a6",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "PuLID-FLUX-v0.9.0",
        "runCount": 315,
        "confidence": 0.6,
        "qualityScore": 24.99687082618404,
        "createdAt": "2025-03-12T12:00:41.838318Z",
        "owner": "jichengdu",
        "coverImage": "https://replicate.delivery/yhqm/SFoWklsecL3uaKcXdobzII47UbqfdeizdRppMfd5mwjKwKfiC/output_1.webp",
        "githubUrl": "https://github.com/ToTheBeginning/PuLID",
        "paperUrl": null,
        "licenseUrl": "https://github.com/ToTheBeginning/PuLID/blob/main/LICENSE",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "width": 896,
              "height": 1152,
              "prompt": "portrait, color, cinematic",
              "true_cfg": 1,
              "id_weight": 1,
              "num_steps": 20,
              "start_step": 0,
              "num_outputs": 1,
              "output_format": "webp",
              "guidance_scale": 4,
              "output_quality": 80,
              "main_face_image": "https://replicate.delivery/pbxt/Me8PvHwdoSXGlm8jtoxY2yHT254b6dV9EzWMLp29RjlGqT5E/43.jpg",
              "negative_prompt": "bad quality, worst quality, text, signature, watermark, extra limbs, low resolution, partially rendered objects, deformed or partially rendered eyes, deformed, deformed eyeballs, cross-eyed, blurry",
              "max_sequence_length": 128
            },
            "output": [
              "https://replicate.delivery/yhqm/SFoWklsecL3uaKcXdobzII47UbqfdeizdRppMfd5mwjKwKfiC/output_1.webp"
            ],
            "prompt": "portrait, color, cinematic"
          }
        ],
        "parameterDescriptions": {
          "seed": "Set a random seed for generation (leave blank or -1 for random)",
          "width": "Set the width of the generated image (256-1536 pixels)",
          "height": "Set the height of the generated image (256-1536 pixels)",
          "prompt": "Enter a text prompt to guide image generation",
          "true_cfg": "Set the Classifier-Free Guidance (CFG) scale. 1.0 uses standard CFG, while values >1.0 enable True CFG for more precise control over generation. Higher values increase adherence to the prompt at the cost of image quality.",
          "id_weight": "Set the weight of the ID image influence (0.0-3.0)",
          "num_steps": "Set the number of denoising steps (1-20)",
          "start_step": "Set the timestep to start inserting ID (0-4 recommended, 0 for highest fidelity, 4 for more editability)",
          "num_outputs": "Set the number of images to generate (1-4)",
          "output_format": "Choose the format of the output image",
          "guidance_scale": "Set the guidance scale for text prompt influence (1.0-10.0)",
          "output_quality": "Set the quality of the output image for jpg and webp (1-100)",
          "main_face_image": "Upload an ID image for face generation",
          "negative_prompt": "Enter a negative prompt to specify what to avoid in the image",
          "max_sequence_length": "Set the max sequence length for prompt (T5), smaller is faster (128-512)"
        }
      }
    },
    {
      "id": "jichengdu/wan-i2v",
      "name": "wan-i2v",
      "displayName": "wan-i2v",
      "provider": "replicate",
      "category": "video",
      "endpoint": "jichengdu/wan-i2v",
      "version": "d6a220d6990c8e166d4639a7b8fc9ef744e8e5297af2aef18edde1477140782e",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "i2v-14B-720p-2.1",
        "runCount": 302,
        "confidence": 0.9,
        "qualityScore": 24.814426285023046,
        "createdAt": "2025-03-11T07:04:21.708852Z",
        "owner": "jichengdu",
        "coverImage": "https://replicate.delivery/yhqm/2eeOEKeH0XGXdph2HTtPNWRMoD0wxvjeD4TO1ydUDQuzfDLjC/output_video.mp4",
        "githubUrl": "https://github.com/Wan-Video/Wan2.1",
        "paperUrl": null,
        "licenseUrl": "https://github.com/Wan-Video/Wan2.1/blob/main/LICENSE.txt",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/MfpzR98ZJmwZM7oUcVqeFNW5DUvtTGFDTopDvFC40JdGhZKB/i2v_input.JPG",
              "prompt": "Summer beach vacation style, a white cat wearing sunglasses sits on a surfboard. The fluffy-furred feline gazes directly at the camera with a relaxed expression. Blurred beach scenery forms the background featuring crystal-clear waters, distant green hills, and a blue sky dotted with white clouds. The cat assumes a naturally relaxed posture, as if savoring the sea breeze and warm sunlight. A close-up shot highlights the feline's intricate details and the refreshing atmosphere of the seaside.",
              "max_area": "1280*720",
              "num_frames": 81,
              "sample_shift": 5,
              "sample_steps": 30,
              "frames_per_second": 16,
              "sample_guide_scale": 5
            },
            "output": "https://replicate.delivery/yhqm/2eeOEKeH0XGXdph2HTtPNWRMoD0wxvjeD4TO1ydUDQuzfDLjC/output_video.mp4",
            "prompt": "Summer beach vacation style, a white cat wearing sunglasses sits on a surfboard. The fluffy-furred feline gazes directly at the camera with a relaxed expression. Blurred beach scenery forms the background featuring crystal-clear waters, distant green hills, and a blue sky dotted with white clouds. The cat assumes a naturally relaxed posture, as if savoring the sea breeze and warm sunlight. A close-up shot highlights the feline's intricate details and the refreshing atmosphere of the seaside."
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Leave blank for random",
          "image": "Input image to start generating from",
          "prompt": "Prompt for video generation",
          "max_area": "Maximum area of generated image. The input image will shrink to fit these dimensions",
          "num_frames": "Number of video frames. 81 frames give the best results",
          "sample_shift": "Sample shift factor",
          "sample_steps": "Number of generation steps",
          "frames_per_second": "Frames per second",
          "sample_guide_scale": "Higher guide scale makes prompt adherence better"
        }
      }
    },
    {
      "id": "zx-xch/tiktok-lifestyle-slideshow",
      "name": "tiktok-lifestyle-slideshow",
      "displayName": "tiktok-lifestyle-slideshow",
      "provider": "replicate",
      "category": "image",
      "endpoint": "zx-xch/tiktok-lifestyle-slideshow",
      "version": "d73359c8840bebcced2ae6e339bd6614064f53c335f3543b06299a8cfba907f5",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate luxury lifestyle TikTok slideshow images.",
        "runCount": 205,
        "confidence": 0.6,
        "qualityScore": 23.138672203691534,
        "createdAt": "2025-06-03T02:50:54.526330Z",
        "owner": "zx-xch",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/97cb83fb-7e38-4a75-a715-1c5225ab373d/TikTok_Lifestyle_Slideshow_Examp.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "lone figure, shot from knees up, urban rooftop at night, skyline of glowing windows,\nshot on iPhone 15 Pro Night mode, wide-angle smartphone lens,\ndeep depth of field, slight noise, mild sharpening, subtle HDR,\nhand-held, ISO 1600 grain, tiny lens flare",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/GoWrn8lXT1pBEdbBVmWN5oatZNEV7ayfn3Mjqql96aEIvgZKA/out-0.webp"
            ],
            "prompt": "lone figure, shot from knees up, urban rooftop at night, skyline of glowing windows,\nshot on iPhone 15 Pro Night mode, wide-angle smartphone lens,\ndeep depth of field, slight noise, mild sharpening, subtle HDR,\nhand-held, ISO 1600 grain, tiny lens flare"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "visoar/hipng",
      "name": "hipng",
      "displayName": "hipng",
      "provider": "replicate",
      "category": "image",
      "endpoint": "visoar/hipng",
      "version": "0a33482a8bb06e954f16a3bc081bb5a7e5652fb5662241938e420f9031847684",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "PNG Generation Model https://hipng.com/",
        "runCount": 203,
        "confidence": 0.6,
        "qualityScore": 23.09630167425899,
        "createdAt": "2025-03-10T09:59:39.952922Z",
        "owner": "visoar",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/2300ddf7-e01b-4802-8097-404aca94c2f6/hipng-logo.png",
        "githubUrl": "https://github.com/UllrAI/HeadShot.cv",
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "ping": false,
              "seed": -1,
              "steps": 25,
              "width": 1024,
              "height": 1024,
              "prompt": "rabbit, abstract geometric shapes, transparent background, high contrast, clean edges, sharp details,colorful",
              "num_samples": 1,
              "guidance_scale": 3.5,
              "negative_prompt": "bad, ugly",
              "is_animated_lora": true
            },
            "output": [
              "https://replicate.delivery/xezq/WWz4z5GTO6YTIpOguO7PlpqdUUfWUTnS0EakzRuiDH6FYjLKA/0000.png"
            ],
            "prompt": "rabbit, abstract geometric shapes, transparent background, high contrast, clean edges, sharp details,colorful"
          }
        ],
        "parameterDescriptions": {
          "seed": "Seed number for reproducability purpose. Use -1 for random generation.",
          "steps": "Denoising steps.",
          "width": "Width of the generated images.",
          "height": "Height of the generated images.",
          "prompt": "A textual description of what to generate.",
          "num_samples": "The desired number of samples.",
          "guidance_scale": "Amount of classifier-free guidance.",
          "negative_prompt": "A textual description of what to avoid in the generations.",
          "is_animated_lora": "Whether to use animated LoRA model."
        }
      }
    },
    {
      "id": "nucksftw13/kim3",
      "name": "kim3",
      "displayName": "kim3",
      "provider": "replicate",
      "category": "image",
      "endpoint": "nucksftw13/kim3",
      "version": "ab0446ec9c512fc7c7a716413b59271cf4b5747d236e77d7dd9a05e881ab8eed",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Kim Kardashian with black hair and wide hips",
        "runCount": 198,
        "confidence": 0.6,
        "qualityScore": 22.988530764097067,
        "createdAt": "2025-06-27T07:39:19.027065Z",
        "owner": "nucksftw13",
        "coverImage": "https://replicate.delivery/xezq/e8BL7VqOcI26GKrVfuly9ddrinIvDb0ixdDefT14Wzoyk4sTB/out-3.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "a POV selfie of a woman, black hair, wide hips, WMN, hourglass figure, high quality, masterpiece, black latex dress, skin-tight with strategic cutouts, makeup, high resolution, flat hair, looking down, head not looking up, arm reaching out holding camera",
              "go_fast": false,
              "extra_lora": "https://civitai.com/api/download/models/1668530?type=Model&format=SafeTensor",
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 4,
              "aspect_ratio": "9:16",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 50
            },
            "output": [
              "https://replicate.delivery/xezq/hgk6jeNXPy2rMqjHpJUClf9enW7iKjea0fSSK8fTfp0bmEndKA/out-1.webp",
              "https://replicate.delivery/xezq/e8BL7VqOcI26GKrVfuly9ddrinIvDb0ixdDefT14Wzoyk4sTB/out-3.webp"
            ],
            "prompt": "a POV selfie of a woman, black hair, wide hips, WMN, hourglass figure, high quality, masterpiece, black latex dress, skin-tight with strategic cutouts, makeup, high resolution, flat hair, looking down, head not looking up, arm reaching out holding camera"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "jjj3000/retro-sci-fi",
      "name": "retro-sci-fi",
      "displayName": "retro-sci-fi",
      "provider": "replicate",
      "category": "image",
      "endpoint": "jjj3000/retro-sci-fi",
      "version": "eb4e4877907bf0ab52f816846563e565eeb76b395144fd899a284312399d6391",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate retro futurism images",
        "runCount": 197,
        "confidence": 0.6,
        "qualityScore": 22.96665190261531,
        "createdAt": "2025-03-23T16:10:11.841163Z",
        "owner": "jjj3000",
        "coverImage": "https://replicate.delivery/xezq/YiTlqRVh7MIkENQj6EfwvDRvJDCEP4pFyuU2AfFOclEee5tRB/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "retro lady having a drink with a robot on a holiday",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/YiTlqRVh7MIkENQj6EfwvDRvJDCEP4pFyuU2AfFOclEee5tRB/out-0.webp"
            ],
            "prompt": "retro lady having a drink with a robot on a holiday"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "goodguy1963/good-sdxl-models-plus-loras",
      "name": "good-sdxl-models-plus-loras",
      "displayName": "good-sdxl-models-plus-loras",
      "provider": "replicate",
      "category": "image",
      "endpoint": "goodguy1963/good-sdxl-models-plus-loras",
      "version": "e0d304fdec5f0f693fd6d4906a3ddce96d1a52c9d6c5759215cea926bea3df35",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "BROKEN - DO NOT USE!",
        "runCount": 191,
        "confidence": 0.9,
        "qualityScore": 22.833012287035498,
        "createdAt": "2025-03-25T21:55:46.305683Z",
        "owner": "goodguy1963",
        "coverImage": "https://replicate.delivery/xezq/huXeGcwUpmzvb6JfOHiBrA33vYjeC13EXuVD6rTvss6cYC3oA/output.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "width": 1024,
              "height": 1024,
              "prompt": "magical Castel",
              "sampler": "DPMPP_2M",
              "model_name": "cyberrealistic_xl_cyberdelia",
              "lora_weight": 0.8,
              "guidance_scale": 7.5,
              "lora_selection": "none",
              "scheduler_type": "karras",
              "negative_prompt": "worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art, mutated, deformed, distorted, disfigured, body horror, watermark, text, meme, bad proportions, cropped head, out of frame, cut off, ugly, duplicate, mutilated, mutation, disgusting, bad anatomy, bad hands, three hands, three legs, bad feet, three feet",
              "prompt_strength": 0.8,
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/xezq/huXeGcwUpmzvb6JfOHiBrA33vYjeC13EXuVD6rTvss6cYC3oA/output.png",
            "prompt": "magical Castel"
          }
        ],
        "parameterDescriptions": {
          "mask": "Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted.",
          "seed": "Random seed. Leave blank to randomize the seed",
          "image": "Input image for img2img or inpaint mode",
          "width": "Width of output image",
          "height": "Height of output image",
          "prompt": "Input prompt",
          "sampler": "Choose a sampler",
          "model_name": "Choose which model to use",
          "lora_weight": "LoRA weight (higher values increase effect strength)",
          "guidance_scale": "Scale for classifier-free guidance",
          "lora_selection": "Select a LoRA or LoRA combination to apply",
          "scheduler_type": "Choose a scheduler type",
          "negative_prompt": "Specify things to not see in the output",
          "prompt_strength": "Prompt strength when using init image. 1.0 corresponds to full destruction of information in init image",
          "num_inference_steps": "Number of denoising steps"
        }
      }
    },
    {
      "id": "fofr/wan-0_1-webp",
      "name": "wan-0_1-webp",
      "displayName": "wan-0_1-webp",
      "provider": "replicate",
      "category": "image",
      "endpoint": "fofr/wan-0_1-webp",
      "version": "ab9ed47d967bc3efd31ef27ace2b4b3078c089f358df68c53aeae093074db029",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Wan 14b fine-tuned on 0_1 character",
        "runCount": 163,
        "confidence": 0.6,
        "qualityScore": 22.14843848047698,
        "createdAt": "2025-03-12T13:17:42.365878Z",
        "owner": "fofr",
        "coverImage": "https://replicate.delivery/xezq/NkJh9qaz9W6mPZSuKfdBHet9HCrfSdszwUrcz2eLOO8skPfiC/R8_Wan_00001.mp4",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "frames": 81,
              "prompt": "0_1 woman is laughing",
              "aspect_ratio": "9:16",
              "sample_shift": 8,
              "sample_steps": 30,
              "negative_prompt": "",
              "lora_strength_clip": 1,
              "sample_guide_scale": 5,
              "lora_strength_model": 1
            },
            "output": [
              "https://replicate.delivery/xezq/NkJh9qaz9W6mPZSuKfdBHet9HCrfSdszwUrcz2eLOO8skPfiC/R8_Wan_00001.mp4"
            ],
            "prompt": "0_1 woman is laughing"
          }
        ],
        "parameterDescriptions": {
          "seed": "Set a seed for reproducibility. Random by default.",
          "image": "Image to use as a starting frame for image to video generation.",
          "frames": "The number of frames to generate (1 to 5 seconds)",
          "prompt": "Text prompt for video generation",
          "fast_mode": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.",
          "resolution": "The resolution of the video. 720p is not supported for 1.3b.",
          "aspect_ratio": "The aspect ratio of the video. 16:9, 9:16, 1:1, etc.",
          "sample_shift": "Sample shift factor",
          "sample_steps": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts",
          "negative_prompt": "Things you do not want to see in your video",
          "replicate_weights": "Replicate LoRA weights to use. Leave blank to use the default weights.",
          "lora_strength_clip": "Strength of the LORA applied to the CLIP model. 0.0 is no LORA.",
          "sample_guide_scale": "Higher guide scale makes prompt adherence better, but can reduce variation",
          "lora_strength_model": "Strength of the LORA applied to the model. 0.0 is no LORA."
        }
      }
    },
    {
      "id": "vincetheeleventh/flux-gramps01",
      "name": "flux-gramps01",
      "displayName": "flux-gramps01",
      "provider": "replicate",
      "category": "image",
      "endpoint": "vincetheeleventh/flux-gramps01",
      "version": "3c5446ab672252a9ff78cbf5ebbec5f6772b926833513f00349a719be559b414",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A fine-tuned FLUX.1 model",
        "runCount": 152,
        "confidence": 0.6,
        "qualityScore": 21.84691430817599,
        "createdAt": "2025-03-01T02:57:50.229275Z",
        "owner": "vincetheeleventh",
        "coverImage": "https://replicate.delivery/xezq/uTRpRfjioRXLFi7Hx7mzVvsRerUfdFf1IT8Kf3eHFe6AZTQGKA/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "An ink and watercolor illustration in the style of E.H. Shepard, featuring a warm and expressive scene. The linework is delicate and sketchy, with a flowing, organic quality, full of charm and gentle humor. The background is lightly detailed with soft, airy strokes, evoking a sense of nostalgia. The composition is balanced but informal, capturing a cozy, storybook atmosphere. The overall color palette is muted, with natural tones and delicate shading, resembling classic early 20th-century children's book illustrations.\n\nillustration of an elderly chinese man ukj with stocky build wearing a leather jacket, playing tea party with cheerful granddaughter age 5 and stuffed animals ",
              "go_fast": true,
              "lora_scale": 0.5,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 5,
              "output_quality": 80,
              "prompt_strength": 1,
              "extra_lora_scale": 1,
              "num_inference_steps": 40
            },
            "output": [
              "https://replicate.delivery/xezq/uTRpRfjioRXLFi7Hx7mzVvsRerUfdFf1IT8Kf3eHFe6AZTQGKA/out-0.webp"
            ],
            "prompt": "An ink and watercolor illustration in the style of E.H. Shepard, featuring a warm and expressive scene. The linework is delicate and sketchy, with a flowing, organic quality, full of charm and gentle humor. The background is lightly detailed with soft, airy strokes, evoking a sense of nostalgia. The composition is balanced but informal, capturing a cozy, storybook atmosphere. The overall color palette is muted, with natural tones and delicate shading, resembling classic early 20th-century children's book illustrations.\n\nillustration of an elderly chinese man ukj with stocky build wearing a leather jacket, playing tea party with cheerful granddaughter age 5 and stuffed animals "
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "schvffler/low-exposure",
      "name": "low-exposure",
      "displayName": "low-exposure",
      "provider": "replicate",
      "category": "image",
      "endpoint": "schvffler/low-exposure",
      "version": "730097ba324655d937f3562e2ab26e82cd552608264e7cd4b77639badcf44943",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Creates high-quality, low-exposure style images.",
        "runCount": 146,
        "confidence": 0.6,
        "qualityScore": 21.67317334748176,
        "createdAt": "2025-05-27T15:48:47.248242Z",
        "owner": "schvffler",
        "coverImage": "https://replicate.delivery/xezq/EUZvcE311SpTNdvD5KqQE1KlfkuTPlcfo1VXMg2WKTq7Y5wUA/out-0.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "height": 1440,
              "prompt": "LowExp, photorealistic close-up of a luxurious vanity table at night, a two-tone luxury watch, black silk gloves, and premium makeup products scattered elegantly, a tall champagne glass catching faint reflections under minimal lighting, cinematic top-down composition emphasizing textures of metal, fabric, and glass, cool muted palette with soft highlights on select objects, background softly blurred, atmosphere of understated wealth, indulgence, and refined sophistication, subtle grain adding depth, minimal color distractions focusing on gold, black, and silver tones.\n",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "9:16",
              "output_format": "png",
              "guidance_scale": 3,
              "output_quality": 100,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/EUZvcE311SpTNdvD5KqQE1KlfkuTPlcfo1VXMg2WKTq7Y5wUA/out-0.png"
            ],
            "prompt": "LowExp, photorealistic close-up of a luxurious vanity table at night, a two-tone luxury watch, black silk gloves, and premium makeup products scattered elegantly, a tall champagne glass catching faint reflections under minimal lighting, cinematic top-down composition emphasizing textures of metal, fabric, and glass, cool muted palette with soft highlights on select objects, background softly blurred, atmosphere of understated wealth, indulgence, and refined sophistication, subtle grain adding depth, minimal color distractions focusing on gold, black, and silver tones.\n"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "fofr/flux-tron-ares",
      "name": "flux-tron-ares",
      "displayName": "flux-tron-ares",
      "provider": "replicate",
      "category": "image",
      "endpoint": "fofr/flux-tron-ares",
      "version": "b5ea550026e196b614e1509621cedcc0d05110b1133872e160bcdd8b1c8d01f6",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Flux fine-tuned on TRON: ARES",
        "runCount": 138,
        "confidence": 0.6,
        "qualityScore": 21.43014800254095,
        "createdAt": "2025-04-06T02:53:18.968662Z",
        "owner": "fofr",
        "coverImage": "https://replicate.delivery/xezq/cjNTwSjsCSK9OdKmvLbbwium0pH9EmY4UVMmh3yzwsYZf8PKA/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "a TRON_ARES portrait photo of a cyberpunk with domed helmet, brilliant red energy beams streak across a dark night cityscape",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "16:9",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/cjNTwSjsCSK9OdKmvLbbwium0pH9EmY4UVMmh3yzwsYZf8PKA/out-0.webp"
            ],
            "prompt": "a TRON_ARES portrait photo of a cyberpunk with domed helmet, brilliant red energy beams streak across a dark night cityscape"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "pointblack/stable-interiors-v2",
      "name": "stable-interiors-v2",
      "displayName": "stable-interiors-v2",
      "provider": "replicate",
      "category": "image",
      "endpoint": "pointblack/stable-interiors-v2",
      "version": "569b1bd6e4df6c9c900ad932d4a3a9f05585fac957dc6bc627aa1654853a97b5",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "An enhanced version of sd-interior-design",
        "runCount": 137,
        "confidence": 0.9,
        "qualityScore": 21.398790864012366,
        "createdAt": "2025-05-06T11:58:35.908356Z",
        "owner": "pointblack",
        "coverImage": "https://replicate.delivery/xezq/vzwPNLVeDfvPYUe4GeymcIX5nW1Z56YHA6xrbmlNEoaFMrnSB/tmpzwn0g2jr.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/MxenqL56Qq36n2vEfnnl7KRyi63SrnaveKgZUORd5FzHRrcD/living_room_3.jpg",
              "prompt": "a fully furnished Scandinavian living room with one light wood coffee table, a neutral-toned fabric sofa, soft wool throws and cushions, white walls, minimalist shelving, a pendant lamp overhead, and minimal decor, with natural light streaming through sheer linen curtains",
              "guidance_scale": 15,
              "negative_prompt": "lowres, watermark, banner, logo, contactinfo, text, deformed, blurry, blur, out of focus, out of frame, surreal, extra limbs, extra furniture, ugly, overlapping objects, distorted furniture, impossible layout, broken geometry, unrealistic proportions, floating furniture, furniture merging with walls or windows, warped walls, curved walls, mirrors, mirrored surfaces, plush walls, fabric walls, soft focus, poor lighting, artifacts, cut-off furniture",
              "prompt_strength": 0.8,
              "num_inference_steps": 50
            },
            "output": "https://replicate.delivery/xezq/vzwPNLVeDfvPYUe4GeymcIX5nW1Z56YHA6xrbmlNEoaFMrnSB/tmpzwn0g2jr.png",
            "prompt": "a fully furnished Scandinavian living room with one light wood coffee table, a neutral-toned fabric sofa, soft wool throws and cushions, white walls, minimalist shelving, a pendant lamp overhead, and minimal decor, with natural light streaming through sheer linen curtains"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed",
          "image": "Path to input image",
          "prompt": "Text prompt for design",
          "guidance_scale": "Guidance scale",
          "negative_prompt": "Negative prompt",
          "prompt_strength": "Prompt strength for inpainting",
          "num_inference_steps": "Number of denoising steps"
        }
      }
    },
    {
      "id": "that1potato/flux-noto-emoji",
      "name": "flux-noto-emoji",
      "displayName": "flux-noto-emoji",
      "provider": "replicate",
      "category": "image",
      "endpoint": "that1potato/flux-noto-emoji",
      "version": "a208e40331db75dc8ce9d575a6cea3ddfb349f4c1834f1371498fb3e42f63cb7",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "FLUX.1-dev fine-tuned on noto emoji.",
        "runCount": 136,
        "confidence": 0.6,
        "qualityScore": 21.367205671564065,
        "createdAt": "2025-03-08T23:56:25.990435Z",
        "owner": "that1potato",
        "coverImage": "https://replicate.delivery/xezq/pJQA8VyQR0LnPFcmAPe5TuvHwBibHlUnJ1fOb6MxQdhrHqWUA/out-0.webp",
        "githubUrl": "https://github.com/that1potato/flux-noto-emoji-lora",
        "paperUrl": null,
        "licenseUrl": "https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "height": 512,
              "prompt": "NOTO bear wearing space suit emoji , white background",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "0.25",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/pJQA8VyQR0LnPFcmAPe5TuvHwBibHlUnJ1fOb6MxQdhrHqWUA/out-0.webp"
            ],
            "prompt": "NOTO bear wearing space suit emoji , white background"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "lucataco/kontext-meta-cars",
      "name": "kontext-meta-cars",
      "displayName": "kontext-meta-cars",
      "provider": "replicate",
      "category": "image",
      "endpoint": "lucataco/kontext-meta-cars",
      "version": "981b1881832b17fce0b3d7e2af49748b0ef6cb83a7dbc1476d79534db4125424",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Change your car into a CDMX Meta Car",
        "runCount": 118,
        "confidence": 0.9,
        "qualityScore": 20.75546961392531,
        "createdAt": "2025-07-24T02:53:06.261394Z",
        "owner": "lucataco",
        "coverImage": "https://replicate.delivery/xezq/6mnby6n2xpYdOx5XeLLEbsfrLoicZWwaWQhWtlfPBP2GdqHqA/output.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "make this a METACAR",
              "guidance": 2.5,
              "megapixels": "1",
              "input_image": "https://replicate.delivery/pbxt/NPZ57CwbggRomSKamWlBTEKFOxU8ymLqBFSQ9WBO2OMZeArU/replicate-prediction-gpsnv89t21rmc0cq307bthpesw.png",
              "aspect_ratio": "match_input_image",
              "lora_strength": 1,
              "output_format": "webp",
              "output_quality": 80,
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/xezq/6mnby6n2xpYdOx5XeLLEbsfrLoicZWwaWQhWtlfPBP2GdqHqA/output.webp",
            "prompt": "make this a METACAR"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible generation. Leave blank for random.",
          "prompt": "Text description of what you want to generate, or the instruction on how to edit the given image.",
          "guidance": "Guidance scale for generation",
          "megapixels": "Approximate number of megapixels for generated image",
          "input_image": "Image to use as reference. Must be jpeg, png, gif, or webp.",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "lora_strength": "Strength of the lora",
          "output_format": "Output image format",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "replicate_weights": "Path to the lora weights",
          "num_inference_steps": "Number of inference steps",
          "disable_safety_checker": "Disable NSFW safety checker"
        }
      }
    },
    {
      "id": "lclrke/musicgen-ltb",
      "name": "musicgen-ltb",
      "displayName": "musicgen-ltb",
      "provider": "replicate",
      "category": "audio",
      "endpoint": "lclrke/musicgen-ltb",
      "version": "445cd11f0c4b2d16c13f069dc42c35c410766b8d8dc4eace50bb473536f32626",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "fine tuned on ltb",
        "runCount": 101,
        "confidence": 0.9,
        "qualityScore": 20.086001717619176,
        "createdAt": "2025-05-27T14:51:16.695907Z",
        "owner": "lclrke",
        "coverImage": null,
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "top_k": 250,
              "top_p": 0,
              "prompt": "98 bpm. Bright italo disco-inspired synth pop with nostalgic energy. Features retro synth stabs, crisp gated snares, and euphoric melodic layers. Like a lost scene from an 80s teen movie soundtrack.",
              "duration": 8,
              "temperature": 1,
              "continuation": false,
              "output_format": "wav",
              "continuation_start": 0,
              "multi_band_diffusion": false,
              "normalization_strategy": "loudness",
              "classifier_free_guidance": 3
            },
            "output": "https://replicate.delivery/xezq/f1IwdE3ZffcptpWRobs1RnWNeuU7z5TTbONdtkRxpkKsJAiTB/out.wav",
            "prompt": "98 bpm. Bright italo disco-inspired synth pop with nostalgic energy. Features retro synth stabs, crisp gated snares, and euphoric melodic layers. Like a lost scene from an 80s teen movie soundtrack."
          }
        ],
        "parameterDescriptions": {
          "seed": "Seed for random number generator. If None or -1, a random seed will be used.",
          "top_k": "Reduces sampling to the k most likely tokens.",
          "top_p": "Reduces sampling to tokens with cumulative probability of p. When set to  `0` (default), top_k sampling is used.",
          "prompt": "A description of the music you want to generate.",
          "duration": "Duration of the generated audio in seconds.",
          "input_audio": "An audio file that will influence the generated music. If `continuation` is `True`, the generated music will be a continuation of the audio file. Otherwise, the generated music will mimic the audio file's melody.",
          "temperature": "Controls the 'conservativeness' of the sampling process. Higher temperature means more diversity.",
          "continuation": "If `True`, generated music will continue `melody`. Otherwise, generated music will mimic `audio_input`'s melody.",
          "output_format": "Output format for generated audio.",
          "continuation_end": "End time of the audio file to use for continuation. If -1 or None, will default to the end of the audio clip.",
          "replicate_weights": "Replicate MusicGen weights to use. Leave blank to use the default weights.",
          "continuation_start": "Start time of the audio file to use for continuation.",
          "multi_band_diffusion": "If `True`, the EnCodec tokens will be decoded with MultiBand Diffusion. Only works with non-stereo models.",
          "normalization_strategy": "Strategy for normalizing audio.",
          "classifier_free_guidance": "Increases the influence of inputs on the output. Higher values produce lower-varience outputs that adhere more closely to inputs."
        }
      }
    },
    {
      "id": "diaphinus/avax",
      "name": "avax",
      "displayName": "avax",
      "provider": "replicate",
      "category": "image",
      "endpoint": "diaphinus/avax",
      "version": "313b7fec92bb23523458b6c18d2982f8f5b06113899959333b2cc7379dd39e30",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Ava is a young social media influencer",
        "runCount": 98,
        "confidence": 0.6,
        "qualityScore": 19.9563519459755,
        "createdAt": "2025-06-11T19:06:22.774222Z",
        "owner": "diaphinus",
        "coverImage": "https://replicate.delivery/xezq/UeqHr4q2oBTldacb05XYGe3tStjfsIjrUPP8rThzGdeTAjXTB/out-3.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "seed": -1,
              "model": "dev",
              "prompt": "Full body shot AvaX wearing a pink hand cut crop top vapor wave 80s “Ride Me” graphic t-shirt a pink thong under her low rise distressed jean short shorts outside Max Fish bar, a bar that has a giant neon cigarette hanging over its door",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 4,
              "aspect_ratio": "9:16",
              "output_format": "png",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/ecriik8rnM0aBCRQUoFER8Zf9SubBD8SOOZYGbYrNOVEw41UA/out-0.png",
              "https://replicate.delivery/xezq/oBaCYa8gClYJPh7wL4JfWMxC7Zarf9STeKnieKqPVfHkAGvmC/out-1.png",
              "https://replicate.delivery/xezq/518B8SYwa2pMINfRTZ91BaBfDl24DRCe7g9Q4eQgMHVQAjXTB/out-2.png",
              "https://replicate.delivery/xezq/UeqHr4q2oBTldacb05XYGe3tStjfsIjrUPP8rThzGdeTAjXTB/out-3.png"
            ],
            "prompt": "Full body shot AvaX wearing a pink hand cut crop top vapor wave 80s “Ride Me” graphic t-shirt a pink thong under her low rise distressed jean short shorts outside Max Fish bar, a bar that has a giant neon cigarette hanging over its door"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "shridharathi/ghibli-vid",
      "name": "ghibli-vid",
      "displayName": "ghibli-vid",
      "provider": "replicate",
      "category": "image",
      "endpoint": "shridharathi/ghibli-vid",
      "version": "e65c22b73e9df842276a6321a718152d591ddad2e36eb6441606bc06c3d133d0",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Make a video of anything in Studio Ghibli style",
        "runCount": 93,
        "confidence": 0.6,
        "qualityScore": 19.731278535996985,
        "createdAt": "2025-03-27T05:25:34.503043Z",
        "owner": "shridharathi",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/718e7ccc-8773-4e66-96d0-8c63cae115b1/Screenshot_2025-03-27_at_2.27.45P.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "frames": 81,
              "prompt": "GHIBLI style, anime, a girl running through new york city",
              "fast_mode": "Balanced",
              "resolution": "480p",
              "aspect_ratio": "16:9",
              "sample_shift": 8,
              "sample_steps": 30,
              "negative_prompt": "",
              "lora_strength_clip": 1,
              "sample_guide_scale": 5,
              "lora_strength_model": 1
            },
            "output": [
              "https://replicate.delivery/xezq/4T0Ff7e3Yvjy30HeYRQjqWMG19epscJK6DEdFQ5LYTW5EazRB/R8_Wan_00001.mp4"
            ],
            "prompt": "GHIBLI style, anime, a girl running through new york city"
          }
        ],
        "parameterDescriptions": {
          "seed": "Set a seed for reproducibility. Random by default.",
          "image": "Image to use as a starting frame for image to video generation.",
          "frames": "The number of frames to generate (1 to 5 seconds)",
          "prompt": "Text prompt for video generation",
          "fast_mode": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.",
          "resolution": "The resolution of the video. 720p is not supported for 1.3b.",
          "aspect_ratio": "The aspect ratio of the video. 16:9, 9:16, 1:1, etc.",
          "sample_shift": "Sample shift factor",
          "sample_steps": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts",
          "negative_prompt": "Things you do not want to see in your video",
          "replicate_weights": "Replicate LoRA weights to use. Leave blank to use the default weights.",
          "lora_strength_clip": "Strength of the LORA applied to the CLIP model. 0.0 is no LORA.",
          "sample_guide_scale": "Higher guide scale makes prompt adherence better, but can reduce variation",
          "lora_strength_model": "Strength of the LORA applied to the model. 0.0 is no LORA."
        }
      }
    },
    {
      "id": "replicate/flux-2d-game-assets",
      "name": "flux-2d-game-assets",
      "displayName": "flux-2d-game-assets",
      "provider": "replicate",
      "category": "image",
      "endpoint": "replicate/flux-2d-game-assets",
      "version": "0afb5cc10c16d8b5b8af800cbfe236481348936f4d872e404d1b7ce1e3b9c96d",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Flux 2D Game Asset LoRA",
        "runCount": 90,
        "confidence": 0.6,
        "qualityScore": 19.590413923210935,
        "createdAt": "2025-05-21T18:17:13.303125Z",
        "owner": "replicate",
        "coverImage": "https://replicate.delivery/xezq/lScB9fUViPSoP6vpVOpXEYCqUqs6XfQzARGNOhf8fNeeZLvLF/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "FGAL healing crystal, white background, game asset, pixel art",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/lScB9fUViPSoP6vpVOpXEYCqUqs6XfQzARGNOhf8fNeeZLvLF/out-0.webp"
            ],
            "prompt": "FGAL healing crystal, white background, game asset, pixel art"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "yceballost/movistar-images",
      "name": "movistar-images",
      "displayName": "movistar-images",
      "provider": "replicate",
      "category": "image",
      "endpoint": "yceballost/movistar-images",
      "version": "3e6c5b6f16e335e7508c86f13f05de7db88ab5ab1d06be2b22c1fa3039856b3f",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A model to generate images for Movistar brand",
        "runCount": 88,
        "confidence": 0.6,
        "qualityScore": 19.49390006644913,
        "createdAt": "2025-06-03T08:04:22.026160Z",
        "owner": "yceballost",
        "coverImage": "https://replicate.delivery/xezq/VSSMqdkFQ5J8OtX1f5Hhw5uZ0oj3LV4iCNqIw2KOA430IjaKA/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "a woman jumping in front of blue wall MVSTR",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/VSSMqdkFQ5J8OtX1f5Hhw5uZ0oj3LV4iCNqIw2KOA430IjaKA/out-0.webp"
            ],
            "prompt": "a woman jumping in front of blue wall MVSTR"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "lucataco/ltx-video-iclora",
      "name": "ltx-video-iclora",
      "displayName": "ltx-video-iclora",
      "provider": "replicate",
      "category": "video",
      "endpoint": "lucataco/ltx-video-iclora",
      "version": "4cb7ff7f0a3cf4cb577ebc641c82b3160f6821f5f312133472933cf267c7880c",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "LTX Video 0.9.7 Distilled with ICLoRAs",
        "runCount": 74,
        "confidence": 0.9,
        "qualityScore": 18.750612633917,
        "createdAt": "2025-07-17T17:31:12.735671Z",
        "owner": "lucataco",
        "coverImage": "https://replicate.delivery/xezq/N1JUNspJN6bFFpHvxNpp6tMrGxFe8feSLD0C30JofVvMTXEUB/tmp6koley0l.mp4",
        "githubUrl": "https://github.com/lucataco/cog-ltx-video-iclora",
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "fps": 24,
              "seed": 0,
              "prompt": "Two elderly men with large white beards engage in a fight in a lush park setting, they lunge at each other with their golf clubs with determined focus amid the green canopy of trees",
              "num_frames": 121,
              "aspect_ratio": "match_input_video",
              "control_type": "canny",
              "guidance_scale": 1,
              "negative_prompt": "worst quality, inconsistent motion, blurry, jittery, distorted",
              "reference_video": "https://replicate.delivery/pbxt/NMc35bj7yOUe9dClRGg150T3BT5sIZTJ6S3XO49PvcjcsJgx/replicate-prediction-kzhcsj5c31rm80cr1y3s4cwbmm.mp4",
              "num_inference_steps": 7
            },
            "output": "https://replicate.delivery/xezq/N1JUNspJN6bFFpHvxNpp6tMrGxFe8feSLD0C30JofVvMTXEUB/tmp6koley0l.mp4",
            "prompt": "Two elderly men with large white beards engage in a fight in a lush park setting, they lunge at each other with their golf clubs with determined focus amid the green canopy of trees"
          }
        ],
        "parameterDescriptions": {
          "fps": "Frames per second for the generated video",
          "seed": "Random seed for reproducibility (0 for random)",
          "prompt": "Text prompt describing the desired video",
          "num_frames": "Number of frames in the generated video",
          "aspect_ratio": "Aspect ratio for the generated video",
          "control_type": "Type of control guidance",
          "guidance_scale": "Guidance scale for generation",
          "negative_prompt": "Negative prompt describing what to avoid",
          "reference_video": "Reference video for control guidance",
          "num_inference_steps": "Number of inference steps"
        }
      }
    },
    {
      "id": "primateavatar/bandi",
      "name": "bandi",
      "displayName": "bandi",
      "provider": "replicate",
      "category": "image",
      "endpoint": "primateavatar/bandi",
      "version": "42faa99a70c08f67510a1d162af9868b00952e1f19a3e7b85b89d3fb3005fb0f",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Simple anime character",
        "runCount": 65,
        "confidence": 0.6,
        "qualityScore": 18.19543935541869,
        "createdAt": "2025-07-07T18:50:52.208185Z",
        "owner": "primateavatar",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/2f13b068-3959-4a84-830d-95096bdc3431/bandi_trained.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "bandi raising a flag",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/YttEG7JRBfRDTizfzrhAeyNQtigKbs20ixlVQU9itN8xez5TB/out-0.webp"
            ],
            "prompt": "bandi raising a flag"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "dannyboy2323/lora-flux-danielbull23",
      "name": "lora-flux-danielbull23",
      "displayName": "lora-flux-danielbull23",
      "provider": "replicate",
      "category": "image",
      "endpoint": "dannyboy2323/lora-flux-danielbull23",
      "version": "fa8219051a9babfd1f0f903cbf6eaa4bcad9f412dc1bbfa9464827b9b6991ff9",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Use DANIELBULL23 to trigger",
        "runCount": 64,
        "confidence": 0.6,
        "qualityScore": 18.129133566428553,
        "createdAt": "2025-06-11T07:28:48.974104Z",
        "owner": "dannyboy2323",
        "coverImage": "https://replicate.delivery/xezq/qCqUTha0Dv55FBYLHQ6fL2WgfgPXMLLNh01EZkhmIxfZe1flC/out-3.jpg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/N4AF6FMVfB47O2cTmukjpSJIuVTgqwdUUGazEgP9LGzgiRsz/replicate-prediction-hanjvkp47drma0cpaq6av9kkbg%20%281%29.webp",
              "model": "dev",
              "prompt": "DANIELTHEBULL (10 year old boy, messy brown hair, tall and lean build) with his Dad posing in Cavalry uniforms ",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 4,
              "aspect_ratio": "4:3",
              "output_format": "jpg",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/5xoj40gLBey2B6TrBmGhJcaVLIOGqsRA56NUnR74EXcmvevUA/out-0.jpg",
              "https://replicate.delivery/xezq/pnhJMw66O6rhNRe0mWdKenHQFcjbreXCtdRzsityRfVw81flC/out-1.jpg",
              "https://replicate.delivery/xezq/5eHB47idDCV3MSHSXSnfizEmqSJ8Dz321Cnbn4U6QOKMf6fSB/out-2.jpg",
              "https://replicate.delivery/xezq/qCqUTha0Dv55FBYLHQ6fL2WgfgPXMLLNh01EZkhmIxfZe1flC/out-3.jpg"
            ],
            "prompt": "DANIELTHEBULL (10 year old boy, messy brown hair, tall and lean build) with his Dad posing in Cavalry uniforms "
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "hardikdava/flux-image-editing",
      "name": "flux-image-editing",
      "displayName": "flux-image-editing",
      "provider": "replicate",
      "category": "image",
      "endpoint": "hardikdava/flux-image-editing",
      "version": "f3c783b24381c61681c97814f6501c1afc263cc78d7f3d04ffd4e9914977ece8",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Image editing with Flux-dev model",
        "runCount": 55,
        "confidence": 0.6,
        "qualityScore": 17.481880270062003,
        "createdAt": "2025-05-25T11:03:00.504351Z",
        "owner": "hardikdava",
        "coverImage": "https://replicate.delivery/xezq/XBQoxPPVqsr9BdyUVqAfsyz7ok8c5Zhq0qxBgMTvuk0UZFYKA/out-0.jpg",
        "githubUrl": "https://github.com/hardikdava/flux-image-editing",
        "paperUrl": null,
        "licenseUrl": "https://github.com/hardikdava/flux-image-editing/blob/main/LICENSE",
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/N4O2JoisnaLqx7vvJaKTTbH4o2BETSKI87GJRhjPh1z22QoV/mushroom.jpg",
              "prompt": "turn the color of mushroom to gray",
              "num_outputs": 1,
              "output_format": "jpg",
              "guidance_scale": 30,
              "output_quality": 100,
              "use_hyper_lora": false,
              "num_inference_steps": 50
            },
            "output": [
              "https://replicate.delivery/xezq/XBQoxPPVqsr9BdyUVqAfsyz7ok8c5Zhq0qxBgMTvuk0UZFYKA/out-0.jpg"
            ],
            "prompt": "turn the color of mushroom to gray"
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed. Set for reproducible generation",
          "image": "The image for the generation",
          "prompt": "Prompt for generated image",
          "num_outputs": "Number of outputs to generate",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "use_hyper_lora": "Use Hyper Lora for faster generation. This speeds up the process.",
          "num_inference_steps": "Number of inference steps"
        }
      }
    },
    {
      "id": "supervision-2020/jcesar",
      "name": "jcesar",
      "displayName": "jcesar",
      "provider": "replicate",
      "category": "image",
      "endpoint": "supervision-2020/jcesar",
      "version": "4496a015c6757e7bb659872fdba1540559fb2f1a508aeabc7a8c7d6f3d2d38b6",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "julios face",
        "runCount": 53,
        "confidence": 0.6,
        "qualityScore": 17.323937598229687,
        "createdAt": "2025-02-26T06:08:13.070150Z",
        "owner": "supervision-2020",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/d6d91467-5183-4cbd-a3b6-5d3c231aa5c8/out-0-1.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "JULIO dancing in the middle of a crowd at a wedding",
              "go_fast": false,
              "lora_scale": 0.95,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 2.85,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 26
            },
            "output": [
              "https://replicate.delivery/xezq/8qzvLDyijC4fPCwFgqOe8fHFXA8RNtCS6TChWQjB2QvhuMmoA/out-0.webp"
            ],
            "prompt": "JULIO dancing in the middle of a crowd at a wedding"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "emibob/testinggg-59898",
      "name": "testinggg-59898",
      "displayName": "testinggg-59898",
      "provider": "replicate",
      "category": "image",
      "endpoint": "emibob/testinggg-59898",
      "version": "3dab668a676b65396256110f877920825f3d9ad3cc95d43697fae11b69d0dc64",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A fine-tuned portrait model",
        "runCount": 51,
        "confidence": 0.6,
        "qualityScore": 17.16003343634799,
        "createdAt": "2025-02-28T01:47:07.446495Z",
        "owner": "emibob",
        "coverImage": "https://replicate.delivery/xezq/Bft42HP5CBVmEifhrevrF3QjyTcE5nmsY4MqiDGvpCfPzyORB/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/MZj8jBl0PpmeukxsTRj9xUCcBtPZVmcUBi2CaCUeXhfZXjum/Screenshot%202025-02-27%20at%205.55.11%E2%80%AFPM.png",
              "model": "dev",
              "prompt": "HARDYHAR: A heartwarming, close-up moment of a couple in their mid-30s, Bavis and Baylor, in the midst of a joyous engagement. The focus is on their faces, full of raw emotion—Bavis, a tall man with slightly scruffy facial hair, is kneeling with an open ring box, his eyes locked onto Baylor’s with a mix of excitement, love, and nervous anticipation. Baylor, a radiant woman with expressive eyes and a playful energy, stands before him, her hands trembling near her mouth, her eyes wide and glistening with joyful surprise. A tear might be welling up in the corner of her eye, her lips slightly parted in a stunned smile as she processes the moment.\n\nThe engagement ring is prominently displayed, its delicate band catching the warm glow of the surrounding lights. Bavis’s hands are steady but show the slightest tension, as if holding his breath for her response. Baylor’s fingers instinctively reach toward the ring, almost hesitant to believe it’s real. The background is warm, adding to the warmth and intimacy of the moment. Their expressions radiate pure love and excitement, capturing the magic of a holiday proposal frozen in time.",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/Bft42HP5CBVmEifhrevrF3QjyTcE5nmsY4MqiDGvpCfPzyORB/out-0.webp"
            ],
            "prompt": "HARDYHAR: A heartwarming, close-up moment of a couple in their mid-30s, Bavis and Baylor, in the midst of a joyous engagement. The focus is on their faces, full of raw emotion—Bavis, a tall man with slightly scruffy facial hair, is kneeling with an open ring box, his eyes locked onto Baylor’s with a mix of excitement, love, and nervous anticipation. Baylor, a radiant woman with expressive eyes and a playful energy, stands before him, her hands trembling near her mouth, her eyes wide and glistening with joyful surprise. A tear might be welling up in the corner of her eye, her lips slightly parted in a stunned smile as she processes the moment.\n\nThe engagement ring is prominently displayed, its delicate band catching the warm glow of the surrounding lights. Bavis’s hands are steady but show the slightest tension, as if holding his breath for her response. Baylor’s fingers instinctively reach toward the ring, almost hesitant to believe it’s real. The background is warm, adding to the warmth and intimacy of the moment. Their expressions radiate pure love and excitement, capturing the magic of a holiday proposal frozen in time."
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "shangray11/shannonn",
      "name": "shannonn",
      "displayName": "shannonn",
      "provider": "replicate",
      "category": "image",
      "endpoint": "shangray11/shannonn",
      "version": "ccbdcca7093ce8418948cecaea6d7329741b796e8296f307f48107588d91621a",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "a realistic image of Shannon",
        "runCount": 49,
        "confidence": 0.6,
        "qualityScore": 16.989700043360187,
        "createdAt": "2025-06-13T11:17:21.023321Z",
        "owner": "shangray11",
        "coverImage": "https://replicate.delivery/xezq/rWpFwcrkm1IUItDxi5MG84Rl003cwvilRSprySiWBeZpefOpA/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "a selfie photo of shannonn",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/rWpFwcrkm1IUItDxi5MG84Rl003cwvilRSprySiWBeZpefOpA/out-0.webp"
            ],
            "prompt": "a selfie photo of shannonn"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "shridharathi/van-gogh-vid",
      "name": "van-gogh-vid",
      "displayName": "van-gogh-vid",
      "provider": "replicate",
      "category": "image",
      "endpoint": "shridharathi/van-gogh-vid",
      "version": "bee70f3c8f0db29784b12b5129186eaa9607104308f592c5f07274cac7acbd2a",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Make your videos van gogh-esque",
        "runCount": 37,
        "confidence": 0.6,
        "qualityScore": 15.797835966168101,
        "createdAt": "2025-03-27T23:46:30.484477Z",
        "owner": "shridharathi",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/b0fe3906-801d-428c-af7b-1851db1e6797/Screenshot_2025-03-28_at_12.36.04.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "frames": 81,
              "prompt": "GOGH style, painting of a man walking in a field with trees and sunlight",
              "fast_mode": "Balanced",
              "resolution": "480p",
              "aspect_ratio": "16:9",
              "sample_shift": 8,
              "sample_steps": 30,
              "negative_prompt": "",
              "lora_strength_clip": 1,
              "sample_guide_scale": 5,
              "lora_strength_model": 1
            },
            "output": [
              "https://replicate.delivery/xezq/rwGhWqKagypSJBEJAY3NFDt4W33ffhMERfFS2DskbW3mB15oA/R8_Wan_00001.mp4"
            ],
            "prompt": "GOGH style, painting of a man walking in a field with trees and sunlight"
          }
        ],
        "parameterDescriptions": {
          "seed": "Set a seed for reproducibility. Random by default.",
          "image": "Image to use as a starting frame for image to video generation.",
          "frames": "The number of frames to generate (1 to 5 seconds)",
          "prompt": "Text prompt for video generation",
          "fast_mode": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.",
          "resolution": "The resolution of the video. 720p is not supported for 1.3b.",
          "aspect_ratio": "The aspect ratio of the video. 16:9, 9:16, 1:1, etc.",
          "sample_shift": "Sample shift factor",
          "sample_steps": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts",
          "negative_prompt": "Things you do not want to see in your video",
          "replicate_weights": "Replicate LoRA weights to use. Leave blank to use the default weights.",
          "lora_strength_clip": "Strength of the LORA applied to the CLIP model. 0.0 is no LORA.",
          "sample_guide_scale": "Higher guide scale makes prompt adherence better, but can reduce variation",
          "lora_strength_model": "Strength of the LORA applied to the model. 0.0 is no LORA."
        }
      }
    },
    {
      "id": "gneebs/roxys-pizza",
      "name": "roxys-pizza",
      "displayName": "roxys-pizza",
      "provider": "replicate",
      "category": "image",
      "endpoint": "gneebs/roxys-pizza",
      "version": "c0b3cbfb1277dd541d530d673aa6fb987290208fc68d3a4f258c78272ad647ad",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generates in the style of a retro pizza shop",
        "runCount": 33,
        "confidence": 0.6,
        "qualityScore": 15.314789170422552,
        "createdAt": "2025-06-21T17:36:45.011528Z",
        "owner": "gneebs",
        "coverImage": "https://replicate.delivery/xezq/u9oDPXJ1xvoCAFNVTEDbYUh1jGdo4GNce4H32xKVfjJt5w5UA/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "an advertisement for pizza by the slice, ROXY style",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/u9oDPXJ1xvoCAFNVTEDbYUh1jGdo4GNce4H32xKVfjJt5w5UA/out-0.webp"
            ],
            "prompt": "an advertisement for pizza by the slice, ROXY style"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "aramintak/the_point_wan2",
      "name": "the_point_wan2",
      "displayName": "the_point_wan2",
      "provider": "replicate",
      "category": "image",
      "endpoint": "aramintak/the_point_wan2",
      "version": "66f5fb499e03af403187ff31ac259a4b88cfbd82f96ace6ffa40ff566df805f0",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Illustration style model with gritty depth.",
        "runCount": 33,
        "confidence": 0.6,
        "qualityScore": 15.314789170422552,
        "createdAt": "2025-03-15T09:05:21.812120Z",
        "owner": "aramintak",
        "coverImage": "https://replicate.delivery/xezq/g1Q4zZNx9fT5LqEzjMQRGb0sYUGIaRpa2ltBMdLrvtUcGZMKA/R8_Wan_00001.mp4",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "frames": 81,
              "prompt": "a woman falling through the void, illustration style",
              "fast_mode": "Balanced",
              "resolution": "480p",
              "aspect_ratio": "16:9",
              "sample_shift": 8,
              "sample_steps": 30,
              "negative_prompt": "",
              "lora_strength_clip": 0.9,
              "sample_guide_scale": 5,
              "lora_strength_model": 0.9
            },
            "output": [
              "https://replicate.delivery/xezq/g1Q4zZNx9fT5LqEzjMQRGb0sYUGIaRpa2ltBMdLrvtUcGZMKA/R8_Wan_00001.mp4"
            ],
            "prompt": "a woman falling through the void, illustration style"
          }
        ],
        "parameterDescriptions": {
          "seed": "Set a seed for reproducibility. Random by default.",
          "image": "Image to use as a starting frame for image to video generation.",
          "frames": "The number of frames to generate (1 to 5 seconds)",
          "prompt": "Text prompt for video generation",
          "fast_mode": "Speed up generation with different levels of acceleration. Faster modes may degrade quality somewhat. The speedup is dependent on the content, so different videos may see different speedups.",
          "resolution": "The resolution of the video. 720p is not supported for 1.3b.",
          "aspect_ratio": "The aspect ratio of the video. 16:9, 9:16, 1:1, etc.",
          "sample_shift": "Sample shift factor",
          "sample_steps": "Number of generation steps. Fewer steps means faster generation, at the expensive of output quality. 30 steps is sufficient for most prompts",
          "negative_prompt": "Things you do not want to see in your video",
          "replicate_weights": "Replicate LoRA weights to use. Leave blank to use the default weights.",
          "lora_strength_clip": "Strength of the LORA applied to the CLIP model. 0.0 is no LORA.",
          "sample_guide_scale": "Higher guide scale makes prompt adherence better, but can reduce variation",
          "lora_strength_model": "Strength of the LORA applied to the model. 0.0 is no LORA."
        }
      }
    },
    {
      "id": "leverategroup/dylan",
      "name": "dylan",
      "displayName": "dylan",
      "provider": "replicate",
      "category": "image",
      "endpoint": "leverategroup/dylan",
      "version": "a691230af9e09903ffc8cb338b7f8c883b2496a518c80c586c1f4f4322e26c31",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "dylan for AI training",
        "runCount": 31,
        "confidence": 0.6,
        "qualityScore": 15.051499783199061,
        "createdAt": "2025-06-23T04:30:17.232560Z",
        "owner": "leverategroup",
        "coverImage": "https://replicate.delivery/xezq/9KPW8OFuc45GHZwAYWsh3oy3js6au1VLKdymK70ulmjBLaOF/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "mask": "https://replicate.delivery/pbxt/NEaHXtlBFszPxFUN8Uwii8w60LS3CgAAVvcxOzWqPjByiJ45/ChatGPT%20Image%20Jun%2023%2C%202025%2C%2009_48_06%20AM.png",
              "model": "dev",
              "prompt": "dylan, indonesian superhero, with steal custom and batik, in magic wonderland",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "16:9",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/9KPW8OFuc45GHZwAYWsh3oy3js6au1VLKdymK70ulmjBLaOF/out-0.webp"
            ],
            "prompt": "dylan, indonesian superhero, with steal custom and batik, in magic wonderland"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "yanyan19991/my-gufeng",
      "name": "my-gufeng",
      "displayName": "my-gufeng",
      "provider": "replicate",
      "category": "image",
      "endpoint": "yanyan19991/my-gufeng",
      "version": "d3b2d5d31b803a4a71ff684fd07aafd4cf451f76814d581f1d906f966abd2cc4",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "tongyi renwu",
        "runCount": 26,
        "confidence": 0.6,
        "qualityScore": 14.313637641589875,
        "createdAt": "2025-03-26T15:14:47.277169Z",
        "owner": "yanyan19991",
        "coverImage": "https://replicate.delivery/xezq/gP1Blf7zpF3PaKx8NBGO2eWRMjz2guREJkL0lOa56FO4Ye4oA/out-0.webp",
        "githubUrl": "https://github.com/replicate/mymodel",
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/MjB9XrVbIRbaqKXVO98ugSm28UAwgJ1bDj2VL3odytzvNzC8/2.jpg",
              "model": "dev",
              "width": 1024,
              "height": 1024,
              "prompt": "TOK，低头微笑，白衣汉服，墨色长发，清冷气质，写实风格",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/gP1Blf7zpF3PaKx8NBGO2eWRMjz2guREJkL0lOa56FO4Ye4oA/out-0.webp"
            ],
            "prompt": "TOK，低头微笑，白衣汉服，墨色长发，清冷气质，写实风格"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "loolau/flux-static-ads",
      "name": "flux-static-ads",
      "displayName": "flux-static-ads",
      "provider": "replicate",
      "category": "image",
      "endpoint": "loolau/flux-static-ads",
      "version": "573274c01eb4b21b17c1c04b79e8f4b25932206e0404f17cf0e45001edf68bc5",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Create the best static ads for your brand",
        "runCount": 22,
        "confidence": 0.6,
        "qualityScore": 13.617278360175929,
        "createdAt": "2025-06-22T03:17:12.223416Z",
        "owner": "loolau",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/a9550be2-a9f2-4c92-872b-b6cf80513b03/replicate-prediction-g9h5zyrnvnr.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "static ads, a comparison ads of a baby blanket showing the differences",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 2,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/xQUir4mjfgSDdC0k3gapzUnoWAia5JuJdIKJEEDwI6xTM0cKA/out-0.webp",
              "https://replicate.delivery/xezq/8bveGIadN2wZHqrMA1bWVZMim8ZLYCI8aFxQocVhYjxTM0cKA/out-1.webp"
            ],
            "prompt": "static ads, a comparison ads of a baby blanket showing the differences"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "emibob/testinggg-48658",
      "name": "testinggg-48658",
      "displayName": "testinggg-48658",
      "provider": "replicate",
      "category": "image",
      "endpoint": "emibob/testinggg-48658",
      "version": "f678b81cd8c98b1a3cad2715e1ff4d41bb7903727315d0237c7dcab3b2bb6697",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "A fine-tuned portrait model",
        "runCount": 22,
        "confidence": 0.6,
        "qualityScore": 13.617278360175929,
        "createdAt": "2025-03-07T22:57:37.015941Z",
        "owner": "emibob",
        "coverImage": "https://replicate.delivery/xezq/ZXpnoUXPdtrOEZQzBFM7QLeSlhM0OrLCzeXa3zFIlAadNpZUA/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "HARDYHAR: A highly detailed, photorealistic portrait-style photograph of a joyful family enjoying a sunny Hawaiian beach vacation. In the foreground, a married couple stands together smiling warmly. The woman has long, flowing brunette hair gently blowing in the ocean breeze, framing her soft expression beautifully. She is wearing an elegant, flowy white beach dress paired with a wide-brimmed sun hat. Her husband stands beside her dressed in a vibrant Hawaiian shirt, his arm affectionately around her waist. Slightly behind and to their side, their two playful twin 6-year-old sons, both blond and dressed in colorful swim trunks, enthusiastically build an elaborate sandcastle together. The background showcases gentle turquoise ocean waves softly rolling onto pristine golden sands, lush palm trees swaying gently, and a clear, bright blue sky, perfectly capturing the relaxed, carefree spirit of their tropical family getaway",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/ZXpnoUXPdtrOEZQzBFM7QLeSlhM0OrLCzeXa3zFIlAadNpZUA/out-0.webp"
            ],
            "prompt": "HARDYHAR: A highly detailed, photorealistic portrait-style photograph of a joyful family enjoying a sunny Hawaiian beach vacation. In the foreground, a married couple stands together smiling warmly. The woman has long, flowing brunette hair gently blowing in the ocean breeze, framing her soft expression beautifully. She is wearing an elegant, flowy white beach dress paired with a wide-brimmed sun hat. Her husband stands beside her dressed in a vibrant Hawaiian shirt, his arm affectionately around her waist. Slightly behind and to their side, their two playful twin 6-year-old sons, both blond and dressed in colorful swim trunks, enthusiastically build an elaborate sandcastle together. The background showcases gentle turquoise ocean waves softly rolling onto pristine golden sands, lush palm trees swaying gently, and a clear, bright blue sky, perfectly capturing the relaxed, carefree spirit of their tropical family getaway"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "subhash25rawat/venhance",
      "name": "venhance",
      "displayName": "venhance",
      "provider": "replicate",
      "category": "video",
      "endpoint": "subhash25rawat/venhance",
      "version": "23c9a26ac1a1f41279b7a3af3fa659dd9da47616582a9a4963a197e757aad4c0",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "videoUrl": "video"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Enhance your video quality with AI",
        "runCount": 22,
        "confidence": 0.9,
        "qualityScore": 13.617278360175929,
        "createdAt": "2025-03-07T06:04:51.286520Z",
        "owner": "subhash25rawat",
        "coverImage": "https://replicate.delivery/yhqm/mRle4HeVBknBMkKrHagV7Aifz3OO8vCnFlEPlMQeGEoISQYRB/tmp.mp4",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "video": "https://replicate.delivery/pbxt/McGvS5ePPX7pTQ48KI70JJ0jLLIvxk5j6Q4BDBUwye5gBE6y/cat.mp4",
              "prompt": "A cat wearing sunglasses at a pool",
              "up_scale": 4,
              "noise_aug": 200,
              "target_fps": 24
            },
            "output": "https://replicate.delivery/yhqm/mRle4HeVBknBMkKrHagV7Aifz3OO8vCnFlEPlMQeGEoISQYRB/tmp.mp4",
            "prompt": "A cat wearing sunglasses at a pool"
          }
        ],
        "parameterDescriptions": {
          "video": "video to upscale",
          "prompt": "prompt describing the image",
          "up_scale": "up_scale",
          "noise_aug": "noise_aug",
          "target_fps": "target_fps"
        }
      }
    },
    {
      "id": "maikocode/ascii-style",
      "name": "ascii-style",
      "displayName": "ascii-style",
      "provider": "replicate",
      "category": "image",
      "endpoint": "maikocode/ascii-style",
      "version": "4f8d3a23106ead32d5d47f13ba1d31bb33f02ec8e441105689a1e1f191140024",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Turn image into ASCII style.",
        "runCount": 17,
        "confidence": 0.9,
        "qualityScore": 12.552725051033061,
        "createdAt": "2025-07-19T11:27:08.727394Z",
        "owner": "maikocode",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/7a67aa26-2528-4e90-9fe2-204902de23e8/replicate-prediction-ajhfs9c129rm.jpg",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "prompt": "Turn image into ASCII style.",
              "guidance": 2.5,
              "megapixels": "1",
              "input_image": "https://replicate.delivery/pbxt/NNv9fwTeM7f0qD6XpMTTFLAxSoZASqpbiJzDTt2cxfRzBZi6/model%20as%20a%20Clown%20with%20Clown%20Makeup.jpg",
              "aspect_ratio": "1:1",
              "lora_strength": 1,
              "output_format": "jpg",
              "output_quality": 80,
              "num_inference_steps": 30
            },
            "output": "https://replicate.delivery/xezq/j8Eo18Ef4MRXLSZQ1AAlNp3XilbwO5eeud209mfMZXEQIOJUB/output.jpg",
            "prompt": "Turn image into ASCII style."
          }
        ],
        "parameterDescriptions": {
          "seed": "Random seed for reproducible generation. Leave blank for random.",
          "prompt": "Text description of what you want to generate, or the instruction on how to edit the given image.",
          "guidance": "Guidance scale for generation",
          "megapixels": "Approximate number of megapixels for generated image",
          "input_image": "Image to use as reference. Must be jpeg, png, gif, or webp.",
          "aspect_ratio": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "lora_strength": "Strength of the lora",
          "output_format": "Output image format",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "replicate_weights": "Path to the lora weights",
          "num_inference_steps": "Number of inference steps",
          "disable_safety_checker": "Disable NSFW safety checker"
        }
      }
    },
    {
      "id": "citoreh/shahzadeh",
      "name": "shahzadeh",
      "displayName": "shahzadeh",
      "provider": "replicate",
      "category": "image",
      "endpoint": "citoreh/shahzadeh",
      "version": "cddc1efdbcf0f39b578d724ba0ff704c8f37c7cbc7b9d9b9584253dca7cf4286",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate a female character",
        "runCount": 17,
        "confidence": 0.6,
        "qualityScore": 12.552725051033061,
        "createdAt": "2025-06-06T12:14:50.253017Z",
        "owner": "citoreh",
        "coverImage": "https://replicate.delivery/xezq/DGjQiFJqfm0BPSS5dkxbW3PfhSfkMfaV788ZofCEK1AlzVhmC/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "A woman is reading a book in a coffee shop, looking at the camera. shahzadeh",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/DGjQiFJqfm0BPSS5dkxbW3PfhSfkMfaV788ZofCEK1AlzVhmC/out-0.webp"
            ],
            "prompt": "A woman is reading a book in a coffee shop, looking at the camera. shahzadeh"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "airlonfilho/airlonfilhoensaio",
      "name": "airlonfilhoensaio",
      "displayName": "airlonfilhoensaio",
      "provider": "replicate",
      "category": "image",
      "endpoint": "airlonfilho/airlonfilhoensaio",
      "version": "5bb1540741b601b792e14aace3b3719867d89a985a583952c79aab42ccfd0013",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Ensaio profissional",
        "runCount": 17,
        "confidence": 0.6,
        "qualityScore": 12.552725051033061,
        "createdAt": "2025-05-12T20:12:18.787793Z",
        "owner": "airlonfilho",
        "coverImage": "https://replicate.delivery/xezq/auRyH47r2dJCFpD6oNDfrIEzGmpJqky1WqedL2dwTPijQDsUA/out-0.png",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "airlonfilho Studio portrait of a confident, strong, athletic man, 5'8\" and 220 lbs. He has a short, clean, professional haircut, classic business style, and is wearing a black crew neck shirt. His expression is serious and focused, with his gaze slightly to the side. The lighting is moody and cinematic, with soft lights accentuating his facial structure. The background is a gradient of dark tones, creating depth and a premium, sophisticated aesthetic. The image is crisp and professional, emphasizing sophistication and modern style. without accessories",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "png",
              "guidance_scale": 3,
              "output_quality": 100,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/auRyH47r2dJCFpD6oNDfrIEzGmpJqky1WqedL2dwTPijQDsUA/out-0.png"
            ],
            "prompt": "airlonfilho Studio portrait of a confident, strong, athletic man, 5'8\" and 220 lbs. He has a short, clean, professional haircut, classic business style, and is wearing a black crew neck shirt. His expression is serious and focused, with his gaze slightly to the side. The lighting is moody and cinematic, with soft lights accentuating his facial structure. The background is a gradient of dark tones, creating depth and a premium, sophisticated aesthetic. The image is crisp and professional, emphasizing sophistication and modern style. without accessories"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "jbilcke/silly-posters-flux-lora",
      "name": "silly-posters-flux-lora",
      "displayName": "silly-posters-flux-lora",
      "provider": "replicate",
      "category": "image",
      "endpoint": "jbilcke/silly-posters-flux-lora",
      "version": "b55715322da268b76248c687aaeb4d30dc786aef5b221f500fca199079ee6ccc",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Generate silly street posters",
        "runCount": 16,
        "confidence": 0.6,
        "qualityScore": 12.30448921378274,
        "createdAt": "2025-07-13T15:05:51.003727Z",
        "owner": "jbilcke",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/aebc279c-5902-4322-9d32-c18eae81a80f/out-0_3.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "SLLPSTR silly poster of a lost llama, asking about where the llama was",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "4:5",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/o6nB4QTUIBJ9MBBIVZKSOBgksNewALbAZXyP7PRZyHaE8LgKA/out-0.webp"
            ],
            "prompt": "SLLPSTR silly poster of a lost llama, asking about where the llama was"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "haiversion/moodboards",
      "name": "moodboards",
      "displayName": "moodboards",
      "provider": "replicate",
      "category": "image",
      "endpoint": "haiversion/moodboards",
      "version": "b4b8ef52d47f0dd0506f68830e9b7b6336ec0c06c96aeee0be5c580afada346e",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "create interior designers moodboards",
        "runCount": 16,
        "confidence": 0.6,
        "qualityScore": 12.30448921378274,
        "createdAt": "2025-05-27T15:55:18.344164Z",
        "owner": "haiversion",
        "coverImage": "https://replicate.delivery/xezq/TYZqKDv8L1ZmLdSroEpomljGkQSLHWS2xVQCgBcIObuR2ERF/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": " TOK_moodboard Soft pastels, Fluted wood panels, Terrazzo surfaces",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/TYZqKDv8L1ZmLdSroEpomljGkQSLHWS2xVQCgBcIObuR2ERF/out-0.webp"
            ],
            "prompt": " TOK_moodboard Soft pastels, Fluted wood panels, Terrazzo surfaces"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "leverategroup/emma-ds",
      "name": "emma-ds",
      "displayName": "emma-ds",
      "provider": "replicate",
      "category": "image",
      "endpoint": "leverategroup/emma-ds",
      "version": "7db97bebd79d0a3cb334a63b89df014490e994a0565ebafa47584613d559e9af",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "detects doll in an image",
        "runCount": 14,
        "confidence": 0.6,
        "qualityScore": 11.760912590556813,
        "createdAt": "2025-06-20T02:04:18.178915Z",
        "owner": "leverategroup",
        "coverImage": "https://replicate.delivery/xezq/12KmLTzi5MKADd9g4bMGqWd1Hb3fh4ZwBbwwVMaV2f1ltn4UA/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "mask": "https://www.thetoyshop.com/dolls/baby-dolls/BABY-Born-43cm-Emma-Doll-Starter-Set/p/569584",
              "model": "dev",
              "prompt": "EMMA the bald doll, is warming herself next to her fireplace inside the house in the doll setting world in winter with winter clothes and drinking tea",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/12KmLTzi5MKADd9g4bMGqWd1Hb3fh4ZwBbwwVMaV2f1ltn4UA/out-0.webp"
            ],
            "prompt": "EMMA the bald doll, is warming herself next to her fireplace inside the house in the doll setting world in winter with winter clothes and drinking tea"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "probablyvivek/cinematic-poster-lora",
      "name": "cinematic-poster-lora",
      "displayName": "cinematic-poster-lora",
      "provider": "replicate",
      "category": "image",
      "endpoint": "probablyvivek/cinematic-poster-lora",
      "version": "f2f26cf705b0695a562c488a69cb220ee68a0751977583671e2ab7a382cf01be",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Creates Hollywood Style Posters",
        "runCount": 12,
        "confidence": 0.6,
        "qualityScore": 11.139433523068368,
        "createdAt": "2025-04-28T18:13:49.680617Z",
        "owner": "probablyvivek",
        "coverImage": "https://replicate.delivery/xezq/ATZzti3YGHJQL1DgJ33ff4bcKc483UzfFX7P26LqRCUZGvOpA/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "hollywood_poster1, suspenseful thriller poster, shadowy figure in fog, dark alley, glowing neon text, cinematic tone\n",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/ATZzti3YGHJQL1DgJ33ff4bcKc483UzfFX7P26LqRCUZGvOpA/out-0.webp"
            ],
            "prompt": "hollywood_poster1, suspenseful thriller poster, shadowy figure in fog, dark alley, glowing neon text, cinematic tone\n"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "derickson/ds-01",
      "name": "ds-01",
      "displayName": "ds-01",
      "provider": "replicate",
      "category": "image",
      "endpoint": "derickson/ds-01",
      "version": "ca4f2ed73bc8b5d9a97c49a349fc13fa50e736b15e9396eae8ea0f0634b089fd",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "learning to fine tune a lora",
        "runCount": 12,
        "confidence": 0.6,
        "qualityScore": 11.139433523068368,
        "createdAt": "2025-04-24T01:35:25.288283Z",
        "owner": "derickson",
        "coverImage": "https://tjzk.replicate.delivery/models_models_cover_image/7449431c-b574-4484-ba14-92915634acf7/out-0_2.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "image": "https://replicate.delivery/pbxt/MtFE70ID5jCM94NPTlef1yncdGosXWUfpPuY9b5NYOcUzAg1/templatebrom.jpg",
              "model": "dev",
              "prompt": "in the style of bromdarksun25, a painting of a muscled warrior brandishing a spear in a gladiator arena, he wears a mix of bone, metal, and obsidian armor pieces. he is intimidating and yelling",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.5,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/TgwgHSMageU8IKvf5oAEbhwkzgeL0KMDf038PeQM6z3x1lukC/out-0.webp"
            ],
            "prompt": "in the style of bromdarksun25, a painting of a muscled warrior brandishing a spear in a gladiator arena, he wears a mix of bone, metal, and obsidian armor pieces. he is intimidating and yelling"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "citoreh/sasha",
      "name": "sasha",
      "displayName": "sasha",
      "provider": "replicate",
      "category": "image",
      "endpoint": "citoreh/sasha",
      "version": "8334221456395e77c4ba225511955a792d34a233c968076e9519f653c7acd8ec",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Sasha is a young boy advertising persona",
        "runCount": 11,
        "confidence": 0.6,
        "qualityScore": 10.79181246047625,
        "createdAt": "2025-06-07T16:37:48.958963Z",
        "owner": "citoreh",
        "coverImage": "https://replicate.delivery/xezq/FmHHFfRsUA3NDisJSy9R3k3EtK5E9BZ6crMKRATiM2Kz6QaKA/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "sasha. a young boy. Close-up. Studio lighting. Having a cat. Looking at the camera. Smiling. ",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/FmHHFfRsUA3NDisJSy9R3k3EtK5E9BZ6crMKRATiM2Kz6QaKA/out-0.webp"
            ],
            "prompt": "sasha. a young boy. Close-up. Studio lighting. Having a cat. Looking at the camera. Smiling. "
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    },
    {
      "id": "citoreh/qajar",
      "name": "qajar",
      "displayName": "qajar",
      "provider": "replicate",
      "category": "image",
      "endpoint": "citoreh/qajar",
      "version": "5942d0bcc757f513e67d49050cd99c69b4c718038fe6db25ec54cb38a30f4420",
      "defaultParams": {},
      "inputMapping": {
        "prompt": "prompt",
        "imageUrl": "image"
      },
      "outputMapping": {
        "result": "output"
      },
      "metadata": {
        "description": "Imagine your idea in Qajar Era",
        "runCount": 11,
        "confidence": 0.6,
        "qualityScore": 10.79181246047625,
        "createdAt": "2025-06-06T14:43:45.406911Z",
        "owner": "citoreh",
        "coverImage": "https://replicate.delivery/xezq/dt5mVpr4aMqWJ5Eo15h1C3KDCWfg3NZiLfjOaCfMWFdUgWopA/out-0.webp",
        "githubUrl": null,
        "paperUrl": null,
        "licenseUrl": null,
        "pricing": {
          "tier": "free"
        },
        "examples": [
          {
            "input": {
              "model": "dev",
              "prompt": "City of Tehran in qajar era",
              "go_fast": false,
              "lora_scale": 1,
              "megapixels": "1",
              "num_outputs": 1,
              "aspect_ratio": "1:1",
              "output_format": "webp",
              "guidance_scale": 3,
              "output_quality": 80,
              "prompt_strength": 0.8,
              "extra_lora_scale": 1,
              "num_inference_steps": 28
            },
            "output": [
              "https://replicate.delivery/xezq/dt5mVpr4aMqWJ5Eo15h1C3KDCWfg3NZiLfjOaCfMWFdUgWopA/out-0.webp"
            ],
            "prompt": "City of Tehran in qajar era"
          }
        ],
        "parameterDescriptions": {
          "mask": "Image mask for image inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "seed": "Random seed. Set for reproducible generation",
          "image": "Input image for image to image or inpainting mode. If provided, aspect_ratio, width, and height inputs are ignored.",
          "model": "Which model to run inference with. The dev model performs best with around 28 inference steps but the schnell model only needs 4 steps.",
          "width": "Width of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "height": "Height of generated image. Only works if `aspect_ratio` is set to custom. Will be rounded to nearest multiple of 16. Incompatible with fast generation",
          "prompt": "Prompt for generated image. If you include the `trigger_word` used in the training process you are more likely to activate the trained object, style, or concept in the resulting image.",
          "go_fast": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16",
          "extra_lora": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "lora_scale": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "megapixels": "Approximate number of megapixels for generated image",
          "num_outputs": "Number of outputs to generate",
          "aspect_ratio": "Aspect ratio for the generated image. If custom is selected, uses height and width below & will run in bf16 mode",
          "output_format": "Format of the output images",
          "guidance_scale": "Guidance scale for the diffusion process. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "output_quality": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "prompt_strength": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "extra_lora_scale": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "replicate_weights": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "num_inference_steps": "Number of denoising steps. More steps can give more detailed images, but take longer.",
          "disable_safety_checker": "Disable safety checker for generated images."
        }
      }
    }
  ]
}